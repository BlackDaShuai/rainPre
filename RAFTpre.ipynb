{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-13T13:43:07.692472Z",
     "start_time": "2024-10-13T13:43:07.570299Z"
    }
   },
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from cv2 import waitKey, destroyAllWindows\n",
    "from torchvision.models.optical_flow import raft_large, Raft_Large_Weights, raft_small, Raft_Small_Weights\n",
    "from torchvision.utils import flow_to_image\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 配置\n",
    "image_folder = 'overDataSet1'  # 替换为你的图片文件夹路径\n",
    "output_folder = 'lightFlowOutput'  # 替换为你希望保存输出的文件夹路径\n",
    "output_PRE_folder = 'lightFlowOutputPre'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "os.makedirs(output_PRE_folder, exist_ok=True)\n",
    "\n",
    "# 加载模型\n",
    "# weights1= Raft_Large_Weights.DEFAULT\n",
    "weights1= Raft_Large_Weights.C_T_SKHT_K_V2\n",
    "weights2= Raft_Small_Weights.DEFAULT\n",
    "model = raft_large(weights=weights1, progress=False).to(device)\n",
    "model = model.eval()\n",
    "\n",
    "# 图片预处理函数，像素点需要被8整除\n",
    "# def preprocess(img1, img2):\n",
    "#     img1 = F.resize(img1, size=[520, 960], antialias=False)\n",
    "#     img2 = F.resize(img2, size=[520, 960], antialias=False)\n",
    "#     return transforms(img1, img2)\n",
    "\n",
    "# 获取所有图片文件\n",
    "image_files = sorted(glob.glob(os.path.join(image_folder, '*.png')))\n",
    "image_files = sorted(image_files, key=lambda x: int((os.path.basename(x).split('.')[0]).split('_')[-1]))\n",
    "print(image_files )\n",
    "num_frames = len(image_files)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['overDataSet3\\\\0.png', 'overDataSet3\\\\1.png', 'overDataSet3\\\\2.png', 'overDataSet3\\\\3.png', 'overDataSet3\\\\4.png', 'overDataSet3\\\\5.png', 'overDataSet3\\\\6.png', 'overDataSet3\\\\7.png', 'overDataSet3\\\\8.png', 'overDataSet3\\\\9.png', 'overDataSet3\\\\10.png', 'overDataSet3\\\\11.png', 'overDataSet3\\\\12.png', 'overDataSet3\\\\13.png', 'overDataSet3\\\\14.png', 'overDataSet3\\\\15.png', 'overDataSet3\\\\16.png', 'overDataSet3\\\\17.png', 'overDataSet3\\\\18.png', 'overDataSet3\\\\19.png', 'overDataSet3\\\\20.png', 'overDataSet3\\\\21.png', 'overDataSet3\\\\22.png', 'overDataSet3\\\\23.png', 'overDataSet3\\\\24.png', 'overDataSet3\\\\25.png', 'overDataSet3\\\\26.png', 'overDataSet3\\\\27.png', 'overDataSet3\\\\28.png', 'overDataSet3\\\\29.png', 'overDataSet3\\\\30.png', 'overDataSet3\\\\31.png', 'overDataSet3\\\\32.png', 'overDataSet3\\\\33.png', 'overDataSet3\\\\34.png', 'overDataSet3\\\\35.png', 'overDataSet3\\\\36.png', 'overDataSet3\\\\37.png', 'overDataSet3\\\\38.png', 'overDataSet3\\\\39.png', 'overDataSet3\\\\40.png', 'overDataSet3\\\\41.png', 'overDataSet3\\\\42.png', 'overDataSet3\\\\43.png', 'overDataSet3\\\\44.png', 'overDataSet3\\\\45.png', 'overDataSet3\\\\46.png', 'overDataSet3\\\\47.png', 'overDataSet3\\\\48.png', 'overDataSet3\\\\49.png', 'overDataSet3\\\\50.png', 'overDataSet3\\\\51.png', 'overDataSet3\\\\52.png', 'overDataSet3\\\\53.png', 'overDataSet3\\\\54.png', 'overDataSet3\\\\55.png', 'overDataSet3\\\\56.png', 'overDataSet3\\\\57.png', 'overDataSet3\\\\58.png', 'overDataSet3\\\\59.png', 'overDataSet3\\\\60.png', 'overDataSet3\\\\61.png', 'overDataSet3\\\\62.png', 'overDataSet3\\\\63.png', 'overDataSet3\\\\64.png', 'overDataSet3\\\\65.png', 'overDataSet3\\\\66.png', 'overDataSet3\\\\67.png', 'overDataSet3\\\\68.png', 'overDataSet3\\\\69.png', 'overDataSet3\\\\70.png', 'overDataSet3\\\\71.png', 'overDataSet3\\\\72.png', 'overDataSet3\\\\73.png', 'overDataSet3\\\\74.png', 'overDataSet3\\\\75.png', 'overDataSet3\\\\76.png', 'overDataSet3\\\\77.png', 'overDataSet3\\\\78.png', 'overDataSet3\\\\79.png', 'overDataSet3\\\\80.png', 'overDataSet3\\\\81.png', 'overDataSet3\\\\82.png', 'overDataSet3\\\\83.png', 'overDataSet3\\\\84.png', 'overDataSet3\\\\85.png', 'overDataSet3\\\\86.png', 'overDataSet3\\\\87.png', 'overDataSet3\\\\88.png', 'overDataSet3\\\\89.png', 'overDataSet3\\\\90.png', 'overDataSet3\\\\91.png', 'overDataSet3\\\\92.png', 'overDataSet3\\\\93.png', 'overDataSet3\\\\94.png', 'overDataSet3\\\\95.png', 'overDataSet3\\\\96.png', 'overDataSet3\\\\97.png', 'overDataSet3\\\\98.png', 'overDataSet3\\\\99.png', 'overDataSet3\\\\100.png', 'overDataSet3\\\\101.png', 'overDataSet3\\\\102.png', 'overDataSet3\\\\103.png', 'overDataSet3\\\\104.png', 'overDataSet3\\\\105.png', 'overDataSet3\\\\106.png', 'overDataSet3\\\\107.png', 'overDataSet3\\\\108.png', 'overDataSet3\\\\109.png', 'overDataSet3\\\\110.png', 'overDataSet3\\\\111.png', 'overDataSet3\\\\112.png', 'overDataSet3\\\\113.png', 'overDataSet3\\\\114.png', 'overDataSet3\\\\115.png', 'overDataSet3\\\\116.png', 'overDataSet3\\\\117.png', 'overDataSet3\\\\118.png', 'overDataSet3\\\\119.png', 'overDataSet3\\\\120.png', 'overDataSet3\\\\121.png', 'overDataSet3\\\\122.png', 'overDataSet3\\\\123.png', 'overDataSet3\\\\124.png', 'overDataSet3\\\\125.png', 'overDataSet3\\\\126.png', 'overDataSet3\\\\127.png', 'overDataSet3\\\\128.png', 'overDataSet3\\\\129.png', 'overDataSet3\\\\130.png', 'overDataSet3\\\\131.png', 'overDataSet3\\\\132.png', 'overDataSet3\\\\133.png', 'overDataSet3\\\\134.png', 'overDataSet3\\\\135.png', 'overDataSet3\\\\136.png', 'overDataSet3\\\\137.png', 'overDataSet3\\\\138.png', 'overDataSet3\\\\139.png', 'overDataSet3\\\\140.png', 'overDataSet3\\\\141.png', 'overDataSet3\\\\142.png', 'overDataSet3\\\\143.png', 'overDataSet3\\\\144.png', 'overDataSet3\\\\145.png', 'overDataSet3\\\\146.png', 'overDataSet3\\\\147.png', 'overDataSet3\\\\148.png', 'overDataSet3\\\\149.png', 'overDataSet3\\\\150.png', 'overDataSet3\\\\151.png', 'overDataSet3\\\\152.png', 'overDataSet3\\\\153.png', 'overDataSet3\\\\154.png', 'overDataSet3\\\\155.png', 'overDataSet3\\\\156.png', 'overDataSet3\\\\157.png', 'overDataSet3\\\\158.png', 'overDataSet3\\\\159.png', 'overDataSet3\\\\160.png', 'overDataSet3\\\\161.png', 'overDataSet3\\\\162.png', 'overDataSet3\\\\163.png', 'overDataSet3\\\\164.png', 'overDataSet3\\\\165.png', 'overDataSet3\\\\166.png', 'overDataSet3\\\\167.png', 'overDataSet3\\\\168.png', 'overDataSet3\\\\169.png', 'overDataSet3\\\\170.png', 'overDataSet3\\\\171.png', 'overDataSet3\\\\172.png', 'overDataSet3\\\\173.png', 'overDataSet3\\\\174.png', 'overDataSet3\\\\175.png', 'overDataSet3\\\\176.png', 'overDataSet3\\\\177.png', 'overDataSet3\\\\178.png', 'overDataSet3\\\\179.png']\n"
     ]
    }
   ],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T13:43:50.495839Z",
     "start_time": "2024-10-13T13:43:07.707470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 帧预测函数\n",
    "def apply_flow(image, flow):\n",
    "        flow = flow.permute(0, 2, 3, 1)  # (N, H, W, 2)\n",
    "        h, w = flow.shape[1:3]\n",
    "        y_coords, x_coords = torch.meshgrid(torch.arange(h), torch.arange(w), indexing='ij')\n",
    "        y_coords, x_coords = y_coords.float(), x_coords.float()\n",
    "        y_coords, x_coords = y_coords.to(flow.device), x_coords.to(flow.device)\n",
    "        \n",
    "        # 计算新的坐标\n",
    "        new_x_coords = x_coords + flow[:, :, :, 0]\n",
    "        new_y_coords = y_coords + flow[:, :, :, 1]\n",
    "        \n",
    "        # 归一化坐标\n",
    "        new_x_coords = (new_x_coords / (w - 1)) * 2 - 1\n",
    "        new_y_coords = (new_y_coords / (h - 1)) * 2 - 1\n",
    "        \n",
    "        # 使用bicubic插值采样\n",
    "        grid = torch.stack([new_x_coords, new_y_coords], dim=-1)\n",
    "        warped_image = torch.nn.functional.grid_sample(image, grid, mode='bicubic', padding_mode='border', align_corners=True)\n",
    "        return warped_image\n",
    "\n",
    "\n",
    "\n",
    "max_flow_step = 10.0\n",
    "step = 3\n",
    "\n",
    "# 累加光流函数\n",
    "def accumulate_flow(accumulated_flow, new_flow):\n",
    "    return accumulated_flow + new_flow\n",
    "\n",
    "# 限制光流步长函数\n",
    "def limit_flow_step(flow, max_step):\n",
    "    return torch.clamp(flow, min=-max_step, max=max_step)  # 限制光流的最大步长\n",
    "\n",
    "# 进行光流预测\n",
    "print(num_frames)\n",
    "for i in range(num_frames - step):\n",
    "#for i in range(20):\n",
    "    accumulated_flow = None  # 每次更新i初始化累积光流为None\n",
    "    for j in range(step):\n",
    "        print('img1=',i + j)\n",
    "        print('img2=',i + j + 1)\n",
    "        img1 = Image.open(image_files[i + j]).convert('RGB')\n",
    "        img2 = Image.open(image_files[i + j + 1]).convert('RGB')\n",
    "        # if i == 10:\n",
    "        #     img1.save(f'1img{i}{j}.jpg')\n",
    "        # \n",
    "        # \n",
    "        #     img2.save(f'2img{i}{j+1}.jpg')\n",
    "\n",
    "\n",
    "        \n",
    "        img1_tensor = F.to_tensor(img1).unsqueeze(0)\n",
    "        img2_tensor = F.to_tensor(img2).unsqueeze(0)\n",
    "\n",
    "        # img1_tensor, img2_tensor = preprocess(img1_tensor, img2_tensor)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            list_of_flows = model(img1_tensor.to(device), img2_tensor.to(device))\n",
    "            predicted_flows = list_of_flows[-1].cpu()# 获取光流（一般来说最后一个最准确）\n",
    "            \n",
    "        # 限制光流移动步长\n",
    "        # predicted_flows = limit_flow_step(predicted_flows, max_flow_step)\n",
    "        \n",
    "        if accumulated_flow is None:\n",
    "            accumulated_flow = predicted_flows*((j+1)/6)  # 如果是第一帧光流，初始化累积光流\n",
    "        else:\n",
    "            accumulated_flow = accumulate_flow(accumulated_flow, predicted_flows*((j+1)/6))  # 叠加光流，以1/6，2/6……的方式叠加\n",
    "    \n",
    "    \n",
    "    print('shape=',predicted_flows.shape)\n",
    "\n",
    "    flow_imgs = flow_to_image(predicted_flows)\n",
    "    \n",
    "    # 保存光流结果\n",
    "    output_file = os.path.join(output_folder, f'accumulated_flow_{i:03d}_to_{i+step:03d}.png')\n",
    "    plt.imsave(output_file, flow_imgs.squeeze().permute(1, 2, 0).numpy())\n",
    "\n",
    "    print(f\"Processed frame {i} to {i+step}\")\n",
    "\n",
    "    \n",
    "    # 进行帧预测\n",
    "    predicted_next_frame = apply_flow(img2_tensor, accumulated_flow)\n",
    "    # 保存预测结果\n",
    "    output_file = os.path.join(output_PRE_folder, f'predicted{i+step+1:03d}using{i:03d}to{i+step:03d}.png')\n",
    "    predicted_next_frame = predicted_next_frame.squeeze().permute(1, 2, 0).clamp(0, 1)\n",
    "    plt.imsave(output_file, predicted_next_frame.numpy())\n",
    "    print(\"---\")\n",
    "    \n",
    "print(\"All frames processed.\")"
   ],
   "id": "d35b22a0e34208c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n",
      "img1= 0\n",
      "img2= 1\n",
      "img1= 1\n",
      "img2= 2\n",
      "img1= 2\n",
      "img2= 3\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 0 to 3\n",
      "---\n",
      "img1= 1\n",
      "img2= 2\n",
      "img1= 2\n",
      "img2= 3\n",
      "img1= 3\n",
      "img2= 4\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 1 to 4\n",
      "---\n",
      "img1= 2\n",
      "img2= 3\n",
      "img1= 3\n",
      "img2= 4\n",
      "img1= 4\n",
      "img2= 5\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 2 to 5\n",
      "---\n",
      "img1= 3\n",
      "img2= 4\n",
      "img1= 4\n",
      "img2= 5\n",
      "img1= 5\n",
      "img2= 6\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 3 to 6\n",
      "---\n",
      "img1= 4\n",
      "img2= 5\n",
      "img1= 5\n",
      "img2= 6\n",
      "img1= 6\n",
      "img2= 7\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 4 to 7\n",
      "---\n",
      "img1= 5\n",
      "img2= 6\n",
      "img1= 6\n",
      "img2= 7\n",
      "img1= 7\n",
      "img2= 8\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 5 to 8\n",
      "---\n",
      "img1= 6\n",
      "img2= 7\n",
      "img1= 7\n",
      "img2= 8\n",
      "img1= 8\n",
      "img2= 9\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 6 to 9\n",
      "---\n",
      "img1= 7\n",
      "img2= 8\n",
      "img1= 8\n",
      "img2= 9\n",
      "img1= 9\n",
      "img2= 10\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 7 to 10\n",
      "---\n",
      "img1= 8\n",
      "img2= 9\n",
      "img1= 9\n",
      "img2= 10\n",
      "img1= 10\n",
      "img2= 11\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 8 to 11\n",
      "---\n",
      "img1= 9\n",
      "img2= 10\n",
      "img1= 10\n",
      "img2= 11\n",
      "img1= 11\n",
      "img2= 12\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 9 to 12\n",
      "---\n",
      "img1= 10\n",
      "img2= 11\n",
      "img1= 11\n",
      "img2= 12\n",
      "img1= 12\n",
      "img2= 13\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 10 to 13\n",
      "---\n",
      "img1= 11\n",
      "img2= 12\n",
      "img1= 12\n",
      "img2= 13\n",
      "img1= 13\n",
      "img2= 14\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 11 to 14\n",
      "---\n",
      "img1= 12\n",
      "img2= 13\n",
      "img1= 13\n",
      "img2= 14\n",
      "img1= 14\n",
      "img2= 15\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 12 to 15\n",
      "---\n",
      "img1= 13\n",
      "img2= 14\n",
      "img1= 14\n",
      "img2= 15\n",
      "img1= 15\n",
      "img2= 16\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 13 to 16\n",
      "---\n",
      "img1= 14\n",
      "img2= 15\n",
      "img1= 15\n",
      "img2= 16\n",
      "img1= 16\n",
      "img2= 17\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 14 to 17\n",
      "---\n",
      "img1= 15\n",
      "img2= 16\n",
      "img1= 16\n",
      "img2= 17\n",
      "img1= 17\n",
      "img2= 18\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 15 to 18\n",
      "---\n",
      "img1= 16\n",
      "img2= 17\n",
      "img1= 17\n",
      "img2= 18\n",
      "img1= 18\n",
      "img2= 19\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 16 to 19\n",
      "---\n",
      "img1= 17\n",
      "img2= 18\n",
      "img1= 18\n",
      "img2= 19\n",
      "img1= 19\n",
      "img2= 20\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 17 to 20\n",
      "---\n",
      "img1= 18\n",
      "img2= 19\n",
      "img1= 19\n",
      "img2= 20\n",
      "img1= 20\n",
      "img2= 21\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 18 to 21\n",
      "---\n",
      "img1= 19\n",
      "img2= 20\n",
      "img1= 20\n",
      "img2= 21\n",
      "img1= 21\n",
      "img2= 22\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 19 to 22\n",
      "---\n",
      "img1= 20\n",
      "img2= 21\n",
      "img1= 21\n",
      "img2= 22\n",
      "img1= 22\n",
      "img2= 23\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 20 to 23\n",
      "---\n",
      "img1= 21\n",
      "img2= 22\n",
      "img1= 22\n",
      "img2= 23\n",
      "img1= 23\n",
      "img2= 24\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 21 to 24\n",
      "---\n",
      "img1= 22\n",
      "img2= 23\n",
      "img1= 23\n",
      "img2= 24\n",
      "img1= 24\n",
      "img2= 25\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 22 to 25\n",
      "---\n",
      "img1= 23\n",
      "img2= 24\n",
      "img1= 24\n",
      "img2= 25\n",
      "img1= 25\n",
      "img2= 26\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 23 to 26\n",
      "---\n",
      "img1= 24\n",
      "img2= 25\n",
      "img1= 25\n",
      "img2= 26\n",
      "img1= 26\n",
      "img2= 27\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 24 to 27\n",
      "---\n",
      "img1= 25\n",
      "img2= 26\n",
      "img1= 26\n",
      "img2= 27\n",
      "img1= 27\n",
      "img2= 28\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 25 to 28\n",
      "---\n",
      "img1= 26\n",
      "img2= 27\n",
      "img1= 27\n",
      "img2= 28\n",
      "img1= 28\n",
      "img2= 29\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 26 to 29\n",
      "---\n",
      "img1= 27\n",
      "img2= 28\n",
      "img1= 28\n",
      "img2= 29\n",
      "img1= 29\n",
      "img2= 30\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 27 to 30\n",
      "---\n",
      "img1= 28\n",
      "img2= 29\n",
      "img1= 29\n",
      "img2= 30\n",
      "img1= 30\n",
      "img2= 31\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 28 to 31\n",
      "---\n",
      "img1= 29\n",
      "img2= 30\n",
      "img1= 30\n",
      "img2= 31\n",
      "img1= 31\n",
      "img2= 32\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 29 to 32\n",
      "---\n",
      "img1= 30\n",
      "img2= 31\n",
      "img1= 31\n",
      "img2= 32\n",
      "img1= 32\n",
      "img2= 33\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 30 to 33\n",
      "---\n",
      "img1= 31\n",
      "img2= 32\n",
      "img1= 32\n",
      "img2= 33\n",
      "img1= 33\n",
      "img2= 34\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 31 to 34\n",
      "---\n",
      "img1= 32\n",
      "img2= 33\n",
      "img1= 33\n",
      "img2= 34\n",
      "img1= 34\n",
      "img2= 35\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 32 to 35\n",
      "---\n",
      "img1= 33\n",
      "img2= 34\n",
      "img1= 34\n",
      "img2= 35\n",
      "img1= 35\n",
      "img2= 36\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 33 to 36\n",
      "---\n",
      "img1= 34\n",
      "img2= 35\n",
      "img1= 35\n",
      "img2= 36\n",
      "img1= 36\n",
      "img2= 37\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 34 to 37\n",
      "---\n",
      "img1= 35\n",
      "img2= 36\n",
      "img1= 36\n",
      "img2= 37\n",
      "img1= 37\n",
      "img2= 38\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 35 to 38\n",
      "---\n",
      "img1= 36\n",
      "img2= 37\n",
      "img1= 37\n",
      "img2= 38\n",
      "img1= 38\n",
      "img2= 39\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 36 to 39\n",
      "---\n",
      "img1= 37\n",
      "img2= 38\n",
      "img1= 38\n",
      "img2= 39\n",
      "img1= 39\n",
      "img2= 40\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 37 to 40\n",
      "---\n",
      "img1= 38\n",
      "img2= 39\n",
      "img1= 39\n",
      "img2= 40\n",
      "img1= 40\n",
      "img2= 41\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 38 to 41\n",
      "---\n",
      "img1= 39\n",
      "img2= 40\n",
      "img1= 40\n",
      "img2= 41\n",
      "img1= 41\n",
      "img2= 42\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 39 to 42\n",
      "---\n",
      "img1= 40\n",
      "img2= 41\n",
      "img1= 41\n",
      "img2= 42\n",
      "img1= 42\n",
      "img2= 43\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 40 to 43\n",
      "---\n",
      "img1= 41\n",
      "img2= 42\n",
      "img1= 42\n",
      "img2= 43\n",
      "img1= 43\n",
      "img2= 44\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 41 to 44\n",
      "---\n",
      "img1= 42\n",
      "img2= 43\n",
      "img1= 43\n",
      "img2= 44\n",
      "img1= 44\n",
      "img2= 45\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 42 to 45\n",
      "---\n",
      "img1= 43\n",
      "img2= 44\n",
      "img1= 44\n",
      "img2= 45\n",
      "img1= 45\n",
      "img2= 46\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 43 to 46\n",
      "---\n",
      "img1= 44\n",
      "img2= 45\n",
      "img1= 45\n",
      "img2= 46\n",
      "img1= 46\n",
      "img2= 47\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 44 to 47\n",
      "---\n",
      "img1= 45\n",
      "img2= 46\n",
      "img1= 46\n",
      "img2= 47\n",
      "img1= 47\n",
      "img2= 48\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 45 to 48\n",
      "---\n",
      "img1= 46\n",
      "img2= 47\n",
      "img1= 47\n",
      "img2= 48\n",
      "img1= 48\n",
      "img2= 49\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 46 to 49\n",
      "---\n",
      "img1= 47\n",
      "img2= 48\n",
      "img1= 48\n",
      "img2= 49\n",
      "img1= 49\n",
      "img2= 50\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 47 to 50\n",
      "---\n",
      "img1= 48\n",
      "img2= 49\n",
      "img1= 49\n",
      "img2= 50\n",
      "img1= 50\n",
      "img2= 51\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 48 to 51\n",
      "---\n",
      "img1= 49\n",
      "img2= 50\n",
      "img1= 50\n",
      "img2= 51\n",
      "img1= 51\n",
      "img2= 52\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 49 to 52\n",
      "---\n",
      "img1= 50\n",
      "img2= 51\n",
      "img1= 51\n",
      "img2= 52\n",
      "img1= 52\n",
      "img2= 53\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 50 to 53\n",
      "---\n",
      "img1= 51\n",
      "img2= 52\n",
      "img1= 52\n",
      "img2= 53\n",
      "img1= 53\n",
      "img2= 54\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 51 to 54\n",
      "---\n",
      "img1= 52\n",
      "img2= 53\n",
      "img1= 53\n",
      "img2= 54\n",
      "img1= 54\n",
      "img2= 55\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 52 to 55\n",
      "---\n",
      "img1= 53\n",
      "img2= 54\n",
      "img1= 54\n",
      "img2= 55\n",
      "img1= 55\n",
      "img2= 56\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 53 to 56\n",
      "---\n",
      "img1= 54\n",
      "img2= 55\n",
      "img1= 55\n",
      "img2= 56\n",
      "img1= 56\n",
      "img2= 57\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 54 to 57\n",
      "---\n",
      "img1= 55\n",
      "img2= 56\n",
      "img1= 56\n",
      "img2= 57\n",
      "img1= 57\n",
      "img2= 58\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 55 to 58\n",
      "---\n",
      "img1= 56\n",
      "img2= 57\n",
      "img1= 57\n",
      "img2= 58\n",
      "img1= 58\n",
      "img2= 59\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 56 to 59\n",
      "---\n",
      "img1= 57\n",
      "img2= 58\n",
      "img1= 58\n",
      "img2= 59\n",
      "img1= 59\n",
      "img2= 60\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 57 to 60\n",
      "---\n",
      "img1= 58\n",
      "img2= 59\n",
      "img1= 59\n",
      "img2= 60\n",
      "img1= 60\n",
      "img2= 61\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 58 to 61\n",
      "---\n",
      "img1= 59\n",
      "img2= 60\n",
      "img1= 60\n",
      "img2= 61\n",
      "img1= 61\n",
      "img2= 62\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 59 to 62\n",
      "---\n",
      "img1= 60\n",
      "img2= 61\n",
      "img1= 61\n",
      "img2= 62\n",
      "img1= 62\n",
      "img2= 63\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 60 to 63\n",
      "---\n",
      "img1= 61\n",
      "img2= 62\n",
      "img1= 62\n",
      "img2= 63\n",
      "img1= 63\n",
      "img2= 64\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 61 to 64\n",
      "---\n",
      "img1= 62\n",
      "img2= 63\n",
      "img1= 63\n",
      "img2= 64\n",
      "img1= 64\n",
      "img2= 65\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 62 to 65\n",
      "---\n",
      "img1= 63\n",
      "img2= 64\n",
      "img1= 64\n",
      "img2= 65\n",
      "img1= 65\n",
      "img2= 66\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 63 to 66\n",
      "---\n",
      "img1= 64\n",
      "img2= 65\n",
      "img1= 65\n",
      "img2= 66\n",
      "img1= 66\n",
      "img2= 67\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 64 to 67\n",
      "---\n",
      "img1= 65\n",
      "img2= 66\n",
      "img1= 66\n",
      "img2= 67\n",
      "img1= 67\n",
      "img2= 68\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 65 to 68\n",
      "---\n",
      "img1= 66\n",
      "img2= 67\n",
      "img1= 67\n",
      "img2= 68\n",
      "img1= 68\n",
      "img2= 69\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 66 to 69\n",
      "---\n",
      "img1= 67\n",
      "img2= 68\n",
      "img1= 68\n",
      "img2= 69\n",
      "img1= 69\n",
      "img2= 70\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 67 to 70\n",
      "---\n",
      "img1= 68\n",
      "img2= 69\n",
      "img1= 69\n",
      "img2= 70\n",
      "img1= 70\n",
      "img2= 71\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 68 to 71\n",
      "---\n",
      "img1= 69\n",
      "img2= 70\n",
      "img1= 70\n",
      "img2= 71\n",
      "img1= 71\n",
      "img2= 72\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 69 to 72\n",
      "---\n",
      "img1= 70\n",
      "img2= 71\n",
      "img1= 71\n",
      "img2= 72\n",
      "img1= 72\n",
      "img2= 73\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 70 to 73\n",
      "---\n",
      "img1= 71\n",
      "img2= 72\n",
      "img1= 72\n",
      "img2= 73\n",
      "img1= 73\n",
      "img2= 74\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 71 to 74\n",
      "---\n",
      "img1= 72\n",
      "img2= 73\n",
      "img1= 73\n",
      "img2= 74\n",
      "img1= 74\n",
      "img2= 75\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 72 to 75\n",
      "---\n",
      "img1= 73\n",
      "img2= 74\n",
      "img1= 74\n",
      "img2= 75\n",
      "img1= 75\n",
      "img2= 76\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 73 to 76\n",
      "---\n",
      "img1= 74\n",
      "img2= 75\n",
      "img1= 75\n",
      "img2= 76\n",
      "img1= 76\n",
      "img2= 77\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 74 to 77\n",
      "---\n",
      "img1= 75\n",
      "img2= 76\n",
      "img1= 76\n",
      "img2= 77\n",
      "img1= 77\n",
      "img2= 78\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 75 to 78\n",
      "---\n",
      "img1= 76\n",
      "img2= 77\n",
      "img1= 77\n",
      "img2= 78\n",
      "img1= 78\n",
      "img2= 79\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 76 to 79\n",
      "---\n",
      "img1= 77\n",
      "img2= 78\n",
      "img1= 78\n",
      "img2= 79\n",
      "img1= 79\n",
      "img2= 80\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 77 to 80\n",
      "---\n",
      "img1= 78\n",
      "img2= 79\n",
      "img1= 79\n",
      "img2= 80\n",
      "img1= 80\n",
      "img2= 81\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 78 to 81\n",
      "---\n",
      "img1= 79\n",
      "img2= 80\n",
      "img1= 80\n",
      "img2= 81\n",
      "img1= 81\n",
      "img2= 82\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 79 to 82\n",
      "---\n",
      "img1= 80\n",
      "img2= 81\n",
      "img1= 81\n",
      "img2= 82\n",
      "img1= 82\n",
      "img2= 83\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 80 to 83\n",
      "---\n",
      "img1= 81\n",
      "img2= 82\n",
      "img1= 82\n",
      "img2= 83\n",
      "img1= 83\n",
      "img2= 84\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 81 to 84\n",
      "---\n",
      "img1= 82\n",
      "img2= 83\n",
      "img1= 83\n",
      "img2= 84\n",
      "img1= 84\n",
      "img2= 85\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 82 to 85\n",
      "---\n",
      "img1= 83\n",
      "img2= 84\n",
      "img1= 84\n",
      "img2= 85\n",
      "img1= 85\n",
      "img2= 86\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 83 to 86\n",
      "---\n",
      "img1= 84\n",
      "img2= 85\n",
      "img1= 85\n",
      "img2= 86\n",
      "img1= 86\n",
      "img2= 87\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 84 to 87\n",
      "---\n",
      "img1= 85\n",
      "img2= 86\n",
      "img1= 86\n",
      "img2= 87\n",
      "img1= 87\n",
      "img2= 88\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 85 to 88\n",
      "---\n",
      "img1= 86\n",
      "img2= 87\n",
      "img1= 87\n",
      "img2= 88\n",
      "img1= 88\n",
      "img2= 89\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 86 to 89\n",
      "---\n",
      "img1= 87\n",
      "img2= 88\n",
      "img1= 88\n",
      "img2= 89\n",
      "img1= 89\n",
      "img2= 90\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 87 to 90\n",
      "---\n",
      "img1= 88\n",
      "img2= 89\n",
      "img1= 89\n",
      "img2= 90\n",
      "img1= 90\n",
      "img2= 91\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 88 to 91\n",
      "---\n",
      "img1= 89\n",
      "img2= 90\n",
      "img1= 90\n",
      "img2= 91\n",
      "img1= 91\n",
      "img2= 92\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 89 to 92\n",
      "---\n",
      "img1= 90\n",
      "img2= 91\n",
      "img1= 91\n",
      "img2= 92\n",
      "img1= 92\n",
      "img2= 93\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 90 to 93\n",
      "---\n",
      "img1= 91\n",
      "img2= 92\n",
      "img1= 92\n",
      "img2= 93\n",
      "img1= 93\n",
      "img2= 94\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 91 to 94\n",
      "---\n",
      "img1= 92\n",
      "img2= 93\n",
      "img1= 93\n",
      "img2= 94\n",
      "img1= 94\n",
      "img2= 95\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 92 to 95\n",
      "---\n",
      "img1= 93\n",
      "img2= 94\n",
      "img1= 94\n",
      "img2= 95\n",
      "img1= 95\n",
      "img2= 96\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 93 to 96\n",
      "---\n",
      "img1= 94\n",
      "img2= 95\n",
      "img1= 95\n",
      "img2= 96\n",
      "img1= 96\n",
      "img2= 97\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 94 to 97\n",
      "---\n",
      "img1= 95\n",
      "img2= 96\n",
      "img1= 96\n",
      "img2= 97\n",
      "img1= 97\n",
      "img2= 98\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 95 to 98\n",
      "---\n",
      "img1= 96\n",
      "img2= 97\n",
      "img1= 97\n",
      "img2= 98\n",
      "img1= 98\n",
      "img2= 99\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 96 to 99\n",
      "---\n",
      "img1= 97\n",
      "img2= 98\n",
      "img1= 98\n",
      "img2= 99\n",
      "img1= 99\n",
      "img2= 100\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 97 to 100\n",
      "---\n",
      "img1= 98\n",
      "img2= 99\n",
      "img1= 99\n",
      "img2= 100\n",
      "img1= 100\n",
      "img2= 101\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 98 to 101\n",
      "---\n",
      "img1= 99\n",
      "img2= 100\n",
      "img1= 100\n",
      "img2= 101\n",
      "img1= 101\n",
      "img2= 102\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 99 to 102\n",
      "---\n",
      "img1= 100\n",
      "img2= 101\n",
      "img1= 101\n",
      "img2= 102\n",
      "img1= 102\n",
      "img2= 103\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 100 to 103\n",
      "---\n",
      "img1= 101\n",
      "img2= 102\n",
      "img1= 102\n",
      "img2= 103\n",
      "img1= 103\n",
      "img2= 104\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 101 to 104\n",
      "---\n",
      "img1= 102\n",
      "img2= 103\n",
      "img1= 103\n",
      "img2= 104\n",
      "img1= 104\n",
      "img2= 105\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 102 to 105\n",
      "---\n",
      "img1= 103\n",
      "img2= 104\n",
      "img1= 104\n",
      "img2= 105\n",
      "img1= 105\n",
      "img2= 106\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 103 to 106\n",
      "---\n",
      "img1= 104\n",
      "img2= 105\n",
      "img1= 105\n",
      "img2= 106\n",
      "img1= 106\n",
      "img2= 107\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 104 to 107\n",
      "---\n",
      "img1= 105\n",
      "img2= 106\n",
      "img1= 106\n",
      "img2= 107\n",
      "img1= 107\n",
      "img2= 108\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 105 to 108\n",
      "---\n",
      "img1= 106\n",
      "img2= 107\n",
      "img1= 107\n",
      "img2= 108\n",
      "img1= 108\n",
      "img2= 109\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 106 to 109\n",
      "---\n",
      "img1= 107\n",
      "img2= 108\n",
      "img1= 108\n",
      "img2= 109\n",
      "img1= 109\n",
      "img2= 110\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 107 to 110\n",
      "---\n",
      "img1= 108\n",
      "img2= 109\n",
      "img1= 109\n",
      "img2= 110\n",
      "img1= 110\n",
      "img2= 111\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 108 to 111\n",
      "---\n",
      "img1= 109\n",
      "img2= 110\n",
      "img1= 110\n",
      "img2= 111\n",
      "img1= 111\n",
      "img2= 112\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 109 to 112\n",
      "---\n",
      "img1= 110\n",
      "img2= 111\n",
      "img1= 111\n",
      "img2= 112\n",
      "img1= 112\n",
      "img2= 113\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 110 to 113\n",
      "---\n",
      "img1= 111\n",
      "img2= 112\n",
      "img1= 112\n",
      "img2= 113\n",
      "img1= 113\n",
      "img2= 114\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 111 to 114\n",
      "---\n",
      "img1= 112\n",
      "img2= 113\n",
      "img1= 113\n",
      "img2= 114\n",
      "img1= 114\n",
      "img2= 115\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 112 to 115\n",
      "---\n",
      "img1= 113\n",
      "img2= 114\n",
      "img1= 114\n",
      "img2= 115\n",
      "img1= 115\n",
      "img2= 116\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 113 to 116\n",
      "---\n",
      "img1= 114\n",
      "img2= 115\n",
      "img1= 115\n",
      "img2= 116\n",
      "img1= 116\n",
      "img2= 117\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 114 to 117\n",
      "---\n",
      "img1= 115\n",
      "img2= 116\n",
      "img1= 116\n",
      "img2= 117\n",
      "img1= 117\n",
      "img2= 118\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 115 to 118\n",
      "---\n",
      "img1= 116\n",
      "img2= 117\n",
      "img1= 117\n",
      "img2= 118\n",
      "img1= 118\n",
      "img2= 119\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 116 to 119\n",
      "---\n",
      "img1= 117\n",
      "img2= 118\n",
      "img1= 118\n",
      "img2= 119\n",
      "img1= 119\n",
      "img2= 120\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 117 to 120\n",
      "---\n",
      "img1= 118\n",
      "img2= 119\n",
      "img1= 119\n",
      "img2= 120\n",
      "img1= 120\n",
      "img2= 121\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 118 to 121\n",
      "---\n",
      "img1= 119\n",
      "img2= 120\n",
      "img1= 120\n",
      "img2= 121\n",
      "img1= 121\n",
      "img2= 122\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 119 to 122\n",
      "---\n",
      "img1= 120\n",
      "img2= 121\n",
      "img1= 121\n",
      "img2= 122\n",
      "img1= 122\n",
      "img2= 123\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 120 to 123\n",
      "---\n",
      "img1= 121\n",
      "img2= 122\n",
      "img1= 122\n",
      "img2= 123\n",
      "img1= 123\n",
      "img2= 124\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 121 to 124\n",
      "---\n",
      "img1= 122\n",
      "img2= 123\n",
      "img1= 123\n",
      "img2= 124\n",
      "img1= 124\n",
      "img2= 125\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 122 to 125\n",
      "---\n",
      "img1= 123\n",
      "img2= 124\n",
      "img1= 124\n",
      "img2= 125\n",
      "img1= 125\n",
      "img2= 126\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 123 to 126\n",
      "---\n",
      "img1= 124\n",
      "img2= 125\n",
      "img1= 125\n",
      "img2= 126\n",
      "img1= 126\n",
      "img2= 127\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 124 to 127\n",
      "---\n",
      "img1= 125\n",
      "img2= 126\n",
      "img1= 126\n",
      "img2= 127\n",
      "img1= 127\n",
      "img2= 128\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 125 to 128\n",
      "---\n",
      "img1= 126\n",
      "img2= 127\n",
      "img1= 127\n",
      "img2= 128\n",
      "img1= 128\n",
      "img2= 129\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 126 to 129\n",
      "---\n",
      "img1= 127\n",
      "img2= 128\n",
      "img1= 128\n",
      "img2= 129\n",
      "img1= 129\n",
      "img2= 130\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 127 to 130\n",
      "---\n",
      "img1= 128\n",
      "img2= 129\n",
      "img1= 129\n",
      "img2= 130\n",
      "img1= 130\n",
      "img2= 131\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 128 to 131\n",
      "---\n",
      "img1= 129\n",
      "img2= 130\n",
      "img1= 130\n",
      "img2= 131\n",
      "img1= 131\n",
      "img2= 132\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 129 to 132\n",
      "---\n",
      "img1= 130\n",
      "img2= 131\n",
      "img1= 131\n",
      "img2= 132\n",
      "img1= 132\n",
      "img2= 133\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 130 to 133\n",
      "---\n",
      "img1= 131\n",
      "img2= 132\n",
      "img1= 132\n",
      "img2= 133\n",
      "img1= 133\n",
      "img2= 134\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 131 to 134\n",
      "---\n",
      "img1= 132\n",
      "img2= 133\n",
      "img1= 133\n",
      "img2= 134\n",
      "img1= 134\n",
      "img2= 135\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 132 to 135\n",
      "---\n",
      "img1= 133\n",
      "img2= 134\n",
      "img1= 134\n",
      "img2= 135\n",
      "img1= 135\n",
      "img2= 136\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 133 to 136\n",
      "---\n",
      "img1= 134\n",
      "img2= 135\n",
      "img1= 135\n",
      "img2= 136\n",
      "img1= 136\n",
      "img2= 137\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 134 to 137\n",
      "---\n",
      "img1= 135\n",
      "img2= 136\n",
      "img1= 136\n",
      "img2= 137\n",
      "img1= 137\n",
      "img2= 138\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 135 to 138\n",
      "---\n",
      "img1= 136\n",
      "img2= 137\n",
      "img1= 137\n",
      "img2= 138\n",
      "img1= 138\n",
      "img2= 139\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 136 to 139\n",
      "---\n",
      "img1= 137\n",
      "img2= 138\n",
      "img1= 138\n",
      "img2= 139\n",
      "img1= 139\n",
      "img2= 140\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 137 to 140\n",
      "---\n",
      "img1= 138\n",
      "img2= 139\n",
      "img1= 139\n",
      "img2= 140\n",
      "img1= 140\n",
      "img2= 141\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 138 to 141\n",
      "---\n",
      "img1= 139\n",
      "img2= 140\n",
      "img1= 140\n",
      "img2= 141\n",
      "img1= 141\n",
      "img2= 142\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 139 to 142\n",
      "---\n",
      "img1= 140\n",
      "img2= 141\n",
      "img1= 141\n",
      "img2= 142\n",
      "img1= 142\n",
      "img2= 143\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 140 to 143\n",
      "---\n",
      "img1= 141\n",
      "img2= 142\n",
      "img1= 142\n",
      "img2= 143\n",
      "img1= 143\n",
      "img2= 144\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 141 to 144\n",
      "---\n",
      "img1= 142\n",
      "img2= 143\n",
      "img1= 143\n",
      "img2= 144\n",
      "img1= 144\n",
      "img2= 145\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 142 to 145\n",
      "---\n",
      "img1= 143\n",
      "img2= 144\n",
      "img1= 144\n",
      "img2= 145\n",
      "img1= 145\n",
      "img2= 146\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 143 to 146\n",
      "---\n",
      "img1= 144\n",
      "img2= 145\n",
      "img1= 145\n",
      "img2= 146\n",
      "img1= 146\n",
      "img2= 147\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 144 to 147\n",
      "---\n",
      "img1= 145\n",
      "img2= 146\n",
      "img1= 146\n",
      "img2= 147\n",
      "img1= 147\n",
      "img2= 148\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 145 to 148\n",
      "---\n",
      "img1= 146\n",
      "img2= 147\n",
      "img1= 147\n",
      "img2= 148\n",
      "img1= 148\n",
      "img2= 149\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 146 to 149\n",
      "---\n",
      "img1= 147\n",
      "img2= 148\n",
      "img1= 148\n",
      "img2= 149\n",
      "img1= 149\n",
      "img2= 150\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 147 to 150\n",
      "---\n",
      "img1= 148\n",
      "img2= 149\n",
      "img1= 149\n",
      "img2= 150\n",
      "img1= 150\n",
      "img2= 151\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 148 to 151\n",
      "---\n",
      "img1= 149\n",
      "img2= 150\n",
      "img1= 150\n",
      "img2= 151\n",
      "img1= 151\n",
      "img2= 152\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 149 to 152\n",
      "---\n",
      "img1= 150\n",
      "img2= 151\n",
      "img1= 151\n",
      "img2= 152\n",
      "img1= 152\n",
      "img2= 153\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 150 to 153\n",
      "---\n",
      "img1= 151\n",
      "img2= 152\n",
      "img1= 152\n",
      "img2= 153\n",
      "img1= 153\n",
      "img2= 154\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 151 to 154\n",
      "---\n",
      "img1= 152\n",
      "img2= 153\n",
      "img1= 153\n",
      "img2= 154\n",
      "img1= 154\n",
      "img2= 155\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 152 to 155\n",
      "---\n",
      "img1= 153\n",
      "img2= 154\n",
      "img1= 154\n",
      "img2= 155\n",
      "img1= 155\n",
      "img2= 156\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 153 to 156\n",
      "---\n",
      "img1= 154\n",
      "img2= 155\n",
      "img1= 155\n",
      "img2= 156\n",
      "img1= 156\n",
      "img2= 157\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 154 to 157\n",
      "---\n",
      "img1= 155\n",
      "img2= 156\n",
      "img1= 156\n",
      "img2= 157\n",
      "img1= 157\n",
      "img2= 158\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 155 to 158\n",
      "---\n",
      "img1= 156\n",
      "img2= 157\n",
      "img1= 157\n",
      "img2= 158\n",
      "img1= 158\n",
      "img2= 159\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 156 to 159\n",
      "---\n",
      "img1= 157\n",
      "img2= 158\n",
      "img1= 158\n",
      "img2= 159\n",
      "img1= 159\n",
      "img2= 160\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 157 to 160\n",
      "---\n",
      "img1= 158\n",
      "img2= 159\n",
      "img1= 159\n",
      "img2= 160\n",
      "img1= 160\n",
      "img2= 161\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 158 to 161\n",
      "---\n",
      "img1= 159\n",
      "img2= 160\n",
      "img1= 160\n",
      "img2= 161\n",
      "img1= 161\n",
      "img2= 162\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 159 to 162\n",
      "---\n",
      "img1= 160\n",
      "img2= 161\n",
      "img1= 161\n",
      "img2= 162\n",
      "img1= 162\n",
      "img2= 163\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 160 to 163\n",
      "---\n",
      "img1= 161\n",
      "img2= 162\n",
      "img1= 162\n",
      "img2= 163\n",
      "img1= 163\n",
      "img2= 164\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 161 to 164\n",
      "---\n",
      "img1= 162\n",
      "img2= 163\n",
      "img1= 163\n",
      "img2= 164\n",
      "img1= 164\n",
      "img2= 165\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 162 to 165\n",
      "---\n",
      "img1= 163\n",
      "img2= 164\n",
      "img1= 164\n",
      "img2= 165\n",
      "img1= 165\n",
      "img2= 166\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 163 to 166\n",
      "---\n",
      "img1= 164\n",
      "img2= 165\n",
      "img1= 165\n",
      "img2= 166\n",
      "img1= 166\n",
      "img2= 167\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 164 to 167\n",
      "---\n",
      "img1= 165\n",
      "img2= 166\n",
      "img1= 166\n",
      "img2= 167\n",
      "img1= 167\n",
      "img2= 168\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 165 to 168\n",
      "---\n",
      "img1= 166\n",
      "img2= 167\n",
      "img1= 167\n",
      "img2= 168\n",
      "img1= 168\n",
      "img2= 169\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 166 to 169\n",
      "---\n",
      "img1= 167\n",
      "img2= 168\n",
      "img1= 168\n",
      "img2= 169\n",
      "img1= 169\n",
      "img2= 170\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 167 to 170\n",
      "---\n",
      "img1= 168\n",
      "img2= 169\n",
      "img1= 169\n",
      "img2= 170\n",
      "img1= 170\n",
      "img2= 171\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 168 to 171\n",
      "---\n",
      "img1= 169\n",
      "img2= 170\n",
      "img1= 170\n",
      "img2= 171\n",
      "img1= 171\n",
      "img2= 172\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 169 to 172\n",
      "---\n",
      "img1= 170\n",
      "img2= 171\n",
      "img1= 171\n",
      "img2= 172\n",
      "img1= 172\n",
      "img2= 173\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 170 to 173\n",
      "---\n",
      "img1= 171\n",
      "img2= 172\n",
      "img1= 172\n",
      "img2= 173\n",
      "img1= 173\n",
      "img2= 174\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 171 to 174\n",
      "---\n",
      "img1= 172\n",
      "img2= 173\n",
      "img1= 173\n",
      "img2= 174\n",
      "img1= 174\n",
      "img2= 175\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 172 to 175\n",
      "---\n",
      "img1= 173\n",
      "img2= 174\n",
      "img1= 174\n",
      "img2= 175\n",
      "img1= 175\n",
      "img2= 176\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 173 to 176\n",
      "---\n",
      "img1= 174\n",
      "img2= 175\n",
      "img1= 175\n",
      "img2= 176\n",
      "img1= 176\n",
      "img2= 177\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 174 to 177\n",
      "---\n",
      "img1= 175\n",
      "img2= 176\n",
      "img1= 176\n",
      "img2= 177\n",
      "img1= 177\n",
      "img2= 178\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 175 to 178\n",
      "---\n",
      "img1= 176\n",
      "img2= 177\n",
      "img1= 177\n",
      "img2= 178\n",
      "img1= 178\n",
      "img2= 179\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 176 to 179\n",
      "---\n",
      "All frames processed.\n"
     ]
    }
   ],
   "execution_count": 134
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T13:43:50.573443Z",
     "start_time": "2024-10-13T13:43:50.559441Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9a3b126ac1289828",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
