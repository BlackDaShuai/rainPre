{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-14T13:32:57.973657Z",
     "start_time": "2024-10-14T13:32:57.499259Z"
    }
   },
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from cv2 import waitKey, destroyAllWindows\n",
    "from torchvision.models.optical_flow import raft_large, Raft_Large_Weights, raft_small, Raft_Small_Weights\n",
    "from torchvision.utils import flow_to_image\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 配置\n",
    "image_folder = 'overDataSet2'  # 图片文件夹路径\n",
    "output_folder = 'lightFlowOutput'  # 保存输出的光流文件夹路径\n",
    "output_PRE_folder = 'lightFlowOutputPre' # 保存输出的预测图片文件夹路径\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "os.makedirs(output_PRE_folder, exist_ok=True)\n",
    "\n",
    "# 加载模型\n",
    "weights1= Raft_Large_Weights.C_T_SKHT_K_V2\n",
    "weights2= Raft_Small_Weights.DEFAULT\n",
    "model = raft_large(weights=weights1, ).to(device)\n",
    "print(model)\n",
    "\n",
    "# 获取所有图片文件\n",
    "image_files = sorted(glob.glob(os.path.join(image_folder, '*.png')))\n",
    "# 针对数字进行排序\n",
    "image_files = sorted(image_files, key=lambda x: int((os.path.basename(x).split('.')[0]).split('_')[-1]))\n",
    "# print(image_files )\n",
    "num_frames = len(image_files)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAFT(\n",
      "  (feature_encoder): FeatureEncoder(\n",
      "    (convnormrelu): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "      (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (convnormrelu1): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (convnormrelu2): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (downsample): Identity()\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (convnormrelu1): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (convnormrelu2): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (downsample): Identity()\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (convnormrelu1): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (convnormrelu2): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (downsample): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))\n",
      "          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (convnormrelu1): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (convnormrelu2): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (downsample): Identity()\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (convnormrelu1): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (convnormrelu2): Conv2dNormActivation(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (downsample): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (convnormrelu1): Conv2dNormActivation(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (convnormrelu2): Conv2dNormActivation(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (downsample): Identity()\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (context_encoder): FeatureEncoder(\n",
      "    (convnormrelu): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (convnormrelu1): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (convnormrelu2): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (downsample): Identity()\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (convnormrelu1): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (convnormrelu2): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (downsample): Identity()\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (convnormrelu1): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (convnormrelu2): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (downsample): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (convnormrelu1): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (convnormrelu2): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (downsample): Identity()\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): ResidualBlock(\n",
      "        (convnormrelu1): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (convnormrelu2): Conv2dNormActivation(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (downsample): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): ResidualBlock(\n",
      "        (convnormrelu1): Conv2dNormActivation(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (convnormrelu2): Conv2dNormActivation(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (downsample): Identity()\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (corr_block): CorrBlock()\n",
      "  (update_block): UpdateBlock(\n",
      "    (motion_encoder): MotionEncoder(\n",
      "      (convcorr1): Conv2dNormActivation(\n",
      "        (0): Conv2d(324, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (convcorr2): Conv2dNormActivation(\n",
      "        (0): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (convflow1): Conv2dNormActivation(\n",
      "        (0): Conv2d(2, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (convflow2): Conv2dNormActivation(\n",
      "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv): Conv2dNormActivation(\n",
      "        (0): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (recurrent_block): RecurrentBlock(\n",
      "      (convgru1): ConvGRU(\n",
      "        (convz): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
      "        (convr): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
      "        (convq): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
      "      )\n",
      "      (convgru2): ConvGRU(\n",
      "        (convz): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
      "        (convr): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
      "        (convq): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
      "      )\n",
      "    )\n",
      "    (flow_head): FlowHead(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(256, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (mask_predictor): MaskPredictor(\n",
      "    (convrelu): Conv2dNormActivation(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (conv): Conv2d(256, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 232
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "特征编码器的主要作用是从图像中提取有效的特征。由于雷达回波图像与自然图像不同，你可以重点再训练该部分，以便模型更好地捕捉雷达图像的独特模式。具体建议：\n",
    "\n",
    "第一个卷积层：这一层接收输入图像，因此可以重新训练 convnormrelu 层，使其适应雷达图像中的颜色或纹理信息。\n",
    "后续的残差块（ResidualBlock）：这些层通过不同的层次学习到越来越抽象的特征。再训练这些层，可以帮助模型更好地提取雷达回波的高层次特征。"
   ],
   "id": "30dee7b442c92c19"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T13:33:01.560892Z",
     "start_time": "2024-10-14T13:33:01.531661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 设置要训练的层\n",
    "for name, param in model.named_parameters():\n",
    "    if 'convnormrelu' in name:  # 要训练的层\n",
    "        param.requires_grad = True  # 只训练这一层\n",
    "    else:\n",
    "        param.requires_grad = False  # 冻结其他层\n",
    "        \n",
    "LR = 0.0003\n",
    "entropy_loss = nn.L1Loss()\n",
    "entropy_loss.to(device)\n",
    "# optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "# TODO:写训练函数\n",
    "\n"
   ],
   "id": "5758396fedf2de46",
   "outputs": [],
   "execution_count": 233
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T12:45:08.181865Z",
     "start_time": "2024-10-14T12:43:37.455867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 帧预测函数\n",
    "def apply_flow(image, flow):\n",
    "    flow = flow.permute(0, 2, 3, 1)  # (N, H, W, 2)\n",
    "    h, w = flow.shape[1:3]\n",
    "    y_coords, x_coords = torch.meshgrid(torch.arange(h), torch.arange(w), indexing='ij')\n",
    "    y_coords, x_coords = y_coords.float(), x_coords.float()\n",
    "    y_coords, x_coords = y_coords.to(flow.device), x_coords.to(flow.device)\n",
    "    # 计算新的坐标\n",
    "    new_x_coords = x_coords - flow[:, :, :, 0]\n",
    "    new_y_coords = y_coords - flow[:, :, :, 1]\n",
    "    # 归一化坐标\n",
    "    new_x_coords = (new_x_coords / (w - 1)) * 2 - 1\n",
    "    new_y_coords = (new_y_coords / (h - 1)) * 2 - 1\n",
    "    \n",
    "    # 使用bicubic插值采样\n",
    "    grid = torch.stack([new_x_coords, new_y_coords], dim=-1)\n",
    "    warped_image = torch.nn.functional.grid_sample(image, grid, mode='bicubic', padding_mode='reflection', align_corners=True)\n",
    "    \n",
    "    mean_flow_x = flow[:, :, :, 0].mean()\n",
    "    mean_flow_y = flow[:, :, :, 1].mean()\n",
    "    print(f'mean_flow_x={mean_flow_x}, mean_flow_y={mean_flow_y}')\n",
    "    return warped_image\n",
    "\n",
    "\n",
    "\n",
    "max_flow_step = 5.0\n",
    "step = 5\n",
    "\n",
    "# 累加光流函数\n",
    "def accumulate_flow(accumulated_flow, new_flow):\n",
    "    return accumulated_flow + new_flow\n",
    "\n",
    "# 限制光流步长函数\n",
    "def limit_flow_step(flow, max_step):\n",
    "    return torch.clamp(flow, min=-max_step, max=max_step)  # 限制光流的最大步长\n",
    "\n"
   ],
   "id": "d35b22a0e34208c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241\n",
      "img1= 0\n",
      "img2= 1\n",
      "img1= 1\n",
      "img2= 2\n",
      "img1= 2\n",
      "img2= 3\n",
      "img1= 3\n",
      "img2= 4\n",
      "img1= 4\n",
      "img2= 5\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 0 to 5\n",
      "mean_flow_x=3.3959906101226807, mean_flow_y=1.3247820138931274\n",
      "---\n",
      "img1= 1\n",
      "img2= 2\n",
      "img1= 2\n",
      "img2= 3\n",
      "img1= 3\n",
      "img2= 4\n",
      "img1= 4\n",
      "img2= 5\n",
      "img1= 5\n",
      "img2= 6\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 1 to 6\n",
      "mean_flow_x=2.5793817043304443, mean_flow_y=1.3253446817398071\n",
      "---\n",
      "img1= 2\n",
      "img2= 3\n",
      "img1= 3\n",
      "img2= 4\n",
      "img1= 4\n",
      "img2= 5\n",
      "img1= 5\n",
      "img2= 6\n",
      "img1= 6\n",
      "img2= 7\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 2 to 7\n",
      "mean_flow_x=2.054450035095215, mean_flow_y=1.1756590604782104\n",
      "---\n",
      "img1= 3\n",
      "img2= 4\n",
      "img1= 4\n",
      "img2= 5\n",
      "img1= 5\n",
      "img2= 6\n",
      "img1= 6\n",
      "img2= 7\n",
      "img1= 7\n",
      "img2= 8\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 3 to 8\n",
      "mean_flow_x=0.7431689500808716, mean_flow_y=2.158536195755005\n",
      "---\n",
      "img1= 4\n",
      "img2= 5\n",
      "img1= 5\n",
      "img2= 6\n",
      "img1= 6\n",
      "img2= 7\n",
      "img1= 7\n",
      "img2= 8\n",
      "img1= 8\n",
      "img2= 9\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 4 to 9\n",
      "mean_flow_x=-0.2740216851234436, mean_flow_y=3.1362292766571045\n",
      "---\n",
      "img1= 5\n",
      "img2= 6\n",
      "img1= 6\n",
      "img2= 7\n",
      "img1= 7\n",
      "img2= 8\n",
      "img1= 8\n",
      "img2= 9\n",
      "img1= 9\n",
      "img2= 10\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 5 to 10\n",
      "mean_flow_x=2.648972749710083, mean_flow_y=2.3245935440063477\n",
      "---\n",
      "img1= 6\n",
      "img2= 7\n",
      "img1= 7\n",
      "img2= 8\n",
      "img1= 8\n",
      "img2= 9\n",
      "img1= 9\n",
      "img2= 10\n",
      "img1= 10\n",
      "img2= 11\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 6 to 11\n",
      "mean_flow_x=3.555701494216919, mean_flow_y=1.3685283660888672\n",
      "---\n",
      "img1= 7\n",
      "img2= 8\n",
      "img1= 8\n",
      "img2= 9\n",
      "img1= 9\n",
      "img2= 10\n",
      "img1= 10\n",
      "img2= 11\n",
      "img1= 11\n",
      "img2= 12\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 7 to 12\n",
      "mean_flow_x=5.013444900512695, mean_flow_y=-0.12304101884365082\n",
      "---\n",
      "img1= 8\n",
      "img2= 9\n",
      "img1= 9\n",
      "img2= 10\n",
      "img1= 10\n",
      "img2= 11\n",
      "img1= 11\n",
      "img2= 12\n",
      "img1= 12\n",
      "img2= 13\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 8 to 13\n",
      "mean_flow_x=4.812384605407715, mean_flow_y=0.41779208183288574\n",
      "---\n",
      "img1= 9\n",
      "img2= 10\n",
      "img1= 10\n",
      "img2= 11\n",
      "img1= 11\n",
      "img2= 12\n",
      "img1= 12\n",
      "img2= 13\n",
      "img1= 13\n",
      "img2= 14\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 9 to 14\n",
      "mean_flow_x=3.7208847999572754, mean_flow_y=0.359845906496048\n",
      "---\n",
      "img1= 10\n",
      "img2= 11\n",
      "img1= 11\n",
      "img2= 12\n",
      "img1= 12\n",
      "img2= 13\n",
      "img1= 13\n",
      "img2= 14\n",
      "img1= 14\n",
      "img2= 15\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 10 to 15\n",
      "mean_flow_x=2.306878089904785, mean_flow_y=1.0467184782028198\n",
      "---\n",
      "img1= 11\n",
      "img2= 12\n",
      "img1= 12\n",
      "img2= 13\n",
      "img1= 13\n",
      "img2= 14\n",
      "img1= 14\n",
      "img2= 15\n",
      "img1= 15\n",
      "img2= 16\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 11 to 16\n",
      "mean_flow_x=1.789660930633545, mean_flow_y=1.3244363069534302\n",
      "---\n",
      "img1= 12\n",
      "img2= 13\n",
      "img1= 13\n",
      "img2= 14\n",
      "img1= 14\n",
      "img2= 15\n",
      "img1= 15\n",
      "img2= 16\n",
      "img1= 16\n",
      "img2= 17\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 12 to 17\n",
      "mean_flow_x=1.0017468929290771, mean_flow_y=1.4426109790802002\n",
      "---\n",
      "img1= 13\n",
      "img2= 14\n",
      "img1= 14\n",
      "img2= 15\n",
      "img1= 15\n",
      "img2= 16\n",
      "img1= 16\n",
      "img2= 17\n",
      "img1= 17\n",
      "img2= 18\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 13 to 18\n",
      "mean_flow_x=1.418027639389038, mean_flow_y=1.3613859415054321\n",
      "---\n",
      "img1= 14\n",
      "img2= 15\n",
      "img1= 15\n",
      "img2= 16\n",
      "img1= 16\n",
      "img2= 17\n",
      "img1= 17\n",
      "img2= 18\n",
      "img1= 18\n",
      "img2= 19\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 14 to 19\n",
      "mean_flow_x=2.0733234882354736, mean_flow_y=0.6318778395652771\n",
      "---\n",
      "img1= 15\n",
      "img2= 16\n",
      "img1= 16\n",
      "img2= 17\n",
      "img1= 17\n",
      "img2= 18\n",
      "img1= 18\n",
      "img2= 19\n",
      "img1= 19\n",
      "img2= 20\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 15 to 20\n",
      "mean_flow_x=1.4381166696548462, mean_flow_y=0.9063441157341003\n",
      "---\n",
      "img1= 16\n",
      "img2= 17\n",
      "img1= 17\n",
      "img2= 18\n",
      "img1= 18\n",
      "img2= 19\n",
      "img1= 19\n",
      "img2= 20\n",
      "img1= 20\n",
      "img2= 21\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 16 to 21\n",
      "mean_flow_x=-0.25226014852523804, mean_flow_y=2.362396240234375\n",
      "---\n",
      "img1= 17\n",
      "img2= 18\n",
      "img1= 18\n",
      "img2= 19\n",
      "img1= 19\n",
      "img2= 20\n",
      "img1= 20\n",
      "img2= 21\n",
      "img1= 21\n",
      "img2= 22\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 17 to 22\n",
      "mean_flow_x=-0.6247785091400146, mean_flow_y=2.766286849975586\n",
      "---\n",
      "img1= 18\n",
      "img2= 19\n",
      "img1= 19\n",
      "img2= 20\n",
      "img1= 20\n",
      "img2= 21\n",
      "img1= 21\n",
      "img2= 22\n",
      "img1= 22\n",
      "img2= 23\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 18 to 23\n",
      "mean_flow_x=0.9807096719741821, mean_flow_y=1.8504630327224731\n",
      "---\n",
      "img1= 19\n",
      "img2= 20\n",
      "img1= 20\n",
      "img2= 21\n",
      "img1= 21\n",
      "img2= 22\n",
      "img1= 22\n",
      "img2= 23\n",
      "img1= 23\n",
      "img2= 24\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 19 to 24\n",
      "mean_flow_x=2.4807610511779785, mean_flow_y=0.5189166069030762\n",
      "---\n",
      "img1= 20\n",
      "img2= 21\n",
      "img1= 21\n",
      "img2= 22\n",
      "img1= 22\n",
      "img2= 23\n",
      "img1= 23\n",
      "img2= 24\n",
      "img1= 24\n",
      "img2= 25\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 20 to 25\n",
      "mean_flow_x=3.526170253753662, mean_flow_y=1.5349557399749756\n",
      "---\n",
      "img1= 21\n",
      "img2= 22\n",
      "img1= 22\n",
      "img2= 23\n",
      "img1= 23\n",
      "img2= 24\n",
      "img1= 24\n",
      "img2= 25\n",
      "img1= 25\n",
      "img2= 26\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 21 to 26\n",
      "mean_flow_x=2.947082757949829, mean_flow_y=1.7034720182418823\n",
      "---\n",
      "img1= 22\n",
      "img2= 23\n",
      "img1= 23\n",
      "img2= 24\n",
      "img1= 24\n",
      "img2= 25\n",
      "img1= 25\n",
      "img2= 26\n",
      "img1= 26\n",
      "img2= 27\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 22 to 27\n",
      "mean_flow_x=3.9474589824676514, mean_flow_y=1.3223689794540405\n",
      "---\n",
      "img1= 23\n",
      "img2= 24\n",
      "img1= 24\n",
      "img2= 25\n",
      "img1= 25\n",
      "img2= 26\n",
      "img1= 26\n",
      "img2= 27\n",
      "img1= 27\n",
      "img2= 28\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 23 to 28\n",
      "mean_flow_x=4.519286632537842, mean_flow_y=0.04025917872786522\n",
      "---\n",
      "img1= 24\n",
      "img2= 25\n",
      "img1= 25\n",
      "img2= 26\n",
      "img1= 26\n",
      "img2= 27\n",
      "img1= 27\n",
      "img2= 28\n",
      "img1= 28\n",
      "img2= 29\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 24 to 29\n",
      "mean_flow_x=5.67719841003418, mean_flow_y=-1.2377620935440063\n",
      "---\n",
      "img1= 25\n",
      "img2= 26\n",
      "img1= 26\n",
      "img2= 27\n",
      "img1= 27\n",
      "img2= 28\n",
      "img1= 28\n",
      "img2= 29\n",
      "img1= 29\n",
      "img2= 30\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 25 to 30\n",
      "mean_flow_x=6.929152965545654, mean_flow_y=-2.4329311847686768\n",
      "---\n",
      "img1= 26\n",
      "img2= 27\n",
      "img1= 27\n",
      "img2= 28\n",
      "img1= 28\n",
      "img2= 29\n",
      "img1= 29\n",
      "img2= 30\n",
      "img1= 30\n",
      "img2= 31\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 26 to 31\n",
      "mean_flow_x=6.637255668640137, mean_flow_y=-2.826430320739746\n",
      "---\n",
      "img1= 27\n",
      "img2= 28\n",
      "img1= 28\n",
      "img2= 29\n",
      "img1= 29\n",
      "img2= 30\n",
      "img1= 30\n",
      "img2= 31\n",
      "img1= 31\n",
      "img2= 32\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 27 to 32\n",
      "mean_flow_x=6.005046844482422, mean_flow_y=-2.5779623985290527\n",
      "---\n",
      "img1= 28\n",
      "img2= 29\n",
      "img1= 29\n",
      "img2= 30\n",
      "img1= 30\n",
      "img2= 31\n",
      "img1= 31\n",
      "img2= 32\n",
      "img1= 32\n",
      "img2= 33\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 28 to 33\n",
      "mean_flow_x=6.431224346160889, mean_flow_y=-3.029820680618286\n",
      "---\n",
      "img1= 29\n",
      "img2= 30\n",
      "img1= 30\n",
      "img2= 31\n",
      "img1= 31\n",
      "img2= 32\n",
      "img1= 32\n",
      "img2= 33\n",
      "img1= 33\n",
      "img2= 34\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 29 to 34\n",
      "mean_flow_x=6.542943477630615, mean_flow_y=-2.9591031074523926\n",
      "---\n",
      "img1= 30\n",
      "img2= 31\n",
      "img1= 31\n",
      "img2= 32\n",
      "img1= 32\n",
      "img2= 33\n",
      "img1= 33\n",
      "img2= 34\n",
      "img1= 34\n",
      "img2= 35\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 30 to 35\n",
      "mean_flow_x=6.708216190338135, mean_flow_y=-3.0285181999206543\n",
      "---\n",
      "img1= 31\n",
      "img2= 32\n",
      "img1= 32\n",
      "img2= 33\n",
      "img1= 33\n",
      "img2= 34\n",
      "img1= 34\n",
      "img2= 35\n",
      "img1= 35\n",
      "img2= 36\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 31 to 36\n",
      "mean_flow_x=6.96282958984375, mean_flow_y=-3.2711663246154785\n",
      "---\n",
      "img1= 32\n",
      "img2= 33\n",
      "img1= 33\n",
      "img2= 34\n",
      "img1= 34\n",
      "img2= 35\n",
      "img1= 35\n",
      "img2= 36\n",
      "img1= 36\n",
      "img2= 37\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 32 to 37\n",
      "mean_flow_x=6.47487211227417, mean_flow_y=-2.979602813720703\n",
      "---\n",
      "img1= 33\n",
      "img2= 34\n",
      "img1= 34\n",
      "img2= 35\n",
      "img1= 35\n",
      "img2= 36\n",
      "img1= 36\n",
      "img2= 37\n",
      "img1= 37\n",
      "img2= 38\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 33 to 38\n",
      "mean_flow_x=6.53403902053833, mean_flow_y=-3.0471675395965576\n",
      "---\n",
      "img1= 34\n",
      "img2= 35\n",
      "img1= 35\n",
      "img2= 36\n",
      "img1= 36\n",
      "img2= 37\n",
      "img1= 37\n",
      "img2= 38\n",
      "img1= 38\n",
      "img2= 39\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 34 to 39\n",
      "mean_flow_x=6.0996246337890625, mean_flow_y=-2.889294147491455\n",
      "---\n",
      "img1= 35\n",
      "img2= 36\n",
      "img1= 36\n",
      "img2= 37\n",
      "img1= 37\n",
      "img2= 38\n",
      "img1= 38\n",
      "img2= 39\n",
      "img1= 39\n",
      "img2= 40\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 35 to 40\n",
      "mean_flow_x=6.015198230743408, mean_flow_y=-3.0483791828155518\n",
      "---\n",
      "img1= 36\n",
      "img2= 37\n",
      "img1= 37\n",
      "img2= 38\n",
      "img1= 38\n",
      "img2= 39\n",
      "img1= 39\n",
      "img2= 40\n",
      "img1= 40\n",
      "img2= 41\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 36 to 41\n",
      "mean_flow_x=6.2560906410217285, mean_flow_y=-2.5860276222229004\n",
      "---\n",
      "img1= 37\n",
      "img2= 38\n",
      "img1= 38\n",
      "img2= 39\n",
      "img1= 39\n",
      "img2= 40\n",
      "img1= 40\n",
      "img2= 41\n",
      "img1= 41\n",
      "img2= 42\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 37 to 42\n",
      "mean_flow_x=6.18503999710083, mean_flow_y=-2.38558292388916\n",
      "---\n",
      "img1= 38\n",
      "img2= 39\n",
      "img1= 39\n",
      "img2= 40\n",
      "img1= 40\n",
      "img2= 41\n",
      "img1= 41\n",
      "img2= 42\n",
      "img1= 42\n",
      "img2= 43\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 38 to 43\n",
      "mean_flow_x=6.533251762390137, mean_flow_y=-2.137617588043213\n",
      "---\n",
      "img1= 39\n",
      "img2= 40\n",
      "img1= 40\n",
      "img2= 41\n",
      "img1= 41\n",
      "img2= 42\n",
      "img1= 42\n",
      "img2= 43\n",
      "img1= 43\n",
      "img2= 44\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 39 to 44\n",
      "mean_flow_x=6.348100185394287, mean_flow_y=-2.218675374984741\n",
      "---\n",
      "img1= 40\n",
      "img2= 41\n",
      "img1= 41\n",
      "img2= 42\n",
      "img1= 42\n",
      "img2= 43\n",
      "img1= 43\n",
      "img2= 44\n",
      "img1= 44\n",
      "img2= 45\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 40 to 45\n",
      "mean_flow_x=6.41489315032959, mean_flow_y=-2.0449020862579346\n",
      "---\n",
      "img1= 41\n",
      "img2= 42\n",
      "img1= 42\n",
      "img2= 43\n",
      "img1= 43\n",
      "img2= 44\n",
      "img1= 44\n",
      "img2= 45\n",
      "img1= 45\n",
      "img2= 46\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 41 to 46\n",
      "mean_flow_x=6.4348859786987305, mean_flow_y=-1.9862183332443237\n",
      "---\n",
      "img1= 42\n",
      "img2= 43\n",
      "img1= 43\n",
      "img2= 44\n",
      "img1= 44\n",
      "img2= 45\n",
      "img1= 45\n",
      "img2= 46\n",
      "img1= 46\n",
      "img2= 47\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 42 to 47\n",
      "mean_flow_x=6.799262523651123, mean_flow_y=-2.0412309169769287\n",
      "---\n",
      "img1= 43\n",
      "img2= 44\n",
      "img1= 44\n",
      "img2= 45\n",
      "img1= 45\n",
      "img2= 46\n",
      "img1= 46\n",
      "img2= 47\n",
      "img1= 47\n",
      "img2= 48\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 43 to 48\n",
      "mean_flow_x=7.036187648773193, mean_flow_y=-2.0338900089263916\n",
      "---\n",
      "img1= 44\n",
      "img2= 45\n",
      "img1= 45\n",
      "img2= 46\n",
      "img1= 46\n",
      "img2= 47\n",
      "img1= 47\n",
      "img2= 48\n",
      "img1= 48\n",
      "img2= 49\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 44 to 49\n",
      "mean_flow_x=7.384441375732422, mean_flow_y=-1.859025001525879\n",
      "---\n",
      "img1= 45\n",
      "img2= 46\n",
      "img1= 46\n",
      "img2= 47\n",
      "img1= 47\n",
      "img2= 48\n",
      "img1= 48\n",
      "img2= 49\n",
      "img1= 49\n",
      "img2= 50\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 45 to 50\n",
      "mean_flow_x=7.626584529876709, mean_flow_y=-1.317652940750122\n",
      "---\n",
      "img1= 46\n",
      "img2= 47\n",
      "img1= 47\n",
      "img2= 48\n",
      "img1= 48\n",
      "img2= 49\n",
      "img1= 49\n",
      "img2= 50\n",
      "img1= 50\n",
      "img2= 51\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 46 to 51\n",
      "mean_flow_x=7.4337849617004395, mean_flow_y=-1.1528288125991821\n",
      "---\n",
      "img1= 47\n",
      "img2= 48\n",
      "img1= 48\n",
      "img2= 49\n",
      "img1= 49\n",
      "img2= 50\n",
      "img1= 50\n",
      "img2= 51\n",
      "img1= 51\n",
      "img2= 52\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 47 to 52\n",
      "mean_flow_x=7.568865776062012, mean_flow_y=-0.7190797924995422\n",
      "---\n",
      "img1= 48\n",
      "img2= 49\n",
      "img1= 49\n",
      "img2= 50\n",
      "img1= 50\n",
      "img2= 51\n",
      "img1= 51\n",
      "img2= 52\n",
      "img1= 52\n",
      "img2= 53\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 48 to 53\n",
      "mean_flow_x=10.964761734008789, mean_flow_y=-1.2384593486785889\n",
      "---\n",
      "img1= 49\n",
      "img2= 50\n",
      "img1= 50\n",
      "img2= 51\n",
      "img1= 51\n",
      "img2= 52\n",
      "img1= 52\n",
      "img2= 53\n",
      "img1= 53\n",
      "img2= 54\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 49 to 54\n",
      "mean_flow_x=9.97633171081543, mean_flow_y=-1.3862311840057373\n",
      "---\n",
      "img1= 50\n",
      "img2= 51\n",
      "img1= 51\n",
      "img2= 52\n",
      "img1= 52\n",
      "img2= 53\n",
      "img1= 53\n",
      "img2= 54\n",
      "img1= 54\n",
      "img2= 55\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 50 to 55\n",
      "mean_flow_x=9.565640449523926, mean_flow_y=-1.0584371089935303\n",
      "---\n",
      "img1= 51\n",
      "img2= 52\n",
      "img1= 52\n",
      "img2= 53\n",
      "img1= 53\n",
      "img2= 54\n",
      "img1= 54\n",
      "img2= 55\n",
      "img1= 55\n",
      "img2= 56\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 51 to 56\n",
      "mean_flow_x=8.058890342712402, mean_flow_y=-1.2760629653930664\n",
      "---\n",
      "img1= 52\n",
      "img2= 53\n",
      "img1= 53\n",
      "img2= 54\n",
      "img1= 54\n",
      "img2= 55\n",
      "img1= 55\n",
      "img2= 56\n",
      "img1= 56\n",
      "img2= 57\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 52 to 57\n",
      "mean_flow_x=7.026890754699707, mean_flow_y=-1.2867406606674194\n",
      "---\n",
      "img1= 53\n",
      "img2= 54\n",
      "img1= 54\n",
      "img2= 55\n",
      "img1= 55\n",
      "img2= 56\n",
      "img1= 56\n",
      "img2= 57\n",
      "img1= 57\n",
      "img2= 58\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 53 to 58\n",
      "mean_flow_x=7.093104839324951, mean_flow_y=-1.6293654441833496\n",
      "---\n",
      "img1= 54\n",
      "img2= 55\n",
      "img1= 55\n",
      "img2= 56\n",
      "img1= 56\n",
      "img2= 57\n",
      "img1= 57\n",
      "img2= 58\n",
      "img1= 58\n",
      "img2= 59\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 54 to 59\n",
      "mean_flow_x=6.884495258331299, mean_flow_y=-1.9523112773895264\n",
      "---\n",
      "img1= 55\n",
      "img2= 56\n",
      "img1= 56\n",
      "img2= 57\n",
      "img1= 57\n",
      "img2= 58\n",
      "img1= 58\n",
      "img2= 59\n",
      "img1= 59\n",
      "img2= 60\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 55 to 60\n",
      "mean_flow_x=8.515657424926758, mean_flow_y=-1.8380485773086548\n",
      "---\n",
      "img1= 56\n",
      "img2= 57\n",
      "img1= 57\n",
      "img2= 58\n",
      "img1= 58\n",
      "img2= 59\n",
      "img1= 59\n",
      "img2= 60\n",
      "img1= 60\n",
      "img2= 61\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 56 to 61\n",
      "mean_flow_x=9.275907516479492, mean_flow_y=-2.0016355514526367\n",
      "---\n",
      "img1= 57\n",
      "img2= 58\n",
      "img1= 58\n",
      "img2= 59\n",
      "img1= 59\n",
      "img2= 60\n",
      "img1= 60\n",
      "img2= 61\n",
      "img1= 61\n",
      "img2= 62\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 57 to 62\n",
      "mean_flow_x=8.535027503967285, mean_flow_y=-2.023422956466675\n",
      "---\n",
      "img1= 58\n",
      "img2= 59\n",
      "img1= 59\n",
      "img2= 60\n",
      "img1= 60\n",
      "img2= 61\n",
      "img1= 61\n",
      "img2= 62\n",
      "img1= 62\n",
      "img2= 63\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 58 to 63\n",
      "mean_flow_x=7.494168758392334, mean_flow_y=-1.9423154592514038\n",
      "---\n",
      "img1= 59\n",
      "img2= 60\n",
      "img1= 60\n",
      "img2= 61\n",
      "img1= 61\n",
      "img2= 62\n",
      "img1= 62\n",
      "img2= 63\n",
      "img1= 63\n",
      "img2= 64\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 59 to 64\n",
      "mean_flow_x=7.674882888793945, mean_flow_y=-1.6926710605621338\n",
      "---\n",
      "img1= 60\n",
      "img2= 61\n",
      "img1= 61\n",
      "img2= 62\n",
      "img1= 62\n",
      "img2= 63\n",
      "img1= 63\n",
      "img2= 64\n",
      "img1= 64\n",
      "img2= 65\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 60 to 65\n",
      "mean_flow_x=7.932003021240234, mean_flow_y=-1.357621192932129\n",
      "---\n",
      "img1= 61\n",
      "img2= 62\n",
      "img1= 62\n",
      "img2= 63\n",
      "img1= 63\n",
      "img2= 64\n",
      "img1= 64\n",
      "img2= 65\n",
      "img1= 65\n",
      "img2= 66\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 61 to 66\n",
      "mean_flow_x=7.702607154846191, mean_flow_y=-1.1368178129196167\n",
      "---\n",
      "img1= 62\n",
      "img2= 63\n",
      "img1= 63\n",
      "img2= 64\n",
      "img1= 64\n",
      "img2= 65\n",
      "img1= 65\n",
      "img2= 66\n",
      "img1= 66\n",
      "img2= 67\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 62 to 67\n",
      "mean_flow_x=7.1476640701293945, mean_flow_y=-1.2350140810012817\n",
      "---\n",
      "img1= 63\n",
      "img2= 64\n",
      "img1= 64\n",
      "img2= 65\n",
      "img1= 65\n",
      "img2= 66\n",
      "img1= 66\n",
      "img2= 67\n",
      "img1= 67\n",
      "img2= 68\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 63 to 68\n",
      "mean_flow_x=7.112751483917236, mean_flow_y=-1.3477451801300049\n",
      "---\n",
      "img1= 64\n",
      "img2= 65\n",
      "img1= 65\n",
      "img2= 66\n",
      "img1= 66\n",
      "img2= 67\n",
      "img1= 67\n",
      "img2= 68\n",
      "img1= 68\n",
      "img2= 69\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 64 to 69\n",
      "mean_flow_x=7.222936630249023, mean_flow_y=-1.0113221406936646\n",
      "---\n",
      "img1= 65\n",
      "img2= 66\n",
      "img1= 66\n",
      "img2= 67\n",
      "img1= 67\n",
      "img2= 68\n",
      "img1= 68\n",
      "img2= 69\n",
      "img1= 69\n",
      "img2= 70\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 65 to 70\n",
      "mean_flow_x=7.142717361450195, mean_flow_y=-1.144045352935791\n",
      "---\n",
      "img1= 66\n",
      "img2= 67\n",
      "img1= 67\n",
      "img2= 68\n",
      "img1= 68\n",
      "img2= 69\n",
      "img1= 69\n",
      "img2= 70\n",
      "img1= 70\n",
      "img2= 71\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 66 to 71\n",
      "mean_flow_x=7.525568962097168, mean_flow_y=-1.125610113143921\n",
      "---\n",
      "img1= 67\n",
      "img2= 68\n",
      "img1= 68\n",
      "img2= 69\n",
      "img1= 69\n",
      "img2= 70\n",
      "img1= 70\n",
      "img2= 71\n",
      "img1= 71\n",
      "img2= 72\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 67 to 72\n",
      "mean_flow_x=16.28814697265625, mean_flow_y=-0.804602324962616\n",
      "---\n",
      "img1= 68\n",
      "img2= 69\n",
      "img1= 69\n",
      "img2= 70\n",
      "img1= 70\n",
      "img2= 71\n",
      "img1= 71\n",
      "img2= 72\n",
      "img1= 72\n",
      "img2= 73\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 68 to 73\n",
      "mean_flow_x=25.46938133239746, mean_flow_y=-1.6123237609863281\n",
      "---\n",
      "img1= 69\n",
      "img2= 70\n",
      "img1= 70\n",
      "img2= 71\n",
      "img1= 71\n",
      "img2= 72\n",
      "img1= 72\n",
      "img2= 73\n",
      "img1= 73\n",
      "img2= 74\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 69 to 74\n",
      "mean_flow_x=24.57196617126465, mean_flow_y=-0.40964236855506897\n",
      "---\n",
      "img1= 70\n",
      "img2= 71\n",
      "img1= 71\n",
      "img2= 72\n",
      "img1= 72\n",
      "img2= 73\n",
      "img1= 73\n",
      "img2= 74\n",
      "img1= 74\n",
      "img2= 75\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 70 to 75\n",
      "mean_flow_x=19.393033981323242, mean_flow_y=-0.32638242840766907\n",
      "---\n",
      "img1= 71\n",
      "img2= 72\n",
      "img1= 72\n",
      "img2= 73\n",
      "img1= 73\n",
      "img2= 74\n",
      "img1= 74\n",
      "img2= 75\n",
      "img1= 75\n",
      "img2= 76\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 71 to 76\n",
      "mean_flow_x=12.567353248596191, mean_flow_y=-0.5331103801727295\n",
      "---\n",
      "img1= 72\n",
      "img2= 73\n",
      "img1= 73\n",
      "img2= 74\n",
      "img1= 74\n",
      "img2= 75\n",
      "img1= 75\n",
      "img2= 76\n",
      "img1= 76\n",
      "img2= 77\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 72 to 77\n",
      "mean_flow_x=7.980739116668701, mean_flow_y=-0.46737802028656006\n",
      "---\n",
      "img1= 73\n",
      "img2= 74\n",
      "img1= 74\n",
      "img2= 75\n",
      "img1= 75\n",
      "img2= 76\n",
      "img1= 76\n",
      "img2= 77\n",
      "img1= 77\n",
      "img2= 78\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 73 to 78\n",
      "mean_flow_x=6.763164043426514, mean_flow_y=-0.7821956276893616\n",
      "---\n",
      "img1= 74\n",
      "img2= 75\n",
      "img1= 75\n",
      "img2= 76\n",
      "img1= 76\n",
      "img2= 77\n",
      "img1= 77\n",
      "img2= 78\n",
      "img1= 78\n",
      "img2= 79\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 74 to 79\n",
      "mean_flow_x=6.197087287902832, mean_flow_y=-0.8590672016143799\n",
      "---\n",
      "img1= 75\n",
      "img2= 76\n",
      "img1= 76\n",
      "img2= 77\n",
      "img1= 77\n",
      "img2= 78\n",
      "img1= 78\n",
      "img2= 79\n",
      "img1= 79\n",
      "img2= 80\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 75 to 80\n",
      "mean_flow_x=5.866086483001709, mean_flow_y=-0.3873717784881592\n",
      "---\n",
      "img1= 76\n",
      "img2= 77\n",
      "img1= 77\n",
      "img2= 78\n",
      "img1= 78\n",
      "img2= 79\n",
      "img1= 79\n",
      "img2= 80\n",
      "img1= 80\n",
      "img2= 81\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 76 to 81\n",
      "mean_flow_x=5.879157066345215, mean_flow_y=-0.5793420672416687\n",
      "---\n",
      "img1= 77\n",
      "img2= 78\n",
      "img1= 78\n",
      "img2= 79\n",
      "img1= 79\n",
      "img2= 80\n",
      "img1= 80\n",
      "img2= 81\n",
      "img1= 81\n",
      "img2= 82\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 77 to 82\n",
      "mean_flow_x=6.2165141105651855, mean_flow_y=-0.9986883997917175\n",
      "---\n",
      "img1= 78\n",
      "img2= 79\n",
      "img1= 79\n",
      "img2= 80\n",
      "img1= 80\n",
      "img2= 81\n",
      "img1= 81\n",
      "img2= 82\n",
      "img1= 82\n",
      "img2= 83\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 78 to 83\n",
      "mean_flow_x=6.56473445892334, mean_flow_y=-0.940600574016571\n",
      "---\n",
      "img1= 79\n",
      "img2= 80\n",
      "img1= 80\n",
      "img2= 81\n",
      "img1= 81\n",
      "img2= 82\n",
      "img1= 82\n",
      "img2= 83\n",
      "img1= 83\n",
      "img2= 84\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 79 to 84\n",
      "mean_flow_x=5.933493137359619, mean_flow_y=-0.6393116116523743\n",
      "---\n",
      "img1= 80\n",
      "img2= 81\n",
      "img1= 81\n",
      "img2= 82\n",
      "img1= 82\n",
      "img2= 83\n",
      "img1= 83\n",
      "img2= 84\n",
      "img1= 84\n",
      "img2= 85\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 80 to 85\n",
      "mean_flow_x=5.769518852233887, mean_flow_y=-0.5963028073310852\n",
      "---\n",
      "img1= 81\n",
      "img2= 82\n",
      "img1= 82\n",
      "img2= 83\n",
      "img1= 83\n",
      "img2= 84\n",
      "img1= 84\n",
      "img2= 85\n",
      "img1= 85\n",
      "img2= 86\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 81 to 86\n",
      "mean_flow_x=7.029578685760498, mean_flow_y=-0.502099335193634\n",
      "---\n",
      "img1= 82\n",
      "img2= 83\n",
      "img1= 83\n",
      "img2= 84\n",
      "img1= 84\n",
      "img2= 85\n",
      "img1= 85\n",
      "img2= 86\n",
      "img1= 86\n",
      "img2= 87\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 82 to 87\n",
      "mean_flow_x=6.549942970275879, mean_flow_y=-0.43669453263282776\n",
      "---\n",
      "img1= 83\n",
      "img2= 84\n",
      "img1= 84\n",
      "img2= 85\n",
      "img1= 85\n",
      "img2= 86\n",
      "img1= 86\n",
      "img2= 87\n",
      "img1= 87\n",
      "img2= 88\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 83 to 88\n",
      "mean_flow_x=6.338567733764648, mean_flow_y=-0.7395432591438293\n",
      "---\n",
      "img1= 84\n",
      "img2= 85\n",
      "img1= 85\n",
      "img2= 86\n",
      "img1= 86\n",
      "img2= 87\n",
      "img1= 87\n",
      "img2= 88\n",
      "img1= 88\n",
      "img2= 89\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 84 to 89\n",
      "mean_flow_x=5.64061975479126, mean_flow_y=-0.9298601746559143\n",
      "---\n",
      "img1= 85\n",
      "img2= 86\n",
      "img1= 86\n",
      "img2= 87\n",
      "img1= 87\n",
      "img2= 88\n",
      "img1= 88\n",
      "img2= 89\n",
      "img1= 89\n",
      "img2= 90\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 85 to 90\n",
      "mean_flow_x=5.4564208984375, mean_flow_y=-1.2814021110534668\n",
      "---\n",
      "img1= 86\n",
      "img2= 87\n",
      "img1= 87\n",
      "img2= 88\n",
      "img1= 88\n",
      "img2= 89\n",
      "img1= 89\n",
      "img2= 90\n",
      "img1= 90\n",
      "img2= 91\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 86 to 91\n",
      "mean_flow_x=5.7492170333862305, mean_flow_y=-1.3171204328536987\n",
      "---\n",
      "img1= 87\n",
      "img2= 88\n",
      "img1= 88\n",
      "img2= 89\n",
      "img1= 89\n",
      "img2= 90\n",
      "img1= 90\n",
      "img2= 91\n",
      "img1= 91\n",
      "img2= 92\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 87 to 92\n",
      "mean_flow_x=6.084105491638184, mean_flow_y=-1.6593033075332642\n",
      "---\n",
      "img1= 88\n",
      "img2= 89\n",
      "img1= 89\n",
      "img2= 90\n",
      "img1= 90\n",
      "img2= 91\n",
      "img1= 91\n",
      "img2= 92\n",
      "img1= 92\n",
      "img2= 93\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 88 to 93\n",
      "mean_flow_x=7.182575225830078, mean_flow_y=-1.6035627126693726\n",
      "---\n",
      "img1= 89\n",
      "img2= 90\n",
      "img1= 90\n",
      "img2= 91\n",
      "img1= 91\n",
      "img2= 92\n",
      "img1= 92\n",
      "img2= 93\n",
      "img1= 93\n",
      "img2= 94\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 89 to 94\n",
      "mean_flow_x=7.047285079956055, mean_flow_y=-2.1166441440582275\n",
      "---\n",
      "img1= 90\n",
      "img2= 91\n",
      "img1= 91\n",
      "img2= 92\n",
      "img1= 92\n",
      "img2= 93\n",
      "img1= 93\n",
      "img2= 94\n",
      "img1= 94\n",
      "img2= 95\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 90 to 95\n",
      "mean_flow_x=6.620419502258301, mean_flow_y=-1.8703179359436035\n",
      "---\n",
      "img1= 91\n",
      "img2= 92\n",
      "img1= 92\n",
      "img2= 93\n",
      "img1= 93\n",
      "img2= 94\n",
      "img1= 94\n",
      "img2= 95\n",
      "img1= 95\n",
      "img2= 96\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 91 to 96\n",
      "mean_flow_x=5.967739105224609, mean_flow_y=-1.5375570058822632\n",
      "---\n",
      "img1= 92\n",
      "img2= 93\n",
      "img1= 93\n",
      "img2= 94\n",
      "img1= 94\n",
      "img2= 95\n",
      "img1= 95\n",
      "img2= 96\n",
      "img1= 96\n",
      "img2= 97\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 92 to 97\n",
      "mean_flow_x=11.500528335571289, mean_flow_y=-1.1052391529083252\n",
      "---\n",
      "img1= 93\n",
      "img2= 94\n",
      "img1= 94\n",
      "img2= 95\n",
      "img1= 95\n",
      "img2= 96\n",
      "img1= 96\n",
      "img2= 97\n",
      "img1= 97\n",
      "img2= 98\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 93 to 98\n",
      "mean_flow_x=9.561612129211426, mean_flow_y=-1.248288869857788\n",
      "---\n",
      "img1= 94\n",
      "img2= 95\n",
      "img1= 95\n",
      "img2= 96\n",
      "img1= 96\n",
      "img2= 97\n",
      "img1= 97\n",
      "img2= 98\n",
      "img1= 98\n",
      "img2= 99\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 94 to 99\n",
      "mean_flow_x=8.280760765075684, mean_flow_y=-1.7375479936599731\n",
      "---\n",
      "img1= 95\n",
      "img2= 96\n",
      "img1= 96\n",
      "img2= 97\n",
      "img1= 97\n",
      "img2= 98\n",
      "img1= 98\n",
      "img2= 99\n",
      "img1= 99\n",
      "img2= 100\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 95 to 100\n",
      "mean_flow_x=10.85560131072998, mean_flow_y=0.2849045991897583\n",
      "---\n",
      "img1= 96\n",
      "img2= 97\n",
      "img1= 97\n",
      "img2= 98\n",
      "img1= 98\n",
      "img2= 99\n",
      "img1= 99\n",
      "img2= 100\n",
      "img1= 100\n",
      "img2= 101\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 96 to 101\n",
      "mean_flow_x=8.39582633972168, mean_flow_y=-0.19458593428134918\n",
      "---\n",
      "img1= 97\n",
      "img2= 98\n",
      "img1= 98\n",
      "img2= 99\n",
      "img1= 99\n",
      "img2= 100\n",
      "img1= 100\n",
      "img2= 101\n",
      "img1= 101\n",
      "img2= 102\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 97 to 102\n",
      "mean_flow_x=7.557882785797119, mean_flow_y=-0.5223188996315002\n",
      "---\n",
      "img1= 98\n",
      "img2= 99\n",
      "img1= 99\n",
      "img2= 100\n",
      "img1= 100\n",
      "img2= 101\n",
      "img1= 101\n",
      "img2= 102\n",
      "img1= 102\n",
      "img2= 103\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 98 to 103\n",
      "mean_flow_x=6.791293621063232, mean_flow_y=-0.820554792881012\n",
      "---\n",
      "img1= 99\n",
      "img2= 100\n",
      "img1= 100\n",
      "img2= 101\n",
      "img1= 101\n",
      "img2= 102\n",
      "img1= 102\n",
      "img2= 103\n",
      "img1= 103\n",
      "img2= 104\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 99 to 104\n",
      "mean_flow_x=5.86386251449585, mean_flow_y=-1.5901871919631958\n",
      "---\n",
      "img1= 100\n",
      "img2= 101\n",
      "img1= 101\n",
      "img2= 102\n",
      "img1= 102\n",
      "img2= 103\n",
      "img1= 103\n",
      "img2= 104\n",
      "img1= 104\n",
      "img2= 105\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 100 to 105\n",
      "mean_flow_x=6.50666618347168, mean_flow_y=-1.6919881105422974\n",
      "---\n",
      "img1= 101\n",
      "img2= 102\n",
      "img1= 102\n",
      "img2= 103\n",
      "img1= 103\n",
      "img2= 104\n",
      "img1= 104\n",
      "img2= 105\n",
      "img1= 105\n",
      "img2= 106\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 101 to 106\n",
      "mean_flow_x=12.425223350524902, mean_flow_y=-1.3714810609817505\n",
      "---\n",
      "img1= 102\n",
      "img2= 103\n",
      "img1= 103\n",
      "img2= 104\n",
      "img1= 104\n",
      "img2= 105\n",
      "img1= 105\n",
      "img2= 106\n",
      "img1= 106\n",
      "img2= 107\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 102 to 107\n",
      "mean_flow_x=11.283638000488281, mean_flow_y=-1.3460038900375366\n",
      "---\n",
      "img1= 103\n",
      "img2= 104\n",
      "img1= 104\n",
      "img2= 105\n",
      "img1= 105\n",
      "img2= 106\n",
      "img1= 106\n",
      "img2= 107\n",
      "img1= 107\n",
      "img2= 108\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 103 to 108\n",
      "mean_flow_x=15.35131549835205, mean_flow_y=-1.1129049062728882\n",
      "---\n",
      "img1= 104\n",
      "img2= 105\n",
      "img1= 105\n",
      "img2= 106\n",
      "img1= 106\n",
      "img2= 107\n",
      "img1= 107\n",
      "img2= 108\n",
      "img1= 108\n",
      "img2= 109\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 104 to 109\n",
      "mean_flow_x=12.736498832702637, mean_flow_y=-1.384055733680725\n",
      "---\n",
      "img1= 105\n",
      "img2= 106\n",
      "img1= 106\n",
      "img2= 107\n",
      "img1= 107\n",
      "img2= 108\n",
      "img1= 108\n",
      "img2= 109\n",
      "img1= 109\n",
      "img2= 110\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 105 to 110\n",
      "mean_flow_x=9.85647201538086, mean_flow_y=-1.677476406097412\n",
      "---\n",
      "img1= 106\n",
      "img2= 107\n",
      "img1= 107\n",
      "img2= 108\n",
      "img1= 108\n",
      "img2= 109\n",
      "img1= 109\n",
      "img2= 110\n",
      "img1= 110\n",
      "img2= 111\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 106 to 111\n",
      "mean_flow_x=9.070209503173828, mean_flow_y=-1.6040349006652832\n",
      "---\n",
      "img1= 107\n",
      "img2= 108\n",
      "img1= 108\n",
      "img2= 109\n",
      "img1= 109\n",
      "img2= 110\n",
      "img1= 110\n",
      "img2= 111\n",
      "img1= 111\n",
      "img2= 112\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 107 to 112\n",
      "mean_flow_x=7.01332950592041, mean_flow_y=-1.8447993993759155\n",
      "---\n",
      "img1= 108\n",
      "img2= 109\n",
      "img1= 109\n",
      "img2= 110\n",
      "img1= 110\n",
      "img2= 111\n",
      "img1= 111\n",
      "img2= 112\n",
      "img1= 112\n",
      "img2= 113\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 108 to 113\n",
      "mean_flow_x=6.890211582183838, mean_flow_y=-1.8880279064178467\n",
      "---\n",
      "img1= 109\n",
      "img2= 110\n",
      "img1= 110\n",
      "img2= 111\n",
      "img1= 111\n",
      "img2= 112\n",
      "img1= 112\n",
      "img2= 113\n",
      "img1= 113\n",
      "img2= 114\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 109 to 114\n",
      "mean_flow_x=6.266324043273926, mean_flow_y=-1.8630080223083496\n",
      "---\n",
      "img1= 110\n",
      "img2= 111\n",
      "img1= 111\n",
      "img2= 112\n",
      "img1= 112\n",
      "img2= 113\n",
      "img1= 113\n",
      "img2= 114\n",
      "img1= 114\n",
      "img2= 115\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 110 to 115\n",
      "mean_flow_x=5.769720554351807, mean_flow_y=-1.974037528038025\n",
      "---\n",
      "img1= 111\n",
      "img2= 112\n",
      "img1= 112\n",
      "img2= 113\n",
      "img1= 113\n",
      "img2= 114\n",
      "img1= 114\n",
      "img2= 115\n",
      "img1= 115\n",
      "img2= 116\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 111 to 116\n",
      "mean_flow_x=5.400208950042725, mean_flow_y=-1.8982881307601929\n",
      "---\n",
      "img1= 112\n",
      "img2= 113\n",
      "img1= 113\n",
      "img2= 114\n",
      "img1= 114\n",
      "img2= 115\n",
      "img1= 115\n",
      "img2= 116\n",
      "img1= 116\n",
      "img2= 117\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 112 to 117\n",
      "mean_flow_x=5.61160135269165, mean_flow_y=-1.8786495923995972\n",
      "---\n",
      "img1= 113\n",
      "img2= 114\n",
      "img1= 114\n",
      "img2= 115\n",
      "img1= 115\n",
      "img2= 116\n",
      "img1= 116\n",
      "img2= 117\n",
      "img1= 117\n",
      "img2= 118\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 113 to 118\n",
      "mean_flow_x=5.653720855712891, mean_flow_y=-2.1565325260162354\n",
      "---\n",
      "img1= 114\n",
      "img2= 115\n",
      "img1= 115\n",
      "img2= 116\n",
      "img1= 116\n",
      "img2= 117\n",
      "img1= 117\n",
      "img2= 118\n",
      "img1= 118\n",
      "img2= 119\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 114 to 119\n",
      "mean_flow_x=5.7095232009887695, mean_flow_y=-2.0810835361480713\n",
      "---\n",
      "img1= 115\n",
      "img2= 116\n",
      "img1= 116\n",
      "img2= 117\n",
      "img1= 117\n",
      "img2= 118\n",
      "img1= 118\n",
      "img2= 119\n",
      "img1= 119\n",
      "img2= 120\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 115 to 120\n",
      "mean_flow_x=5.447381019592285, mean_flow_y=-2.220219135284424\n",
      "---\n",
      "img1= 116\n",
      "img2= 117\n",
      "img1= 117\n",
      "img2= 118\n",
      "img1= 118\n",
      "img2= 119\n",
      "img1= 119\n",
      "img2= 120\n",
      "img1= 120\n",
      "img2= 121\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 116 to 121\n",
      "mean_flow_x=6.423568248748779, mean_flow_y=-1.8461283445358276\n",
      "---\n",
      "img1= 117\n",
      "img2= 118\n",
      "img1= 118\n",
      "img2= 119\n",
      "img1= 119\n",
      "img2= 120\n",
      "img1= 120\n",
      "img2= 121\n",
      "img1= 121\n",
      "img2= 122\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 117 to 122\n",
      "mean_flow_x=32.32026290893555, mean_flow_y=1.0585681200027466\n",
      "---\n",
      "img1= 118\n",
      "img2= 119\n",
      "img1= 119\n",
      "img2= 120\n",
      "img1= 120\n",
      "img2= 121\n",
      "img1= 121\n",
      "img2= 122\n",
      "img1= 122\n",
      "img2= 123\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 118 to 123\n",
      "mean_flow_x=25.537607192993164, mean_flow_y=0.28431054949760437\n",
      "---\n",
      "img1= 119\n",
      "img2= 120\n",
      "img1= 120\n",
      "img2= 121\n",
      "img1= 121\n",
      "img2= 122\n",
      "img1= 122\n",
      "img2= 123\n",
      "img1= 123\n",
      "img2= 124\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 119 to 124\n",
      "mean_flow_x=21.98052215576172, mean_flow_y=-0.911361038684845\n",
      "---\n",
      "img1= 120\n",
      "img2= 121\n",
      "img1= 121\n",
      "img2= 122\n",
      "img1= 122\n",
      "img2= 123\n",
      "img1= 123\n",
      "img2= 124\n",
      "img1= 124\n",
      "img2= 125\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 120 to 125\n",
      "mean_flow_x=13.988675117492676, mean_flow_y=-1.8235701322555542\n",
      "---\n",
      "img1= 121\n",
      "img2= 122\n",
      "img1= 122\n",
      "img2= 123\n",
      "img1= 123\n",
      "img2= 124\n",
      "img1= 124\n",
      "img2= 125\n",
      "img1= 125\n",
      "img2= 126\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 121 to 126\n",
      "mean_flow_x=7.364027976989746, mean_flow_y=-1.7408435344696045\n",
      "---\n",
      "img1= 122\n",
      "img2= 123\n",
      "img1= 123\n",
      "img2= 124\n",
      "img1= 124\n",
      "img2= 125\n",
      "img1= 125\n",
      "img2= 126\n",
      "img1= 126\n",
      "img2= 127\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 122 to 127\n",
      "mean_flow_x=6.42561149597168, mean_flow_y=-1.7984925508499146\n",
      "---\n",
      "img1= 123\n",
      "img2= 124\n",
      "img1= 124\n",
      "img2= 125\n",
      "img1= 125\n",
      "img2= 126\n",
      "img1= 126\n",
      "img2= 127\n",
      "img1= 127\n",
      "img2= 128\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 123 to 128\n",
      "mean_flow_x=7.142129898071289, mean_flow_y=-0.83852618932724\n",
      "---\n",
      "img1= 124\n",
      "img2= 125\n",
      "img1= 125\n",
      "img2= 126\n",
      "img1= 126\n",
      "img2= 127\n",
      "img1= 127\n",
      "img2= 128\n",
      "img1= 128\n",
      "img2= 129\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 124 to 129\n",
      "mean_flow_x=6.450494766235352, mean_flow_y=-0.7770108580589294\n",
      "---\n",
      "img1= 125\n",
      "img2= 126\n",
      "img1= 126\n",
      "img2= 127\n",
      "img1= 127\n",
      "img2= 128\n",
      "img1= 128\n",
      "img2= 129\n",
      "img1= 129\n",
      "img2= 130\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 125 to 130\n",
      "mean_flow_x=6.025433540344238, mean_flow_y=-0.5811169147491455\n",
      "---\n",
      "img1= 126\n",
      "img2= 127\n",
      "img1= 127\n",
      "img2= 128\n",
      "img1= 128\n",
      "img2= 129\n",
      "img1= 129\n",
      "img2= 130\n",
      "img1= 130\n",
      "img2= 131\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 126 to 131\n",
      "mean_flow_x=5.179378986358643, mean_flow_y=-0.8317009806632996\n",
      "---\n",
      "img1= 127\n",
      "img2= 128\n",
      "img1= 128\n",
      "img2= 129\n",
      "img1= 129\n",
      "img2= 130\n",
      "img1= 130\n",
      "img2= 131\n",
      "img1= 131\n",
      "img2= 132\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 127 to 132\n",
      "mean_flow_x=4.82607889175415, mean_flow_y=-1.787637710571289\n",
      "---\n",
      "img1= 128\n",
      "img2= 129\n",
      "img1= 129\n",
      "img2= 130\n",
      "img1= 130\n",
      "img2= 131\n",
      "img1= 131\n",
      "img2= 132\n",
      "img1= 132\n",
      "img2= 133\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 128 to 133\n",
      "mean_flow_x=4.764660835266113, mean_flow_y=-2.057487964630127\n",
      "---\n",
      "img1= 129\n",
      "img2= 130\n",
      "img1= 130\n",
      "img2= 131\n",
      "img1= 131\n",
      "img2= 132\n",
      "img1= 132\n",
      "img2= 133\n",
      "img1= 133\n",
      "img2= 134\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 129 to 134\n",
      "mean_flow_x=4.52578067779541, mean_flow_y=-2.139312982559204\n",
      "---\n",
      "img1= 130\n",
      "img2= 131\n",
      "img1= 131\n",
      "img2= 132\n",
      "img1= 132\n",
      "img2= 133\n",
      "img1= 133\n",
      "img2= 134\n",
      "img1= 134\n",
      "img2= 135\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 130 to 135\n",
      "mean_flow_x=4.484047889709473, mean_flow_y=-2.16871976852417\n",
      "---\n",
      "img1= 131\n",
      "img2= 132\n",
      "img1= 132\n",
      "img2= 133\n",
      "img1= 133\n",
      "img2= 134\n",
      "img1= 134\n",
      "img2= 135\n",
      "img1= 135\n",
      "img2= 136\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 131 to 136\n",
      "mean_flow_x=4.08636999130249, mean_flow_y=-2.268427848815918\n",
      "---\n",
      "img1= 132\n",
      "img2= 133\n",
      "img1= 133\n",
      "img2= 134\n",
      "img1= 134\n",
      "img2= 135\n",
      "img1= 135\n",
      "img2= 136\n",
      "img1= 136\n",
      "img2= 137\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 132 to 137\n",
      "mean_flow_x=5.022107124328613, mean_flow_y=-2.1913928985595703\n",
      "---\n",
      "img1= 133\n",
      "img2= 134\n",
      "img1= 134\n",
      "img2= 135\n",
      "img1= 135\n",
      "img2= 136\n",
      "img1= 136\n",
      "img2= 137\n",
      "img1= 137\n",
      "img2= 138\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 133 to 138\n",
      "mean_flow_x=5.559361934661865, mean_flow_y=-2.183171510696411\n",
      "---\n",
      "img1= 134\n",
      "img2= 135\n",
      "img1= 135\n",
      "img2= 136\n",
      "img1= 136\n",
      "img2= 137\n",
      "img1= 137\n",
      "img2= 138\n",
      "img1= 138\n",
      "img2= 139\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 134 to 139\n",
      "mean_flow_x=5.3164873123168945, mean_flow_y=-2.2116644382476807\n",
      "---\n",
      "img1= 135\n",
      "img2= 136\n",
      "img1= 136\n",
      "img2= 137\n",
      "img1= 137\n",
      "img2= 138\n",
      "img1= 138\n",
      "img2= 139\n",
      "img1= 139\n",
      "img2= 140\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 135 to 140\n",
      "mean_flow_x=5.025210380554199, mean_flow_y=-2.402052640914917\n",
      "---\n",
      "img1= 136\n",
      "img2= 137\n",
      "img1= 137\n",
      "img2= 138\n",
      "img1= 138\n",
      "img2= 139\n",
      "img1= 139\n",
      "img2= 140\n",
      "img1= 140\n",
      "img2= 141\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 136 to 141\n",
      "mean_flow_x=4.638430595397949, mean_flow_y=-2.1545374393463135\n",
      "---\n",
      "img1= 137\n",
      "img2= 138\n",
      "img1= 138\n",
      "img2= 139\n",
      "img1= 139\n",
      "img2= 140\n",
      "img1= 140\n",
      "img2= 141\n",
      "img1= 141\n",
      "img2= 142\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 137 to 142\n",
      "mean_flow_x=4.577736854553223, mean_flow_y=-2.5561561584472656\n",
      "---\n",
      "img1= 138\n",
      "img2= 139\n",
      "img1= 139\n",
      "img2= 140\n",
      "img1= 140\n",
      "img2= 141\n",
      "img1= 141\n",
      "img2= 142\n",
      "img1= 142\n",
      "img2= 143\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 138 to 143\n",
      "mean_flow_x=4.838376045227051, mean_flow_y=-2.804967164993286\n",
      "---\n",
      "img1= 139\n",
      "img2= 140\n",
      "img1= 140\n",
      "img2= 141\n",
      "img1= 141\n",
      "img2= 142\n",
      "img1= 142\n",
      "img2= 143\n",
      "img1= 143\n",
      "img2= 144\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 139 to 144\n",
      "mean_flow_x=4.4811272621154785, mean_flow_y=-2.8028604984283447\n",
      "---\n",
      "img1= 140\n",
      "img2= 141\n",
      "img1= 141\n",
      "img2= 142\n",
      "img1= 142\n",
      "img2= 143\n",
      "img1= 143\n",
      "img2= 144\n",
      "img1= 144\n",
      "img2= 145\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 140 to 145\n",
      "mean_flow_x=4.249594688415527, mean_flow_y=-2.6432507038116455\n",
      "---\n",
      "img1= 141\n",
      "img2= 142\n",
      "img1= 142\n",
      "img2= 143\n",
      "img1= 143\n",
      "img2= 144\n",
      "img1= 144\n",
      "img2= 145\n",
      "img1= 145\n",
      "img2= 146\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 141 to 146\n",
      "mean_flow_x=3.6757795810699463, mean_flow_y=-1.8894798755645752\n",
      "---\n",
      "img1= 142\n",
      "img2= 143\n",
      "img1= 143\n",
      "img2= 144\n",
      "img1= 144\n",
      "img2= 145\n",
      "img1= 145\n",
      "img2= 146\n",
      "img1= 146\n",
      "img2= 147\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 142 to 147\n",
      "mean_flow_x=3.7305121421813965, mean_flow_y=-1.7662007808685303\n",
      "---\n",
      "img1= 143\n",
      "img2= 144\n",
      "img1= 144\n",
      "img2= 145\n",
      "img1= 145\n",
      "img2= 146\n",
      "img1= 146\n",
      "img2= 147\n",
      "img1= 147\n",
      "img2= 148\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 143 to 148\n",
      "mean_flow_x=4.161909580230713, mean_flow_y=-1.7623261213302612\n",
      "---\n",
      "img1= 144\n",
      "img2= 145\n",
      "img1= 145\n",
      "img2= 146\n",
      "img1= 146\n",
      "img2= 147\n",
      "img1= 147\n",
      "img2= 148\n",
      "img1= 148\n",
      "img2= 149\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 144 to 149\n",
      "mean_flow_x=4.999817848205566, mean_flow_y=-1.7994812726974487\n",
      "---\n",
      "img1= 145\n",
      "img2= 146\n",
      "img1= 146\n",
      "img2= 147\n",
      "img1= 147\n",
      "img2= 148\n",
      "img1= 148\n",
      "img2= 149\n",
      "img1= 149\n",
      "img2= 150\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 145 to 150\n",
      "mean_flow_x=5.280782699584961, mean_flow_y=-2.5932812690734863\n",
      "---\n",
      "img1= 146\n",
      "img2= 147\n",
      "img1= 147\n",
      "img2= 148\n",
      "img1= 148\n",
      "img2= 149\n",
      "img1= 149\n",
      "img2= 150\n",
      "img1= 150\n",
      "img2= 151\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 146 to 151\n",
      "mean_flow_x=5.430044651031494, mean_flow_y=-2.974733591079712\n",
      "---\n",
      "img1= 147\n",
      "img2= 148\n",
      "img1= 148\n",
      "img2= 149\n",
      "img1= 149\n",
      "img2= 150\n",
      "img1= 150\n",
      "img2= 151\n",
      "img1= 151\n",
      "img2= 152\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 147 to 152\n",
      "mean_flow_x=5.828048229217529, mean_flow_y=-3.436037063598633\n",
      "---\n",
      "img1= 148\n",
      "img2= 149\n",
      "img1= 149\n",
      "img2= 150\n",
      "img1= 150\n",
      "img2= 151\n",
      "img1= 151\n",
      "img2= 152\n",
      "img1= 152\n",
      "img2= 153\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 148 to 153\n",
      "mean_flow_x=6.432529926300049, mean_flow_y=-3.7721288204193115\n",
      "---\n",
      "img1= 149\n",
      "img2= 150\n",
      "img1= 150\n",
      "img2= 151\n",
      "img1= 151\n",
      "img2= 152\n",
      "img1= 152\n",
      "img2= 153\n",
      "img1= 153\n",
      "img2= 154\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 149 to 154\n",
      "mean_flow_x=5.6987996101379395, mean_flow_y=-3.6341352462768555\n",
      "---\n",
      "img1= 150\n",
      "img2= 151\n",
      "img1= 151\n",
      "img2= 152\n",
      "img1= 152\n",
      "img2= 153\n",
      "img1= 153\n",
      "img2= 154\n",
      "img1= 154\n",
      "img2= 155\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 150 to 155\n",
      "mean_flow_x=5.324095726013184, mean_flow_y=-3.6951241493225098\n",
      "---\n",
      "img1= 151\n",
      "img2= 152\n",
      "img1= 152\n",
      "img2= 153\n",
      "img1= 153\n",
      "img2= 154\n",
      "img1= 154\n",
      "img2= 155\n",
      "img1= 155\n",
      "img2= 156\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 151 to 156\n",
      "mean_flow_x=4.555595874786377, mean_flow_y=-3.2186734676361084\n",
      "---\n",
      "img1= 152\n",
      "img2= 153\n",
      "img1= 153\n",
      "img2= 154\n",
      "img1= 154\n",
      "img2= 155\n",
      "img1= 155\n",
      "img2= 156\n",
      "img1= 156\n",
      "img2= 157\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 152 to 157\n",
      "mean_flow_x=4.393504619598389, mean_flow_y=-3.334594488143921\n",
      "---\n",
      "img1= 153\n",
      "img2= 154\n",
      "img1= 154\n",
      "img2= 155\n",
      "img1= 155\n",
      "img2= 156\n",
      "img1= 156\n",
      "img2= 157\n",
      "img1= 157\n",
      "img2= 158\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 153 to 158\n",
      "mean_flow_x=5.0722975730896, mean_flow_y=-2.7850542068481445\n",
      "---\n",
      "img1= 154\n",
      "img2= 155\n",
      "img1= 155\n",
      "img2= 156\n",
      "img1= 156\n",
      "img2= 157\n",
      "img1= 157\n",
      "img2= 158\n",
      "img1= 158\n",
      "img2= 159\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 154 to 159\n",
      "mean_flow_x=4.922722339630127, mean_flow_y=-2.7311370372772217\n",
      "---\n",
      "img1= 155\n",
      "img2= 156\n",
      "img1= 156\n",
      "img2= 157\n",
      "img1= 157\n",
      "img2= 158\n",
      "img1= 158\n",
      "img2= 159\n",
      "img1= 159\n",
      "img2= 160\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 155 to 160\n",
      "mean_flow_x=5.748452186584473, mean_flow_y=-3.1380343437194824\n",
      "---\n",
      "img1= 156\n",
      "img2= 157\n",
      "img1= 157\n",
      "img2= 158\n",
      "img1= 158\n",
      "img2= 159\n",
      "img1= 159\n",
      "img2= 160\n",
      "img1= 160\n",
      "img2= 161\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 156 to 161\n",
      "mean_flow_x=5.358682155609131, mean_flow_y=-3.038382053375244\n",
      "---\n",
      "img1= 157\n",
      "img2= 158\n",
      "img1= 158\n",
      "img2= 159\n",
      "img1= 159\n",
      "img2= 160\n",
      "img1= 160\n",
      "img2= 161\n",
      "img1= 161\n",
      "img2= 162\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 157 to 162\n",
      "mean_flow_x=5.554405689239502, mean_flow_y=-2.9095160961151123\n",
      "---\n",
      "img1= 158\n",
      "img2= 159\n",
      "img1= 159\n",
      "img2= 160\n",
      "img1= 160\n",
      "img2= 161\n",
      "img1= 161\n",
      "img2= 162\n",
      "img1= 162\n",
      "img2= 163\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 158 to 163\n",
      "mean_flow_x=5.38421106338501, mean_flow_y=-2.947187900543213\n",
      "---\n",
      "img1= 159\n",
      "img2= 160\n",
      "img1= 160\n",
      "img2= 161\n",
      "img1= 161\n",
      "img2= 162\n",
      "img1= 162\n",
      "img2= 163\n",
      "img1= 163\n",
      "img2= 164\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 159 to 164\n",
      "mean_flow_x=4.746227264404297, mean_flow_y=-3.1931676864624023\n",
      "---\n",
      "img1= 160\n",
      "img2= 161\n",
      "img1= 161\n",
      "img2= 162\n",
      "img1= 162\n",
      "img2= 163\n",
      "img1= 163\n",
      "img2= 164\n",
      "img1= 164\n",
      "img2= 165\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 160 to 165\n",
      "mean_flow_x=8.872932434082031, mean_flow_y=-3.5087788105010986\n",
      "---\n",
      "img1= 161\n",
      "img2= 162\n",
      "img1= 162\n",
      "img2= 163\n",
      "img1= 163\n",
      "img2= 164\n",
      "img1= 164\n",
      "img2= 165\n",
      "img1= 165\n",
      "img2= 166\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 161 to 166\n",
      "mean_flow_x=7.395174980163574, mean_flow_y=-3.41912579536438\n",
      "---\n",
      "img1= 162\n",
      "img2= 163\n",
      "img1= 163\n",
      "img2= 164\n",
      "img1= 164\n",
      "img2= 165\n",
      "img1= 165\n",
      "img2= 166\n",
      "img1= 166\n",
      "img2= 167\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 162 to 167\n",
      "mean_flow_x=6.484920501708984, mean_flow_y=-3.3074047565460205\n",
      "---\n",
      "img1= 163\n",
      "img2= 164\n",
      "img1= 164\n",
      "img2= 165\n",
      "img1= 165\n",
      "img2= 166\n",
      "img1= 166\n",
      "img2= 167\n",
      "img1= 167\n",
      "img2= 168\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 163 to 168\n",
      "mean_flow_x=5.451866626739502, mean_flow_y=-3.2234714031219482\n",
      "---\n",
      "img1= 164\n",
      "img2= 165\n",
      "img1= 165\n",
      "img2= 166\n",
      "img1= 166\n",
      "img2= 167\n",
      "img1= 167\n",
      "img2= 168\n",
      "img1= 168\n",
      "img2= 169\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 164 to 169\n",
      "mean_flow_x=4.452499866485596, mean_flow_y=-3.507233142852783\n",
      "---\n",
      "img1= 165\n",
      "img2= 166\n",
      "img1= 166\n",
      "img2= 167\n",
      "img1= 167\n",
      "img2= 168\n",
      "img1= 168\n",
      "img2= 169\n",
      "img1= 169\n",
      "img2= 170\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 165 to 170\n",
      "mean_flow_x=4.620710372924805, mean_flow_y=-3.6988625526428223\n",
      "---\n",
      "img1= 166\n",
      "img2= 167\n",
      "img1= 167\n",
      "img2= 168\n",
      "img1= 168\n",
      "img2= 169\n",
      "img1= 169\n",
      "img2= 170\n",
      "img1= 170\n",
      "img2= 171\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 166 to 171\n",
      "mean_flow_x=4.87346076965332, mean_flow_y=-3.795093297958374\n",
      "---\n",
      "img1= 167\n",
      "img2= 168\n",
      "img1= 168\n",
      "img2= 169\n",
      "img1= 169\n",
      "img2= 170\n",
      "img1= 170\n",
      "img2= 171\n",
      "img1= 171\n",
      "img2= 172\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 167 to 172\n",
      "mean_flow_x=4.935451507568359, mean_flow_y=-3.9475858211517334\n",
      "---\n",
      "img1= 168\n",
      "img2= 169\n",
      "img1= 169\n",
      "img2= 170\n",
      "img1= 170\n",
      "img2= 171\n",
      "img1= 171\n",
      "img2= 172\n",
      "img1= 172\n",
      "img2= 173\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 168 to 173\n",
      "mean_flow_x=4.8811187744140625, mean_flow_y=-3.991253137588501\n",
      "---\n",
      "img1= 169\n",
      "img2= 170\n",
      "img1= 170\n",
      "img2= 171\n",
      "img1= 171\n",
      "img2= 172\n",
      "img1= 172\n",
      "img2= 173\n",
      "img1= 173\n",
      "img2= 174\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 169 to 174\n",
      "mean_flow_x=5.229651927947998, mean_flow_y=-3.6776180267333984\n",
      "---\n",
      "img1= 170\n",
      "img2= 171\n",
      "img1= 171\n",
      "img2= 172\n",
      "img1= 172\n",
      "img2= 173\n",
      "img1= 173\n",
      "img2= 174\n",
      "img1= 174\n",
      "img2= 175\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 170 to 175\n",
      "mean_flow_x=5.0095720291137695, mean_flow_y=-3.554486036300659\n",
      "---\n",
      "img1= 171\n",
      "img2= 172\n",
      "img1= 172\n",
      "img2= 173\n",
      "img1= 173\n",
      "img2= 174\n",
      "img1= 174\n",
      "img2= 175\n",
      "img1= 175\n",
      "img2= 176\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 171 to 176\n",
      "mean_flow_x=6.002470970153809, mean_flow_y=-3.4628312587738037\n",
      "---\n",
      "img1= 172\n",
      "img2= 173\n",
      "img1= 173\n",
      "img2= 174\n",
      "img1= 174\n",
      "img2= 175\n",
      "img1= 175\n",
      "img2= 176\n",
      "img1= 176\n",
      "img2= 177\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 172 to 177\n",
      "mean_flow_x=5.647256851196289, mean_flow_y=-3.4789609909057617\n",
      "---\n",
      "img1= 173\n",
      "img2= 174\n",
      "img1= 174\n",
      "img2= 175\n",
      "img1= 175\n",
      "img2= 176\n",
      "img1= 176\n",
      "img2= 177\n",
      "img1= 177\n",
      "img2= 178\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 173 to 178\n",
      "mean_flow_x=5.391211986541748, mean_flow_y=-3.478915214538574\n",
      "---\n",
      "img1= 174\n",
      "img2= 175\n",
      "img1= 175\n",
      "img2= 176\n",
      "img1= 176\n",
      "img2= 177\n",
      "img1= 177\n",
      "img2= 178\n",
      "img1= 178\n",
      "img2= 179\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 174 to 179\n",
      "mean_flow_x=5.057561874389648, mean_flow_y=-3.4274332523345947\n",
      "---\n",
      "img1= 175\n",
      "img2= 176\n",
      "img1= 176\n",
      "img2= 177\n",
      "img1= 177\n",
      "img2= 178\n",
      "img1= 178\n",
      "img2= 179\n",
      "img1= 179\n",
      "img2= 180\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 175 to 180\n",
      "mean_flow_x=5.1600751876831055, mean_flow_y=-3.766409397125244\n",
      "---\n",
      "img1= 176\n",
      "img2= 177\n",
      "img1= 177\n",
      "img2= 178\n",
      "img1= 178\n",
      "img2= 179\n",
      "img1= 179\n",
      "img2= 180\n",
      "img1= 180\n",
      "img2= 181\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 176 to 181\n",
      "mean_flow_x=5.13421630859375, mean_flow_y=-4.248100757598877\n",
      "---\n",
      "img1= 177\n",
      "img2= 178\n",
      "img1= 178\n",
      "img2= 179\n",
      "img1= 179\n",
      "img2= 180\n",
      "img1= 180\n",
      "img2= 181\n",
      "img1= 181\n",
      "img2= 182\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 177 to 182\n",
      "mean_flow_x=5.177532196044922, mean_flow_y=-4.305121421813965\n",
      "---\n",
      "img1= 178\n",
      "img2= 179\n",
      "img1= 179\n",
      "img2= 180\n",
      "img1= 180\n",
      "img2= 181\n",
      "img1= 181\n",
      "img2= 182\n",
      "img1= 182\n",
      "img2= 183\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 178 to 183\n",
      "mean_flow_x=4.534887313842773, mean_flow_y=-3.869462013244629\n",
      "---\n",
      "img1= 179\n",
      "img2= 180\n",
      "img1= 180\n",
      "img2= 181\n",
      "img1= 181\n",
      "img2= 182\n",
      "img1= 182\n",
      "img2= 183\n",
      "img1= 183\n",
      "img2= 184\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 179 to 184\n",
      "mean_flow_x=4.3003339767456055, mean_flow_y=-3.581176280975342\n",
      "---\n",
      "img1= 180\n",
      "img2= 181\n",
      "img1= 181\n",
      "img2= 182\n",
      "img1= 182\n",
      "img2= 183\n",
      "img1= 183\n",
      "img2= 184\n",
      "img1= 184\n",
      "img2= 185\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 180 to 185\n",
      "mean_flow_x=4.0876030921936035, mean_flow_y=-3.4866538047790527\n",
      "---\n",
      "img1= 181\n",
      "img2= 182\n",
      "img1= 182\n",
      "img2= 183\n",
      "img1= 183\n",
      "img2= 184\n",
      "img1= 184\n",
      "img2= 185\n",
      "img1= 185\n",
      "img2= 186\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 181 to 186\n",
      "mean_flow_x=4.153458595275879, mean_flow_y=-3.422549247741699\n",
      "---\n",
      "img1= 182\n",
      "img2= 183\n",
      "img1= 183\n",
      "img2= 184\n",
      "img1= 184\n",
      "img2= 185\n",
      "img1= 185\n",
      "img2= 186\n",
      "img1= 186\n",
      "img2= 187\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 182 to 187\n",
      "mean_flow_x=4.031515121459961, mean_flow_y=-3.485292911529541\n",
      "---\n",
      "img1= 183\n",
      "img2= 184\n",
      "img1= 184\n",
      "img2= 185\n",
      "img1= 185\n",
      "img2= 186\n",
      "img1= 186\n",
      "img2= 187\n",
      "img1= 187\n",
      "img2= 188\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 183 to 188\n",
      "mean_flow_x=7.467445373535156, mean_flow_y=-4.048667907714844\n",
      "---\n",
      "img1= 184\n",
      "img2= 185\n",
      "img1= 185\n",
      "img2= 186\n",
      "img1= 186\n",
      "img2= 187\n",
      "img1= 187\n",
      "img2= 188\n",
      "img1= 188\n",
      "img2= 189\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 184 to 189\n",
      "mean_flow_x=6.767918109893799, mean_flow_y=-4.027581691741943\n",
      "---\n",
      "img1= 185\n",
      "img2= 186\n",
      "img1= 186\n",
      "img2= 187\n",
      "img1= 187\n",
      "img2= 188\n",
      "img1= 188\n",
      "img2= 189\n",
      "img1= 189\n",
      "img2= 190\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 185 to 190\n",
      "mean_flow_x=6.184213638305664, mean_flow_y=-4.031257152557373\n",
      "---\n",
      "img1= 186\n",
      "img2= 187\n",
      "img1= 187\n",
      "img2= 188\n",
      "img1= 188\n",
      "img2= 189\n",
      "img1= 189\n",
      "img2= 190\n",
      "img1= 190\n",
      "img2= 191\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 186 to 191\n",
      "mean_flow_x=4.934380531311035, mean_flow_y=-3.9150891304016113\n",
      "---\n",
      "img1= 187\n",
      "img2= 188\n",
      "img1= 188\n",
      "img2= 189\n",
      "img1= 189\n",
      "img2= 190\n",
      "img1= 190\n",
      "img2= 191\n",
      "img1= 191\n",
      "img2= 192\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 187 to 192\n",
      "mean_flow_x=4.08020544052124, mean_flow_y=-3.6439828872680664\n",
      "---\n",
      "img1= 188\n",
      "img2= 189\n",
      "img1= 189\n",
      "img2= 190\n",
      "img1= 190\n",
      "img2= 191\n",
      "img1= 191\n",
      "img2= 192\n",
      "img1= 192\n",
      "img2= 193\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 188 to 193\n",
      "mean_flow_x=3.9135913848876953, mean_flow_y=-3.693638324737549\n",
      "---\n",
      "img1= 189\n",
      "img2= 190\n",
      "img1= 190\n",
      "img2= 191\n",
      "img1= 191\n",
      "img2= 192\n",
      "img1= 192\n",
      "img2= 193\n",
      "img1= 193\n",
      "img2= 194\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 189 to 194\n",
      "mean_flow_x=5.33758020401001, mean_flow_y=-3.9204695224761963\n",
      "---\n",
      "img1= 190\n",
      "img2= 191\n",
      "img1= 191\n",
      "img2= 192\n",
      "img1= 192\n",
      "img2= 193\n",
      "img1= 193\n",
      "img2= 194\n",
      "img1= 194\n",
      "img2= 195\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 190 to 195\n",
      "mean_flow_x=5.04965877532959, mean_flow_y=-3.8877265453338623\n",
      "---\n",
      "img1= 191\n",
      "img2= 192\n",
      "img1= 192\n",
      "img2= 193\n",
      "img1= 193\n",
      "img2= 194\n",
      "img1= 194\n",
      "img2= 195\n",
      "img1= 195\n",
      "img2= 196\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 191 to 196\n",
      "mean_flow_x=4.496667861938477, mean_flow_y=-3.7462565898895264\n",
      "---\n",
      "img1= 192\n",
      "img2= 193\n",
      "img1= 193\n",
      "img2= 194\n",
      "img1= 194\n",
      "img2= 195\n",
      "img1= 195\n",
      "img2= 196\n",
      "img1= 196\n",
      "img2= 197\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 192 to 197\n",
      "mean_flow_x=3.8774914741516113, mean_flow_y=-3.480543851852417\n",
      "---\n",
      "img1= 193\n",
      "img2= 194\n",
      "img1= 194\n",
      "img2= 195\n",
      "img1= 195\n",
      "img2= 196\n",
      "img1= 196\n",
      "img2= 197\n",
      "img1= 197\n",
      "img2= 198\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 193 to 198\n",
      "mean_flow_x=3.394521951675415, mean_flow_y=-3.347672939300537\n",
      "---\n",
      "img1= 194\n",
      "img2= 195\n",
      "img1= 195\n",
      "img2= 196\n",
      "img1= 196\n",
      "img2= 197\n",
      "img1= 197\n",
      "img2= 198\n",
      "img1= 198\n",
      "img2= 199\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 194 to 199\n",
      "mean_flow_x=4.82609748840332, mean_flow_y=-3.923875331878662\n",
      "---\n",
      "img1= 195\n",
      "img2= 196\n",
      "img1= 196\n",
      "img2= 197\n",
      "img1= 197\n",
      "img2= 198\n",
      "img1= 198\n",
      "img2= 199\n",
      "img1= 199\n",
      "img2= 200\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 195 to 200\n",
      "mean_flow_x=4.388080596923828, mean_flow_y=-3.7655062675476074\n",
      "---\n",
      "img1= 196\n",
      "img2= 197\n",
      "img1= 197\n",
      "img2= 198\n",
      "img1= 198\n",
      "img2= 199\n",
      "img1= 199\n",
      "img2= 200\n",
      "img1= 200\n",
      "img2= 201\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 196 to 201\n",
      "mean_flow_x=3.9196054935455322, mean_flow_y=-3.5270304679870605\n",
      "---\n",
      "img1= 197\n",
      "img2= 198\n",
      "img1= 198\n",
      "img2= 199\n",
      "img1= 199\n",
      "img2= 200\n",
      "img1= 200\n",
      "img2= 201\n",
      "img1= 201\n",
      "img2= 202\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 197 to 202\n",
      "mean_flow_x=3.6510632038116455, mean_flow_y=-3.693610191345215\n",
      "---\n",
      "img1= 198\n",
      "img2= 199\n",
      "img1= 199\n",
      "img2= 200\n",
      "img1= 200\n",
      "img2= 201\n",
      "img1= 201\n",
      "img2= 202\n",
      "img1= 202\n",
      "img2= 203\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 198 to 203\n",
      "mean_flow_x=3.550633668899536, mean_flow_y=-3.90295147895813\n",
      "---\n",
      "img1= 199\n",
      "img2= 200\n",
      "img1= 200\n",
      "img2= 201\n",
      "img1= 201\n",
      "img2= 202\n",
      "img1= 202\n",
      "img2= 203\n",
      "img1= 203\n",
      "img2= 204\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 199 to 204\n",
      "mean_flow_x=3.591815710067749, mean_flow_y=-4.184773921966553\n",
      "---\n",
      "img1= 200\n",
      "img2= 201\n",
      "img1= 201\n",
      "img2= 202\n",
      "img1= 202\n",
      "img2= 203\n",
      "img1= 203\n",
      "img2= 204\n",
      "img1= 204\n",
      "img2= 205\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 200 to 205\n",
      "mean_flow_x=3.4634687900543213, mean_flow_y=-3.5438811779022217\n",
      "---\n",
      "img1= 201\n",
      "img2= 202\n",
      "img1= 202\n",
      "img2= 203\n",
      "img1= 203\n",
      "img2= 204\n",
      "img1= 204\n",
      "img2= 205\n",
      "img1= 205\n",
      "img2= 206\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 201 to 206\n",
      "mean_flow_x=3.4973671436309814, mean_flow_y=-3.2648181915283203\n",
      "---\n",
      "img1= 202\n",
      "img2= 203\n",
      "img1= 203\n",
      "img2= 204\n",
      "img1= 204\n",
      "img2= 205\n",
      "img1= 205\n",
      "img2= 206\n",
      "img1= 206\n",
      "img2= 207\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 202 to 207\n",
      "mean_flow_x=3.721214771270752, mean_flow_y=-3.5747053623199463\n",
      "---\n",
      "img1= 203\n",
      "img2= 204\n",
      "img1= 204\n",
      "img2= 205\n",
      "img1= 205\n",
      "img2= 206\n",
      "img1= 206\n",
      "img2= 207\n",
      "img1= 207\n",
      "img2= 208\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 203 to 208\n",
      "mean_flow_x=3.6698625087738037, mean_flow_y=-3.554715633392334\n",
      "---\n",
      "img1= 204\n",
      "img2= 205\n",
      "img1= 205\n",
      "img2= 206\n",
      "img1= 206\n",
      "img2= 207\n",
      "img1= 207\n",
      "img2= 208\n",
      "img1= 208\n",
      "img2= 209\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 204 to 209\n",
      "mean_flow_x=3.6396520137786865, mean_flow_y=-3.4931561946868896\n",
      "---\n",
      "img1= 205\n",
      "img2= 206\n",
      "img1= 206\n",
      "img2= 207\n",
      "img1= 207\n",
      "img2= 208\n",
      "img1= 208\n",
      "img2= 209\n",
      "img1= 209\n",
      "img2= 210\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 205 to 210\n",
      "mean_flow_x=3.6452012062072754, mean_flow_y=-3.6190578937530518\n",
      "---\n",
      "img1= 206\n",
      "img2= 207\n",
      "img1= 207\n",
      "img2= 208\n",
      "img1= 208\n",
      "img2= 209\n",
      "img1= 209\n",
      "img2= 210\n",
      "img1= 210\n",
      "img2= 211\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 206 to 211\n",
      "mean_flow_x=4.059213638305664, mean_flow_y=-3.9624297618865967\n",
      "---\n",
      "img1= 207\n",
      "img2= 208\n",
      "img1= 208\n",
      "img2= 209\n",
      "img1= 209\n",
      "img2= 210\n",
      "img1= 210\n",
      "img2= 211\n",
      "img1= 211\n",
      "img2= 212\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 207 to 212\n",
      "mean_flow_x=4.6817474365234375, mean_flow_y=-4.58891487121582\n",
      "---\n",
      "img1= 208\n",
      "img2= 209\n",
      "img1= 209\n",
      "img2= 210\n",
      "img1= 210\n",
      "img2= 211\n",
      "img1= 211\n",
      "img2= 212\n",
      "img1= 212\n",
      "img2= 213\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 208 to 213\n",
      "mean_flow_x=4.495449066162109, mean_flow_y=-4.597966194152832\n",
      "---\n",
      "img1= 209\n",
      "img2= 210\n",
      "img1= 210\n",
      "img2= 211\n",
      "img1= 211\n",
      "img2= 212\n",
      "img1= 212\n",
      "img2= 213\n",
      "img1= 213\n",
      "img2= 214\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 209 to 214\n",
      "mean_flow_x=4.147993564605713, mean_flow_y=-4.409278869628906\n",
      "---\n",
      "img1= 210\n",
      "img2= 211\n",
      "img1= 211\n",
      "img2= 212\n",
      "img1= 212\n",
      "img2= 213\n",
      "img1= 213\n",
      "img2= 214\n",
      "img1= 214\n",
      "img2= 215\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 210 to 215\n",
      "mean_flow_x=3.937899112701416, mean_flow_y=-3.9945528507232666\n",
      "---\n",
      "img1= 211\n",
      "img2= 212\n",
      "img1= 212\n",
      "img2= 213\n",
      "img1= 213\n",
      "img2= 214\n",
      "img1= 214\n",
      "img2= 215\n",
      "img1= 215\n",
      "img2= 216\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 211 to 216\n",
      "mean_flow_x=3.9210610389709473, mean_flow_y=-3.898610830307007\n",
      "---\n",
      "img1= 212\n",
      "img2= 213\n",
      "img1= 213\n",
      "img2= 214\n",
      "img1= 214\n",
      "img2= 215\n",
      "img1= 215\n",
      "img2= 216\n",
      "img1= 216\n",
      "img2= 217\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 212 to 217\n",
      "mean_flow_x=3.5670597553253174, mean_flow_y=-3.7103219032287598\n",
      "---\n",
      "img1= 213\n",
      "img2= 214\n",
      "img1= 214\n",
      "img2= 215\n",
      "img1= 215\n",
      "img2= 216\n",
      "img1= 216\n",
      "img2= 217\n",
      "img1= 217\n",
      "img2= 218\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 213 to 218\n",
      "mean_flow_x=3.6616454124450684, mean_flow_y=-3.8078269958496094\n",
      "---\n",
      "img1= 214\n",
      "img2= 215\n",
      "img1= 215\n",
      "img2= 216\n",
      "img1= 216\n",
      "img2= 217\n",
      "img1= 217\n",
      "img2= 218\n",
      "img1= 218\n",
      "img2= 219\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 214 to 219\n",
      "mean_flow_x=3.5673110485076904, mean_flow_y=-3.7910706996917725\n",
      "---\n",
      "img1= 215\n",
      "img2= 216\n",
      "img1= 216\n",
      "img2= 217\n",
      "img1= 217\n",
      "img2= 218\n",
      "img1= 218\n",
      "img2= 219\n",
      "img1= 219\n",
      "img2= 220\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 215 to 220\n",
      "mean_flow_x=5.355284690856934, mean_flow_y=-4.009024143218994\n",
      "---\n",
      "img1= 216\n",
      "img2= 217\n",
      "img1= 217\n",
      "img2= 218\n",
      "img1= 218\n",
      "img2= 219\n",
      "img1= 219\n",
      "img2= 220\n",
      "img1= 220\n",
      "img2= 221\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 216 to 221\n",
      "mean_flow_x=4.913593769073486, mean_flow_y=-3.9151835441589355\n",
      "---\n",
      "img1= 217\n",
      "img2= 218\n",
      "img1= 218\n",
      "img2= 219\n",
      "img1= 219\n",
      "img2= 220\n",
      "img1= 220\n",
      "img2= 221\n",
      "img1= 221\n",
      "img2= 222\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 217 to 222\n",
      "mean_flow_x=5.93837308883667, mean_flow_y=-3.669912576675415\n",
      "---\n",
      "img1= 218\n",
      "img2= 219\n",
      "img1= 219\n",
      "img2= 220\n",
      "img1= 220\n",
      "img2= 221\n",
      "img1= 221\n",
      "img2= 222\n",
      "img1= 222\n",
      "img2= 223\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 218 to 223\n",
      "mean_flow_x=5.569217205047607, mean_flow_y=-3.6232569217681885\n",
      "---\n",
      "img1= 219\n",
      "img2= 220\n",
      "img1= 220\n",
      "img2= 221\n",
      "img1= 221\n",
      "img2= 222\n",
      "img1= 222\n",
      "img2= 223\n",
      "img1= 223\n",
      "img2= 224\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 219 to 224\n",
      "mean_flow_x=5.342161178588867, mean_flow_y=-3.856835126876831\n",
      "---\n",
      "img1= 220\n",
      "img2= 221\n",
      "img1= 221\n",
      "img2= 222\n",
      "img1= 222\n",
      "img2= 223\n",
      "img1= 223\n",
      "img2= 224\n",
      "img1= 224\n",
      "img2= 225\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 220 to 225\n",
      "mean_flow_x=4.440252780914307, mean_flow_y=-3.7413442134857178\n",
      "---\n",
      "img1= 221\n",
      "img2= 222\n",
      "img1= 222\n",
      "img2= 223\n",
      "img1= 223\n",
      "img2= 224\n",
      "img1= 224\n",
      "img2= 225\n",
      "img1= 225\n",
      "img2= 226\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 221 to 226\n",
      "mean_flow_x=3.948634386062622, mean_flow_y=-3.7320847511291504\n",
      "---\n",
      "img1= 222\n",
      "img2= 223\n",
      "img1= 223\n",
      "img2= 224\n",
      "img1= 224\n",
      "img2= 225\n",
      "img1= 225\n",
      "img2= 226\n",
      "img1= 226\n",
      "img2= 227\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 222 to 227\n",
      "mean_flow_x=3.657362461090088, mean_flow_y=-3.338798761367798\n",
      "---\n",
      "img1= 223\n",
      "img2= 224\n",
      "img1= 224\n",
      "img2= 225\n",
      "img1= 225\n",
      "img2= 226\n",
      "img1= 226\n",
      "img2= 227\n",
      "img1= 227\n",
      "img2= 228\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 223 to 228\n",
      "mean_flow_x=3.214282751083374, mean_flow_y=-3.5217959880828857\n",
      "---\n",
      "img1= 224\n",
      "img2= 225\n",
      "img1= 225\n",
      "img2= 226\n",
      "img1= 226\n",
      "img2= 227\n",
      "img1= 227\n",
      "img2= 228\n",
      "img1= 228\n",
      "img2= 229\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 224 to 229\n",
      "mean_flow_x=3.1993165016174316, mean_flow_y=-3.2092323303222656\n",
      "---\n",
      "img1= 225\n",
      "img2= 226\n",
      "img1= 226\n",
      "img2= 227\n",
      "img1= 227\n",
      "img2= 228\n",
      "img1= 228\n",
      "img2= 229\n",
      "img1= 229\n",
      "img2= 230\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 225 to 230\n",
      "mean_flow_x=3.063796043395996, mean_flow_y=-3.360802412033081\n",
      "---\n",
      "img1= 226\n",
      "img2= 227\n",
      "img1= 227\n",
      "img2= 228\n",
      "img1= 228\n",
      "img2= 229\n",
      "img1= 229\n",
      "img2= 230\n",
      "img1= 230\n",
      "img2= 231\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 226 to 231\n",
      "mean_flow_x=3.4577813148498535, mean_flow_y=-3.1500344276428223\n",
      "---\n",
      "img1= 227\n",
      "img2= 228\n",
      "img1= 228\n",
      "img2= 229\n",
      "img1= 229\n",
      "img2= 230\n",
      "img1= 230\n",
      "img2= 231\n",
      "img1= 231\n",
      "img2= 232\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 227 to 232\n",
      "mean_flow_x=7.018620491027832, mean_flow_y=-3.5113866329193115\n",
      "---\n",
      "img1= 228\n",
      "img2= 229\n",
      "img1= 229\n",
      "img2= 230\n",
      "img1= 230\n",
      "img2= 231\n",
      "img1= 231\n",
      "img2= 232\n",
      "img1= 232\n",
      "img2= 233\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 228 to 233\n",
      "mean_flow_x=7.426023483276367, mean_flow_y=-3.542379379272461\n",
      "---\n",
      "img1= 229\n",
      "img2= 230\n",
      "img1= 230\n",
      "img2= 231\n",
      "img1= 231\n",
      "img2= 232\n",
      "img1= 232\n",
      "img2= 233\n",
      "img1= 233\n",
      "img2= 234\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 229 to 234\n",
      "mean_flow_x=7.865699768066406, mean_flow_y=-3.5809285640716553\n",
      "---\n",
      "img1= 230\n",
      "img2= 231\n",
      "img1= 231\n",
      "img2= 232\n",
      "img1= 232\n",
      "img2= 233\n",
      "img1= 233\n",
      "img2= 234\n",
      "img1= 234\n",
      "img2= 235\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 230 to 235\n",
      "mean_flow_x=8.286080360412598, mean_flow_y=-3.801964044570923\n",
      "---\n",
      "img1= 231\n",
      "img2= 232\n",
      "img1= 232\n",
      "img2= 233\n",
      "img1= 233\n",
      "img2= 234\n",
      "img1= 234\n",
      "img2= 235\n",
      "img1= 235\n",
      "img2= 236\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 231 to 236\n",
      "mean_flow_x=7.6130242347717285, mean_flow_y=-3.6060500144958496\n",
      "---\n",
      "img1= 232\n",
      "img2= 233\n",
      "img1= 233\n",
      "img2= 234\n",
      "img1= 234\n",
      "img2= 235\n",
      "img1= 235\n",
      "img2= 236\n",
      "img1= 236\n",
      "img2= 237\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 232 to 237\n",
      "mean_flow_x=5.922293663024902, mean_flow_y=-3.4078805446624756\n",
      "---\n",
      "img1= 233\n",
      "img2= 234\n",
      "img1= 234\n",
      "img2= 235\n",
      "img1= 235\n",
      "img2= 236\n",
      "img1= 236\n",
      "img2= 237\n",
      "img1= 237\n",
      "img2= 238\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 233 to 238\n",
      "mean_flow_x=6.473302841186523, mean_flow_y=-3.5732409954071045\n",
      "---\n",
      "img1= 234\n",
      "img2= 235\n",
      "img1= 235\n",
      "img2= 236\n",
      "img1= 236\n",
      "img2= 237\n",
      "img1= 237\n",
      "img2= 238\n",
      "img1= 238\n",
      "img2= 239\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 234 to 239\n",
      "mean_flow_x=5.2584309577941895, mean_flow_y=-3.3494791984558105\n",
      "---\n",
      "img1= 235\n",
      "img2= 236\n",
      "img1= 236\n",
      "img2= 237\n",
      "img1= 237\n",
      "img2= 238\n",
      "img1= 238\n",
      "img2= 239\n",
      "img1= 239\n",
      "img2= 240\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 235 to 240\n",
      "mean_flow_x=4.671545505523682, mean_flow_y=-3.1067774295806885\n",
      "---\n",
      "All frames processed.\n"
     ]
    }
   ],
   "execution_count": 226
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 开始训练\n",
    "for i in range(num_frames - step):\n",
    "    accumulated_flow = None  # 初始化累积光流为None\n",
    "    optimizer.zero_grad()  # 清除上一次迭代的梯度\n",
    "\n",
    "    for j in range(step):\n",
    "        # 加载图片\n",
    "        img1 = Image.open(image_files[i + j]).convert('RGB')\n",
    "        img2 = Image.open(image_files[i + j + 1]).convert('RGB')\n",
    "\n",
    "        img1_tensor = F.to_tensor(img1).unsqueeze(0).to(device)\n",
    "        img2_tensor = F.to_tensor(img2).unsqueeze(0).to(device)\n",
    "\n",
    "        # 进行光流预测\n",
    "        list_of_flows = model(img1_tensor, img2_tensor)\n",
    "        predicted_flows = list_of_flows[-1]  # 获取光流\n",
    "\n",
    "        if accumulated_flow is None:\n",
    "            accumulated_flow = predicted_flows * (j / 10.0)  # 初始化累积光流\n",
    "        else:\n",
    "            accumulated_flow = accumulate_flow(accumulated_flow, predicted_flows * (j / 10.0))  # 叠加光流\n",
    "        if j == step - 1:\n",
    "            img3 = Image.open(image_files[i + j + 2]).convert('RGB')\n",
    "            img3_tensor = F.to_tensor(img3).unsqueeze(0).to(device)\n",
    "\n",
    "    # 使用光流进行帧预测\n",
    "    predicted_next_frame = apply_flow(img2_tensor, accumulated_flow)\n",
    "\n",
    "    # 计算损失（光流叠加后的图像与实际图像的差异）\n",
    "    loss = entropy_loss(predicted_next_frame, img2_tensor)\n",
    "\n",
    "    # 反向传播和优化\n",
    "    loss.backward()  # 计算梯度\n",
    "    optimizer.step()  # 更新权重\n",
    "\n",
    "    print(f\"Processed frame {i} to {i+step}, loss: {loss.item()}\")\n"
   ],
   "id": "d776144baa3288ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T12:43:37.391865Z",
     "start_time": "2024-10-14T12:43:37.384866Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model = model.eval()",
   "id": "9a3b126ac1289828"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 进行光流预测\n",
    "print(num_frames)\n",
    "for i in range(num_frames - step):\n",
    "#for i in range(20):\n",
    "    accumulated_flow = None  # 每次更新i初始化累积光流为None\n",
    "    for j in range(step):\n",
    "        print('img1=',i + j)\n",
    "        print('img2=',i + j + 1)\n",
    "        img1 = Image.open(image_files[i + j]).convert('RGB')\n",
    "        img2 = Image.open(image_files[i + j + 1]).convert('RGB')\n",
    "        # if i == 10:\n",
    "        #     img1.save(f'1img{i}{j}.jpg')\n",
    "        # \n",
    "        # \n",
    "        #     img2.save(f'2img{i}{j+1}.jpg')\n",
    "\n",
    "\n",
    "        \n",
    "        img1_tensor = F.to_tensor(img1).unsqueeze(0)\n",
    "        img2_tensor = F.to_tensor(img2).unsqueeze(0)\n",
    "\n",
    "        # img1_tensor, img2_tensor = preprocess(img1_tensor, img2_tensor)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            list_of_flows = model(img1_tensor.to(device), img2_tensor.to(device))\n",
    "            predicted_flows = list_of_flows[-1].cpu()# 获取光流（一般来说最后一个最准确）\n",
    "            \n",
    "        # 限制光流移动步长\n",
    "        # predicted_flows = limit_flow_step(predicted_flows, max_flow_step)\n",
    "        \n",
    "        if accumulated_flow is None:\n",
    "            accumulated_flow = predicted_flows*(j/10.0)  # 如果是第一帧光流，初始化累积光流\n",
    "        else:\n",
    "            accumulated_flow = accumulate_flow(accumulated_flow, predicted_flows*(j/10.0))  # 叠加光流，以1/6，2/6……的方式叠加\n",
    "    \n",
    "    \n",
    "    print('shape=',predicted_flows.shape)\n",
    "\n",
    "    flow_imgs = flow_to_image(predicted_flows)\n",
    "    \n",
    "    # 保存光流结果\n",
    "    output_file = os.path.join(output_folder, f'accumulated_flow_{i:03d}_to_{i+step:03d}.png')\n",
    "    plt.imsave(output_file, flow_imgs.squeeze().permute(1, 2, 0).numpy())\n",
    "\n",
    "    print(f\"Processed frame {i} to {i+step}\")\n",
    "\n",
    "    \n",
    "    # 进行帧预测\n",
    "    #expand_pixels=20\n",
    "    #expanded_image = torch.nn.functional.pad(img2_tensor, (expand_pixels, expand_pixels, expand_pixels, expand_pixels), mode='constant', value=255)\n",
    "    # 预测\n",
    "    predicted_next_frame = apply_flow(img2_tensor, accumulated_flow)\n",
    "    # 裁剪掉扩展的部分，恢复原始大小\n",
    "    # cropped_warped_image = predicted_next_frame[:, :, expand_pixels:-expand_pixels, expand_pixels:-expand_pixels]\n",
    "    # 保存预测结果\n",
    "    output_file = os.path.join(output_PRE_folder, f'predicted{i+step+1:03d}using{i:03d}to{i+step:03d}.png')\n",
    "    predicted_next_frame = predicted_next_frame.squeeze().permute(1, 2, 0).clamp(0, 1)\n",
    "    plt.imsave(output_file, predicted_next_frame.numpy())\n",
    "    print(\"---\")\n",
    "    \n",
    "print(\"All frames processed.\")"
   ],
   "id": "ca17860a97977eeb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
