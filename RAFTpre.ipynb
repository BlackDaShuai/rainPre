{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-13T15:25:36.381826Z",
     "start_time": "2024-10-13T15:25:36.265484Z"
    }
   },
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from cv2 import waitKey, destroyAllWindows\n",
    "from torchvision.models.optical_flow import raft_large, Raft_Large_Weights, raft_small, Raft_Small_Weights\n",
    "from torchvision.utils import flow_to_image\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 配置\n",
    "image_folder = 'overDataSet1'  # 图片文件夹路径\n",
    "output_folder = 'lightFlowOutput'  # 保存输出的光流文件夹路径\n",
    "output_PRE_folder = 'lightFlowOutputPre' # 保存输出的预测图片文件夹路径\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "os.makedirs(output_PRE_folder, exist_ok=True)\n",
    "\n",
    "# 加载模型\n",
    "# weights1= Raft_Large_Weights.DEFAULT\n",
    "weights1= Raft_Large_Weights.C_T_SKHT_K_V2\n",
    "weights2= Raft_Small_Weights.DEFAULT\n",
    "model = raft_large(weights=weights1, progress=False).to(device)\n",
    "model = model.eval()\n",
    "\n",
    "# 图片预处理函数，像素点需要被8整除\n",
    "# def preprocess(img1, img2):\n",
    "#     img1 = F.resize(img1, size=[520, 960], antialias=False)\n",
    "#     img2 = F.resize(img2, size=[520, 960], antialias=False)\n",
    "#     return transforms(img1, img2)\n",
    "\n",
    "# 获取所有图片文件\n",
    "image_files = sorted(glob.glob(os.path.join(image_folder, '*.png')))\n",
    "# 针对数字进行排序\n",
    "image_files = sorted(image_files, key=lambda x: int((os.path.basename(x).split('.')[0]).split('_')[-1]))\n",
    "print(image_files )\n",
    "num_frames = len(image_files)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['overDataSet1\\\\0.PNG', 'overDataSet1\\\\1.PNG', 'overDataSet1\\\\2.PNG', 'overDataSet1\\\\3.PNG', 'overDataSet1\\\\4.PNG', 'overDataSet1\\\\5.PNG', 'overDataSet1\\\\6.PNG', 'overDataSet1\\\\7.PNG', 'overDataSet1\\\\8.PNG', 'overDataSet1\\\\9.PNG', 'overDataSet1\\\\10.PNG', 'overDataSet1\\\\11.PNG', 'overDataSet1\\\\12.PNG', 'overDataSet1\\\\13.PNG', 'overDataSet1\\\\14.PNG', 'overDataSet1\\\\15.PNG', 'overDataSet1\\\\16.PNG', 'overDataSet1\\\\17.PNG', 'overDataSet1\\\\18.PNG', 'overDataSet1\\\\19.PNG', 'overDataSet1\\\\20.PNG', 'overDataSet1\\\\21.PNG', 'overDataSet1\\\\22.PNG', 'overDataSet1\\\\23.PNG', 'overDataSet1\\\\24.PNG', 'overDataSet1\\\\25.PNG', 'overDataSet1\\\\26.PNG', 'overDataSet1\\\\27.PNG', 'overDataSet1\\\\28.PNG', 'overDataSet1\\\\29.PNG', 'overDataSet1\\\\30.PNG', 'overDataSet1\\\\31.PNG', 'overDataSet1\\\\32.PNG', 'overDataSet1\\\\33.PNG', 'overDataSet1\\\\34.PNG', 'overDataSet1\\\\35.PNG', 'overDataSet1\\\\36.PNG', 'overDataSet1\\\\37.PNG', 'overDataSet1\\\\38.PNG', 'overDataSet1\\\\39.PNG', 'overDataSet1\\\\40.PNG', 'overDataSet1\\\\41.PNG', 'overDataSet1\\\\42.PNG', 'overDataSet1\\\\43.PNG', 'overDataSet1\\\\44.PNG', 'overDataSet1\\\\45.PNG', 'overDataSet1\\\\46.PNG', 'overDataSet1\\\\47.PNG', 'overDataSet1\\\\48.PNG', 'overDataSet1\\\\49.PNG', 'overDataSet1\\\\50.PNG', 'overDataSet1\\\\51.PNG', 'overDataSet1\\\\52.PNG', 'overDataSet1\\\\53.PNG', 'overDataSet1\\\\54.PNG', 'overDataSet1\\\\55.PNG', 'overDataSet1\\\\56.PNG', 'overDataSet1\\\\57.PNG', 'overDataSet1\\\\58.PNG', 'overDataSet1\\\\59.PNG', 'overDataSet1\\\\60.PNG', 'overDataSet1\\\\61.PNG', 'overDataSet1\\\\62.PNG', 'overDataSet1\\\\63.PNG', 'overDataSet1\\\\64.PNG', 'overDataSet1\\\\65.PNG', 'overDataSet1\\\\66.PNG', 'overDataSet1\\\\67.PNG', 'overDataSet1\\\\68.PNG', 'overDataSet1\\\\69.PNG', 'overDataSet1\\\\70.PNG', 'overDataSet1\\\\71.PNG', 'overDataSet1\\\\72.PNG', 'overDataSet1\\\\73.PNG', 'overDataSet1\\\\74.PNG', 'overDataSet1\\\\75.PNG', 'overDataSet1\\\\76.PNG', 'overDataSet1\\\\77.PNG', 'overDataSet1\\\\78.PNG', 'overDataSet1\\\\79.PNG', 'overDataSet1\\\\80.PNG', 'overDataSet1\\\\81.PNG', 'overDataSet1\\\\82.PNG', 'overDataSet1\\\\83.PNG', 'overDataSet1\\\\84.PNG', 'overDataSet1\\\\85.PNG', 'overDataSet1\\\\86.PNG', 'overDataSet1\\\\87.PNG', 'overDataSet1\\\\88.PNG', 'overDataSet1\\\\89.PNG', 'overDataSet1\\\\90.PNG', 'overDataSet1\\\\91.PNG', 'overDataSet1\\\\92.PNG', 'overDataSet1\\\\93.PNG', 'overDataSet1\\\\94.PNG', 'overDataSet1\\\\95.PNG', 'overDataSet1\\\\96.PNG', 'overDataSet1\\\\97.PNG', 'overDataSet1\\\\98.PNG', 'overDataSet1\\\\99.PNG', 'overDataSet1\\\\100.PNG', 'overDataSet1\\\\101.PNG', 'overDataSet1\\\\102.PNG', 'overDataSet1\\\\103.PNG', 'overDataSet1\\\\104.PNG', 'overDataSet1\\\\105.PNG', 'overDataSet1\\\\106.PNG', 'overDataSet1\\\\107.PNG', 'overDataSet1\\\\108.PNG', 'overDataSet1\\\\109.PNG', 'overDataSet1\\\\110.PNG', 'overDataSet1\\\\111.PNG', 'overDataSet1\\\\112.PNG', 'overDataSet1\\\\113.PNG', 'overDataSet1\\\\114.PNG', 'overDataSet1\\\\115.PNG', 'overDataSet1\\\\116.PNG', 'overDataSet1\\\\117.PNG', 'overDataSet1\\\\118.PNG', 'overDataSet1\\\\119.PNG', 'overDataSet1\\\\120.PNG', 'overDataSet1\\\\121.PNG', 'overDataSet1\\\\122.PNG', 'overDataSet1\\\\123.PNG', 'overDataSet1\\\\124.PNG', 'overDataSet1\\\\125.PNG', 'overDataSet1\\\\126.PNG', 'overDataSet1\\\\127.PNG', 'overDataSet1\\\\128.PNG', 'overDataSet1\\\\129.PNG', 'overDataSet1\\\\130.PNG', 'overDataSet1\\\\131.PNG', 'overDataSet1\\\\132.PNG', 'overDataSet1\\\\133.PNG', 'overDataSet1\\\\134.PNG', 'overDataSet1\\\\135.PNG', 'overDataSet1\\\\136.PNG', 'overDataSet1\\\\137.PNG', 'overDataSet1\\\\138.PNG', 'overDataSet1\\\\139.PNG', 'overDataSet1\\\\140.PNG', 'overDataSet1\\\\141.PNG', 'overDataSet1\\\\142.PNG', 'overDataSet1\\\\143.PNG', 'overDataSet1\\\\144.PNG', 'overDataSet1\\\\145.PNG', 'overDataSet1\\\\146.PNG', 'overDataSet1\\\\147.PNG', 'overDataSet1\\\\148.PNG', 'overDataSet1\\\\149.PNG', 'overDataSet1\\\\150.PNG', 'overDataSet1\\\\151.PNG', 'overDataSet1\\\\152.PNG', 'overDataSet1\\\\153.PNG', 'overDataSet1\\\\154.PNG', 'overDataSet1\\\\155.PNG', 'overDataSet1\\\\156.PNG', 'overDataSet1\\\\157.PNG', 'overDataSet1\\\\158.PNG', 'overDataSet1\\\\159.PNG', 'overDataSet1\\\\160.PNG', 'overDataSet1\\\\161.PNG', 'overDataSet1\\\\162.PNG', 'overDataSet1\\\\163.PNG', 'overDataSet1\\\\164.PNG', 'overDataSet1\\\\165.PNG', 'overDataSet1\\\\166.PNG', 'overDataSet1\\\\167.PNG', 'overDataSet1\\\\168.PNG', 'overDataSet1\\\\169.PNG', 'overDataSet1\\\\170.PNG', 'overDataSet1\\\\171.PNG', 'overDataSet1\\\\172.PNG', 'overDataSet1\\\\173.PNG', 'overDataSet1\\\\174.PNG', 'overDataSet1\\\\175.PNG', 'overDataSet1\\\\176.PNG', 'overDataSet1\\\\177.PNG', 'overDataSet1\\\\178.PNG', 'overDataSet1\\\\179.PNG', 'overDataSet1\\\\180.PNG', 'overDataSet1\\\\181.PNG', 'overDataSet1\\\\182.PNG', 'overDataSet1\\\\183.PNG', 'overDataSet1\\\\184.PNG', 'overDataSet1\\\\185.PNG', 'overDataSet1\\\\186.PNG', 'overDataSet1\\\\187.PNG', 'overDataSet1\\\\188.PNG', 'overDataSet1\\\\189.PNG', 'overDataSet1\\\\190.PNG', 'overDataSet1\\\\191.PNG', 'overDataSet1\\\\192.PNG', 'overDataSet1\\\\193.PNG', 'overDataSet1\\\\194.PNG', 'overDataSet1\\\\195.PNG', 'overDataSet1\\\\196.PNG', 'overDataSet1\\\\197.PNG', 'overDataSet1\\\\198.PNG', 'overDataSet1\\\\199.PNG', 'overDataSet1\\\\200.PNG', 'overDataSet1\\\\201.PNG', 'overDataSet1\\\\202.PNG', 'overDataSet1\\\\203.PNG', 'overDataSet1\\\\204.PNG', 'overDataSet1\\\\205.PNG', 'overDataSet1\\\\206.PNG', 'overDataSet1\\\\207.PNG', 'overDataSet1\\\\208.PNG', 'overDataSet1\\\\209.PNG', 'overDataSet1\\\\210.PNG', 'overDataSet1\\\\211.PNG', 'overDataSet1\\\\212.PNG', 'overDataSet1\\\\213.PNG', 'overDataSet1\\\\214.PNG', 'overDataSet1\\\\215.PNG', 'overDataSet1\\\\216.PNG', 'overDataSet1\\\\217.PNG', 'overDataSet1\\\\218.PNG', 'overDataSet1\\\\219.PNG', 'overDataSet1\\\\220.PNG', 'overDataSet1\\\\221.PNG', 'overDataSet1\\\\222.PNG', 'overDataSet1\\\\223.PNG', 'overDataSet1\\\\224.PNG', 'overDataSet1\\\\225.PNG', 'overDataSet1\\\\226.PNG', 'overDataSet1\\\\227.PNG', 'overDataSet1\\\\228.PNG', 'overDataSet1\\\\229.PNG', 'overDataSet1\\\\230.PNG', 'overDataSet1\\\\231.PNG', 'overDataSet1\\\\232.PNG', 'overDataSet1\\\\233.PNG', 'overDataSet1\\\\234.PNG', 'overDataSet1\\\\235.PNG', 'overDataSet1\\\\236.PNG', 'overDataSet1\\\\237.PNG', 'overDataSet1\\\\238.PNG', 'overDataSet1\\\\239.PNG', 'overDataSet1\\\\240.PNG']\n"
     ]
    }
   ],
   "execution_count": 191
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T15:25:36.397335Z",
     "start_time": "2024-10-13T15:25:36.391335Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9a3b126ac1289828",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T15:27:02.349749Z",
     "start_time": "2024-10-13T15:25:36.462334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 帧预测函数\n",
    "def apply_flow(image, flow):\n",
    "    flow = flow.permute(0, 2, 3, 1)  # (N, H, W, 2)\n",
    "    h, w = flow.shape[1:3]\n",
    "    y_coords, x_coords = torch.meshgrid(torch.arange(h), torch.arange(w), indexing='ij')\n",
    "    y_coords, x_coords = y_coords.float(), x_coords.float()\n",
    "    y_coords, x_coords = y_coords.to(flow.device), x_coords.to(flow.device)\n",
    "    \n",
    "    # 计算新的坐标\n",
    "    new_x_coords = x_coords + flow[:, :, :, 0]\n",
    "    new_y_coords = y_coords + flow[:, :, :, 1]\n",
    "    \n",
    "    # 将坐标限制在图像边界内进行裁剪\n",
    "    new_x_coords = torch.clamp(new_x_coords, 0, w - 1)\n",
    "    new_y_coords = torch.clamp(new_y_coords, 0, h - 1)\n",
    "    # 归一化坐标\n",
    "    new_x_coords = (new_x_coords / (w - 1)) * 2 - 1\n",
    "    new_y_coords = (new_y_coords / (h - 1)) * 2 - 1\n",
    "    \n",
    "    \n",
    "    # 使用bicubic插值采样\n",
    "    grid = torch.stack([new_x_coords, new_y_coords], dim=-1)\n",
    "    warped_image = torch.nn.functional.grid_sample(image, grid, mode='bicubic', padding_mode='border', align_corners=True)\n",
    "    \n",
    "    mean_flow_x = flow[:, :, :, 0].mean()\n",
    "    mean_flow_y = flow[:, :, :, 1].mean()\n",
    "    print(f'mean_flow_x={mean_flow_x}, mean_flow_y={mean_flow_y}')\n",
    "    # if mean_flow_x > 0:  # 如果光流向右\n",
    "    #     cropped_warped_image = warped_image[:, :, :, :-int(mean_flow_x)]  # 裁剪右边\n",
    "    # else:  # 如果光流向左\n",
    "    #     cropped_warped_image = warped_image[:, :, :, int(mean_flow_x):]  # 裁剪左边\n",
    "    #     \n",
    "    # \n",
    "    # # 对结果进行裁剪（例如裁剪掉边缘10个像素）\n",
    "    # # cropped_warped_image = warped_image[:, :, :, :-10]\n",
    "    return warped_image\n",
    "\n",
    "\n",
    "\n",
    "max_flow_step = 5.0\n",
    "step = 5\n",
    "\n",
    "# 累加光流函数\n",
    "def accumulate_flow(accumulated_flow, new_flow):\n",
    "    return accumulated_flow + new_flow\n",
    "\n",
    "# 限制光流步长函数\n",
    "def limit_flow_step(flow, max_step):\n",
    "    return torch.clamp(flow, min=-max_step, max=max_step)  # 限制光流的最大步长\n",
    "\n",
    "# 进行光流预测\n",
    "print(num_frames)\n",
    "for i in range(num_frames - step):\n",
    "#for i in range(20):\n",
    "    accumulated_flow = None  # 每次更新i初始化累积光流为None\n",
    "    for j in range(step):\n",
    "        print('img1=',i + j)\n",
    "        print('img2=',i + j + 1)\n",
    "        img1 = Image.open(image_files[i + j]).convert('RGB')\n",
    "        img2 = Image.open(image_files[i + j + 1]).convert('RGB')\n",
    "        # if i == 10:\n",
    "        #     img1.save(f'1img{i}{j}.jpg')\n",
    "        # \n",
    "        # \n",
    "        #     img2.save(f'2img{i}{j+1}.jpg')\n",
    "\n",
    "\n",
    "        \n",
    "        img1_tensor = F.to_tensor(img1).unsqueeze(0)\n",
    "        img2_tensor = F.to_tensor(img2).unsqueeze(0)\n",
    "\n",
    "        # img1_tensor, img2_tensor = preprocess(img1_tensor, img2_tensor)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            list_of_flows = model(img1_tensor.to(device), img2_tensor.to(device))\n",
    "            predicted_flows = list_of_flows[-1].cpu()# 获取光流（一般来说最后一个最准确）\n",
    "            \n",
    "        # 限制光流移动步长\n",
    "        # predicted_flows = limit_flow_step(predicted_flows, max_flow_step)\n",
    "        \n",
    "        if accumulated_flow is None:\n",
    "            accumulated_flow = predicted_flows*((j+1)/6)  # 如果是第一帧光流，初始化累积光流\n",
    "        else:\n",
    "            accumulated_flow = accumulate_flow(accumulated_flow, predicted_flows*((j+1)/6))  # 叠加光流，以1/6，2/6……的方式叠加\n",
    "    \n",
    "    \n",
    "    print('shape=',predicted_flows.shape)\n",
    "\n",
    "    flow_imgs = flow_to_image(predicted_flows)\n",
    "    \n",
    "    # 保存光流结果\n",
    "    output_file = os.path.join(output_folder, f'accumulated_flow_{i:03d}_to_{i+step:03d}.png')\n",
    "    plt.imsave(output_file, flow_imgs.squeeze().permute(1, 2, 0).numpy())\n",
    "\n",
    "    print(f\"Processed frame {i} to {i+step}\")\n",
    "\n",
    "    \n",
    "    # 进行帧预测\n",
    "    #expand_pixels=20\n",
    "    #expanded_image = torch.nn.functional.pad(img2_tensor, (expand_pixels, expand_pixels, expand_pixels, expand_pixels), mode='constant', value=255)\n",
    "    # 预测\n",
    "    predicted_next_frame = apply_flow(img2_tensor, accumulated_flow)\n",
    "    # 裁剪掉扩展的部分，恢复原始大小\n",
    "    # cropped_warped_image = predicted_next_frame[:, :, expand_pixels:-expand_pixels, expand_pixels:-expand_pixels]\n",
    "    # 保存预测结果\n",
    "    output_file = os.path.join(output_PRE_folder, f'predicted{i+step+1:03d}using{i:03d}to{i+step:03d}.png')\n",
    "    predicted_next_frame = predicted_next_frame.squeeze().permute(1, 2, 0).clamp(0, 1)\n",
    "    plt.imsave(output_file, predicted_next_frame.numpy())\n",
    "    print(\"---\")\n",
    "    \n",
    "print(\"All frames processed.\")"
   ],
   "id": "d35b22a0e34208c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241\n",
      "img1= 0\n",
      "img2= 1\n",
      "img1= 1\n",
      "img2= 2\n",
      "img1= 2\n",
      "img2= 3\n",
      "img1= 3\n",
      "img2= 4\n",
      "img1= 4\n",
      "img2= 5\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 0 to 5\n",
      "mean_flow_x=16.45806312561035, mean_flow_y=14.311131477355957\n",
      "---\n",
      "img1= 1\n",
      "img2= 2\n",
      "img1= 2\n",
      "img2= 3\n",
      "img1= 3\n",
      "img2= 4\n",
      "img1= 4\n",
      "img2= 5\n",
      "img1= 5\n",
      "img2= 6\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 1 to 6\n",
      "mean_flow_x=14.06870174407959, mean_flow_y=12.397560119628906\n",
      "---\n",
      "img1= 2\n",
      "img2= 3\n",
      "img1= 3\n",
      "img2= 4\n",
      "img1= 4\n",
      "img2= 5\n",
      "img1= 5\n",
      "img2= 6\n",
      "img1= 6\n",
      "img2= 7\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 2 to 7\n",
      "mean_flow_x=10.814901351928711, mean_flow_y=8.46880054473877\n",
      "---\n",
      "img1= 3\n",
      "img2= 4\n",
      "img1= 4\n",
      "img2= 5\n",
      "img1= 5\n",
      "img2= 6\n",
      "img1= 6\n",
      "img2= 7\n",
      "img1= 7\n",
      "img2= 8\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 3 to 8\n",
      "mean_flow_x=10.693026542663574, mean_flow_y=3.6985394954681396\n",
      "---\n",
      "img1= 4\n",
      "img2= 5\n",
      "img1= 5\n",
      "img2= 6\n",
      "img1= 6\n",
      "img2= 7\n",
      "img1= 7\n",
      "img2= 8\n",
      "img1= 8\n",
      "img2= 9\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 4 to 9\n",
      "mean_flow_x=9.416265487670898, mean_flow_y=3.2597572803497314\n",
      "---\n",
      "img1= 5\n",
      "img2= 6\n",
      "img1= 6\n",
      "img2= 7\n",
      "img1= 7\n",
      "img2= 8\n",
      "img1= 8\n",
      "img2= 9\n",
      "img1= 9\n",
      "img2= 10\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 5 to 10\n",
      "mean_flow_x=8.846578598022461, mean_flow_y=1.794845461845398\n",
      "---\n",
      "img1= 6\n",
      "img2= 7\n",
      "img1= 7\n",
      "img2= 8\n",
      "img1= 8\n",
      "img2= 9\n",
      "img1= 9\n",
      "img2= 10\n",
      "img1= 10\n",
      "img2= 11\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 6 to 11\n",
      "mean_flow_x=10.042167663574219, mean_flow_y=0.8531990051269531\n",
      "---\n",
      "img1= 7\n",
      "img2= 8\n",
      "img1= 8\n",
      "img2= 9\n",
      "img1= 9\n",
      "img2= 10\n",
      "img1= 10\n",
      "img2= 11\n",
      "img1= 11\n",
      "img2= 12\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 7 to 12\n",
      "mean_flow_x=9.164654731750488, mean_flow_y=0.4001878798007965\n",
      "---\n",
      "img1= 8\n",
      "img2= 9\n",
      "img1= 9\n",
      "img2= 10\n",
      "img1= 10\n",
      "img2= 11\n",
      "img1= 11\n",
      "img2= 12\n",
      "img1= 12\n",
      "img2= 13\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 8 to 13\n",
      "mean_flow_x=8.721375465393066, mean_flow_y=0.036848731338977814\n",
      "---\n",
      "img1= 9\n",
      "img2= 10\n",
      "img1= 10\n",
      "img2= 11\n",
      "img1= 11\n",
      "img2= 12\n",
      "img1= 12\n",
      "img2= 13\n",
      "img1= 13\n",
      "img2= 14\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 9 to 14\n",
      "mean_flow_x=9.311405181884766, mean_flow_y=0.4699544310569763\n",
      "---\n",
      "img1= 10\n",
      "img2= 11\n",
      "img1= 11\n",
      "img2= 12\n",
      "img1= 12\n",
      "img2= 13\n",
      "img1= 13\n",
      "img2= 14\n",
      "img1= 14\n",
      "img2= 15\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 10 to 15\n",
      "mean_flow_x=10.11264419555664, mean_flow_y=-0.14242783188819885\n",
      "---\n",
      "img1= 11\n",
      "img2= 12\n",
      "img1= 12\n",
      "img2= 13\n",
      "img1= 13\n",
      "img2= 14\n",
      "img1= 14\n",
      "img2= 15\n",
      "img1= 15\n",
      "img2= 16\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 11 to 16\n",
      "mean_flow_x=10.219771385192871, mean_flow_y=-0.26101839542388916\n",
      "---\n",
      "img1= 12\n",
      "img2= 13\n",
      "img1= 13\n",
      "img2= 14\n",
      "img1= 14\n",
      "img2= 15\n",
      "img1= 15\n",
      "img2= 16\n",
      "img1= 16\n",
      "img2= 17\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 12 to 17\n",
      "mean_flow_x=8.965997695922852, mean_flow_y=-0.17645859718322754\n",
      "---\n",
      "img1= 13\n",
      "img2= 14\n",
      "img1= 14\n",
      "img2= 15\n",
      "img1= 15\n",
      "img2= 16\n",
      "img1= 16\n",
      "img2= 17\n",
      "img1= 17\n",
      "img2= 18\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 13 to 18\n",
      "mean_flow_x=9.125161170959473, mean_flow_y=0.7738397717475891\n",
      "---\n",
      "img1= 14\n",
      "img2= 15\n",
      "img1= 15\n",
      "img2= 16\n",
      "img1= 16\n",
      "img2= 17\n",
      "img1= 17\n",
      "img2= 18\n",
      "img1= 18\n",
      "img2= 19\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 14 to 19\n",
      "mean_flow_x=8.363457679748535, mean_flow_y=0.9129964709281921\n",
      "---\n",
      "img1= 15\n",
      "img2= 16\n",
      "img1= 16\n",
      "img2= 17\n",
      "img1= 17\n",
      "img2= 18\n",
      "img1= 18\n",
      "img2= 19\n",
      "img1= 19\n",
      "img2= 20\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 15 to 20\n",
      "mean_flow_x=6.839425086975098, mean_flow_y=2.920071601867676\n",
      "---\n",
      "img1= 16\n",
      "img2= 17\n",
      "img1= 17\n",
      "img2= 18\n",
      "img1= 18\n",
      "img2= 19\n",
      "img1= 19\n",
      "img2= 20\n",
      "img1= 20\n",
      "img2= 21\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 16 to 21\n",
      "mean_flow_x=6.2992095947265625, mean_flow_y=6.048259258270264\n",
      "---\n",
      "img1= 17\n",
      "img2= 18\n",
      "img1= 18\n",
      "img2= 19\n",
      "img1= 19\n",
      "img2= 20\n",
      "img1= 20\n",
      "img2= 21\n",
      "img1= 21\n",
      "img2= 22\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 17 to 22\n",
      "mean_flow_x=7.616787433624268, mean_flow_y=4.113664627075195\n",
      "---\n",
      "img1= 18\n",
      "img2= 19\n",
      "img1= 19\n",
      "img2= 20\n",
      "img1= 20\n",
      "img2= 21\n",
      "img1= 21\n",
      "img2= 22\n",
      "img1= 22\n",
      "img2= 23\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 18 to 23\n",
      "mean_flow_x=9.706355094909668, mean_flow_y=2.6008126735687256\n",
      "---\n",
      "img1= 19\n",
      "img2= 20\n",
      "img1= 20\n",
      "img2= 21\n",
      "img1= 21\n",
      "img2= 22\n",
      "img1= 22\n",
      "img2= 23\n",
      "img1= 23\n",
      "img2= 24\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 19 to 24\n",
      "mean_flow_x=8.982470512390137, mean_flow_y=3.1376590728759766\n",
      "---\n",
      "img1= 20\n",
      "img2= 21\n",
      "img1= 21\n",
      "img2= 22\n",
      "img1= 22\n",
      "img2= 23\n",
      "img1= 23\n",
      "img2= 24\n",
      "img1= 24\n",
      "img2= 25\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 20 to 25\n",
      "mean_flow_x=8.18504810333252, mean_flow_y=3.189652442932129\n",
      "---\n",
      "img1= 21\n",
      "img2= 22\n",
      "img1= 22\n",
      "img2= 23\n",
      "img1= 23\n",
      "img2= 24\n",
      "img1= 24\n",
      "img2= 25\n",
      "img1= 25\n",
      "img2= 26\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 21 to 26\n",
      "mean_flow_x=7.412456035614014, mean_flow_y=4.108498573303223\n",
      "---\n",
      "img1= 22\n",
      "img2= 23\n",
      "img1= 23\n",
      "img2= 24\n",
      "img1= 24\n",
      "img2= 25\n",
      "img1= 25\n",
      "img2= 26\n",
      "img1= 26\n",
      "img2= 27\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 22 to 27\n",
      "mean_flow_x=6.473577976226807, mean_flow_y=5.017293930053711\n",
      "---\n",
      "img1= 23\n",
      "img2= 24\n",
      "img1= 24\n",
      "img2= 25\n",
      "img1= 25\n",
      "img2= 26\n",
      "img1= 26\n",
      "img2= 27\n",
      "img1= 27\n",
      "img2= 28\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 23 to 28\n",
      "mean_flow_x=6.380831241607666, mean_flow_y=5.712656497955322\n",
      "---\n",
      "img1= 24\n",
      "img2= 25\n",
      "img1= 25\n",
      "img2= 26\n",
      "img1= 26\n",
      "img2= 27\n",
      "img1= 27\n",
      "img2= 28\n",
      "img1= 28\n",
      "img2= 29\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 24 to 29\n",
      "mean_flow_x=7.663951396942139, mean_flow_y=7.709383487701416\n",
      "---\n",
      "img1= 25\n",
      "img2= 26\n",
      "img1= 26\n",
      "img2= 27\n",
      "img1= 27\n",
      "img2= 28\n",
      "img1= 28\n",
      "img2= 29\n",
      "img1= 29\n",
      "img2= 30\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 25 to 30\n",
      "mean_flow_x=7.467031478881836, mean_flow_y=7.361401557922363\n",
      "---\n",
      "img1= 26\n",
      "img2= 27\n",
      "img1= 27\n",
      "img2= 28\n",
      "img1= 28\n",
      "img2= 29\n",
      "img1= 29\n",
      "img2= 30\n",
      "img1= 30\n",
      "img2= 31\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 26 to 31\n",
      "mean_flow_x=7.694626331329346, mean_flow_y=7.9303765296936035\n",
      "---\n",
      "img1= 27\n",
      "img2= 28\n",
      "img1= 28\n",
      "img2= 29\n",
      "img1= 29\n",
      "img2= 30\n",
      "img1= 30\n",
      "img2= 31\n",
      "img1= 31\n",
      "img2= 32\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 27 to 32\n",
      "mean_flow_x=12.225372314453125, mean_flow_y=11.097573280334473\n",
      "---\n",
      "img1= 28\n",
      "img2= 29\n",
      "img1= 29\n",
      "img2= 30\n",
      "img1= 30\n",
      "img2= 31\n",
      "img1= 31\n",
      "img2= 32\n",
      "img1= 32\n",
      "img2= 33\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 28 to 33\n",
      "mean_flow_x=10.174217224121094, mean_flow_y=11.014222145080566\n",
      "---\n",
      "img1= 29\n",
      "img2= 30\n",
      "img1= 30\n",
      "img2= 31\n",
      "img1= 31\n",
      "img2= 32\n",
      "img1= 32\n",
      "img2= 33\n",
      "img1= 33\n",
      "img2= 34\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 29 to 34\n",
      "mean_flow_x=12.412211418151855, mean_flow_y=10.059892654418945\n",
      "---\n",
      "img1= 30\n",
      "img2= 31\n",
      "img1= 31\n",
      "img2= 32\n",
      "img1= 32\n",
      "img2= 33\n",
      "img1= 33\n",
      "img2= 34\n",
      "img1= 34\n",
      "img2= 35\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 30 to 35\n",
      "mean_flow_x=13.630273818969727, mean_flow_y=10.480734825134277\n",
      "---\n",
      "img1= 31\n",
      "img2= 32\n",
      "img1= 32\n",
      "img2= 33\n",
      "img1= 33\n",
      "img2= 34\n",
      "img1= 34\n",
      "img2= 35\n",
      "img1= 35\n",
      "img2= 36\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 31 to 36\n",
      "mean_flow_x=14.230224609375, mean_flow_y=10.85193920135498\n",
      "---\n",
      "img1= 32\n",
      "img2= 33\n",
      "img1= 33\n",
      "img2= 34\n",
      "img1= 34\n",
      "img2= 35\n",
      "img1= 35\n",
      "img2= 36\n",
      "img1= 36\n",
      "img2= 37\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 32 to 37\n",
      "mean_flow_x=16.615062713623047, mean_flow_y=11.292760848999023\n",
      "---\n",
      "img1= 33\n",
      "img2= 34\n",
      "img1= 34\n",
      "img2= 35\n",
      "img1= 35\n",
      "img2= 36\n",
      "img1= 36\n",
      "img2= 37\n",
      "img1= 37\n",
      "img2= 38\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 33 to 38\n",
      "mean_flow_x=16.66719627380371, mean_flow_y=10.939807891845703\n",
      "---\n",
      "img1= 34\n",
      "img2= 35\n",
      "img1= 35\n",
      "img2= 36\n",
      "img1= 36\n",
      "img2= 37\n",
      "img1= 37\n",
      "img2= 38\n",
      "img1= 38\n",
      "img2= 39\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 34 to 39\n",
      "mean_flow_x=14.432576179504395, mean_flow_y=9.811057090759277\n",
      "---\n",
      "img1= 35\n",
      "img2= 36\n",
      "img1= 36\n",
      "img2= 37\n",
      "img1= 37\n",
      "img2= 38\n",
      "img1= 38\n",
      "img2= 39\n",
      "img1= 39\n",
      "img2= 40\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 35 to 40\n",
      "mean_flow_x=12.796294212341309, mean_flow_y=7.303120136260986\n",
      "---\n",
      "img1= 36\n",
      "img2= 37\n",
      "img1= 37\n",
      "img2= 38\n",
      "img1= 38\n",
      "img2= 39\n",
      "img1= 39\n",
      "img2= 40\n",
      "img1= 40\n",
      "img2= 41\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 36 to 41\n",
      "mean_flow_x=11.0870943069458, mean_flow_y=5.956233978271484\n",
      "---\n",
      "img1= 37\n",
      "img2= 38\n",
      "img1= 38\n",
      "img2= 39\n",
      "img1= 39\n",
      "img2= 40\n",
      "img1= 40\n",
      "img2= 41\n",
      "img1= 41\n",
      "img2= 42\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 37 to 42\n",
      "mean_flow_x=9.693742752075195, mean_flow_y=4.585624694824219\n",
      "---\n",
      "img1= 38\n",
      "img2= 39\n",
      "img1= 39\n",
      "img2= 40\n",
      "img1= 40\n",
      "img2= 41\n",
      "img1= 41\n",
      "img2= 42\n",
      "img1= 42\n",
      "img2= 43\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 38 to 43\n",
      "mean_flow_x=8.800697326660156, mean_flow_y=4.061808109283447\n",
      "---\n",
      "img1= 39\n",
      "img2= 40\n",
      "img1= 40\n",
      "img2= 41\n",
      "img1= 41\n",
      "img2= 42\n",
      "img1= 42\n",
      "img2= 43\n",
      "img1= 43\n",
      "img2= 44\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 39 to 44\n",
      "mean_flow_x=8.889901161193848, mean_flow_y=4.607982635498047\n",
      "---\n",
      "img1= 40\n",
      "img2= 41\n",
      "img1= 41\n",
      "img2= 42\n",
      "img1= 42\n",
      "img2= 43\n",
      "img1= 43\n",
      "img2= 44\n",
      "img1= 44\n",
      "img2= 45\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 40 to 45\n",
      "mean_flow_x=8.461125373840332, mean_flow_y=3.9232168197631836\n",
      "---\n",
      "img1= 41\n",
      "img2= 42\n",
      "img1= 42\n",
      "img2= 43\n",
      "img1= 43\n",
      "img2= 44\n",
      "img1= 44\n",
      "img2= 45\n",
      "img1= 45\n",
      "img2= 46\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 41 to 46\n",
      "mean_flow_x=8.146533966064453, mean_flow_y=3.5661375522613525\n",
      "---\n",
      "img1= 42\n",
      "img2= 43\n",
      "img1= 43\n",
      "img2= 44\n",
      "img1= 44\n",
      "img2= 45\n",
      "img1= 45\n",
      "img2= 46\n",
      "img1= 46\n",
      "img2= 47\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 42 to 47\n",
      "mean_flow_x=7.710613250732422, mean_flow_y=4.610607624053955\n",
      "---\n",
      "img1= 43\n",
      "img2= 44\n",
      "img1= 44\n",
      "img2= 45\n",
      "img1= 45\n",
      "img2= 46\n",
      "img1= 46\n",
      "img2= 47\n",
      "img1= 47\n",
      "img2= 48\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 43 to 48\n",
      "mean_flow_x=6.976063251495361, mean_flow_y=4.386231422424316\n",
      "---\n",
      "img1= 44\n",
      "img2= 45\n",
      "img1= 45\n",
      "img2= 46\n",
      "img1= 46\n",
      "img2= 47\n",
      "img1= 47\n",
      "img2= 48\n",
      "img1= 48\n",
      "img2= 49\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 44 to 49\n",
      "mean_flow_x=8.440321922302246, mean_flow_y=6.202458381652832\n",
      "---\n",
      "img1= 45\n",
      "img2= 46\n",
      "img1= 46\n",
      "img2= 47\n",
      "img1= 47\n",
      "img2= 48\n",
      "img1= 48\n",
      "img2= 49\n",
      "img1= 49\n",
      "img2= 50\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 45 to 50\n",
      "mean_flow_x=10.908242225646973, mean_flow_y=6.8859357833862305\n",
      "---\n",
      "img1= 46\n",
      "img2= 47\n",
      "img1= 47\n",
      "img2= 48\n",
      "img1= 48\n",
      "img2= 49\n",
      "img1= 49\n",
      "img2= 50\n",
      "img1= 50\n",
      "img2= 51\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 46 to 51\n",
      "mean_flow_x=12.361334800720215, mean_flow_y=8.15482234954834\n",
      "---\n",
      "img1= 47\n",
      "img2= 48\n",
      "img1= 48\n",
      "img2= 49\n",
      "img1= 49\n",
      "img2= 50\n",
      "img1= 50\n",
      "img2= 51\n",
      "img1= 51\n",
      "img2= 52\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 47 to 52\n",
      "mean_flow_x=12.53172779083252, mean_flow_y=8.636934280395508\n",
      "---\n",
      "img1= 48\n",
      "img2= 49\n",
      "img1= 49\n",
      "img2= 50\n",
      "img1= 50\n",
      "img2= 51\n",
      "img1= 51\n",
      "img2= 52\n",
      "img1= 52\n",
      "img2= 53\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 48 to 53\n",
      "mean_flow_x=12.518378257751465, mean_flow_y=8.553340911865234\n",
      "---\n",
      "img1= 49\n",
      "img2= 50\n",
      "img1= 50\n",
      "img2= 51\n",
      "img1= 51\n",
      "img2= 52\n",
      "img1= 52\n",
      "img2= 53\n",
      "img1= 53\n",
      "img2= 54\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 49 to 54\n",
      "mean_flow_x=14.5382719039917, mean_flow_y=9.201972961425781\n",
      "---\n",
      "img1= 50\n",
      "img2= 51\n",
      "img1= 51\n",
      "img2= 52\n",
      "img1= 52\n",
      "img2= 53\n",
      "img1= 53\n",
      "img2= 54\n",
      "img1= 54\n",
      "img2= 55\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 50 to 55\n",
      "mean_flow_x=15.460761070251465, mean_flow_y=7.848361015319824\n",
      "---\n",
      "img1= 51\n",
      "img2= 52\n",
      "img1= 52\n",
      "img2= 53\n",
      "img1= 53\n",
      "img2= 54\n",
      "img1= 54\n",
      "img2= 55\n",
      "img1= 55\n",
      "img2= 56\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 51 to 56\n",
      "mean_flow_x=18.572254180908203, mean_flow_y=10.675588607788086\n",
      "---\n",
      "img1= 52\n",
      "img2= 53\n",
      "img1= 53\n",
      "img2= 54\n",
      "img1= 54\n",
      "img2= 55\n",
      "img1= 55\n",
      "img2= 56\n",
      "img1= 56\n",
      "img2= 57\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 52 to 57\n",
      "mean_flow_x=18.415363311767578, mean_flow_y=8.576995849609375\n",
      "---\n",
      "img1= 53\n",
      "img2= 54\n",
      "img1= 54\n",
      "img2= 55\n",
      "img1= 55\n",
      "img2= 56\n",
      "img1= 56\n",
      "img2= 57\n",
      "img1= 57\n",
      "img2= 58\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 53 to 58\n",
      "mean_flow_x=15.523870468139648, mean_flow_y=7.408006191253662\n",
      "---\n",
      "img1= 54\n",
      "img2= 55\n",
      "img1= 55\n",
      "img2= 56\n",
      "img1= 56\n",
      "img2= 57\n",
      "img1= 57\n",
      "img2= 58\n",
      "img1= 58\n",
      "img2= 59\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 54 to 59\n",
      "mean_flow_x=12.94273853302002, mean_flow_y=5.200493812561035\n",
      "---\n",
      "img1= 55\n",
      "img2= 56\n",
      "img1= 56\n",
      "img2= 57\n",
      "img1= 57\n",
      "img2= 58\n",
      "img1= 58\n",
      "img2= 59\n",
      "img1= 59\n",
      "img2= 60\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 55 to 60\n",
      "mean_flow_x=12.215005874633789, mean_flow_y=5.768335819244385\n",
      "---\n",
      "img1= 56\n",
      "img2= 57\n",
      "img1= 57\n",
      "img2= 58\n",
      "img1= 58\n",
      "img2= 59\n",
      "img1= 59\n",
      "img2= 60\n",
      "img1= 60\n",
      "img2= 61\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 56 to 61\n",
      "mean_flow_x=10.420731544494629, mean_flow_y=6.419914722442627\n",
      "---\n",
      "img1= 57\n",
      "img2= 58\n",
      "img1= 58\n",
      "img2= 59\n",
      "img1= 59\n",
      "img2= 60\n",
      "img1= 60\n",
      "img2= 61\n",
      "img1= 61\n",
      "img2= 62\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 57 to 62\n",
      "mean_flow_x=9.832139015197754, mean_flow_y=5.664361953735352\n",
      "---\n",
      "img1= 58\n",
      "img2= 59\n",
      "img1= 59\n",
      "img2= 60\n",
      "img1= 60\n",
      "img2= 61\n",
      "img1= 61\n",
      "img2= 62\n",
      "img1= 62\n",
      "img2= 63\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 58 to 63\n",
      "mean_flow_x=9.629118919372559, mean_flow_y=5.048792362213135\n",
      "---\n",
      "img1= 59\n",
      "img2= 60\n",
      "img1= 60\n",
      "img2= 61\n",
      "img1= 61\n",
      "img2= 62\n",
      "img1= 62\n",
      "img2= 63\n",
      "img1= 63\n",
      "img2= 64\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 59 to 64\n",
      "mean_flow_x=9.803717613220215, mean_flow_y=4.462074279785156\n",
      "---\n",
      "img1= 60\n",
      "img2= 61\n",
      "img1= 61\n",
      "img2= 62\n",
      "img1= 62\n",
      "img2= 63\n",
      "img1= 63\n",
      "img2= 64\n",
      "img1= 64\n",
      "img2= 65\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 60 to 65\n",
      "mean_flow_x=10.929978370666504, mean_flow_y=3.808542251586914\n",
      "---\n",
      "img1= 61\n",
      "img2= 62\n",
      "img1= 62\n",
      "img2= 63\n",
      "img1= 63\n",
      "img2= 64\n",
      "img1= 64\n",
      "img2= 65\n",
      "img1= 65\n",
      "img2= 66\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 61 to 66\n",
      "mean_flow_x=11.708996772766113, mean_flow_y=2.7250280380249023\n",
      "---\n",
      "img1= 62\n",
      "img2= 63\n",
      "img1= 63\n",
      "img2= 64\n",
      "img1= 64\n",
      "img2= 65\n",
      "img1= 65\n",
      "img2= 66\n",
      "img1= 66\n",
      "img2= 67\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 62 to 67\n",
      "mean_flow_x=10.771482467651367, mean_flow_y=5.750800132751465\n",
      "---\n",
      "img1= 63\n",
      "img2= 64\n",
      "img1= 64\n",
      "img2= 65\n",
      "img1= 65\n",
      "img2= 66\n",
      "img1= 66\n",
      "img2= 67\n",
      "img1= 67\n",
      "img2= 68\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 63 to 68\n",
      "mean_flow_x=11.227839469909668, mean_flow_y=3.9803566932678223\n",
      "---\n",
      "img1= 64\n",
      "img2= 65\n",
      "img1= 65\n",
      "img2= 66\n",
      "img1= 66\n",
      "img2= 67\n",
      "img1= 67\n",
      "img2= 68\n",
      "img1= 68\n",
      "img2= 69\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 64 to 69\n",
      "mean_flow_x=11.495692253112793, mean_flow_y=3.156599521636963\n",
      "---\n",
      "img1= 65\n",
      "img2= 66\n",
      "img1= 66\n",
      "img2= 67\n",
      "img1= 67\n",
      "img2= 68\n",
      "img1= 68\n",
      "img2= 69\n",
      "img1= 69\n",
      "img2= 70\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 65 to 70\n",
      "mean_flow_x=10.782068252563477, mean_flow_y=2.552440643310547\n",
      "---\n",
      "img1= 66\n",
      "img2= 67\n",
      "img1= 67\n",
      "img2= 68\n",
      "img1= 68\n",
      "img2= 69\n",
      "img1= 69\n",
      "img2= 70\n",
      "img1= 70\n",
      "img2= 71\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 66 to 71\n",
      "mean_flow_x=11.35949420928955, mean_flow_y=2.1254286766052246\n",
      "---\n",
      "img1= 67\n",
      "img2= 68\n",
      "img1= 68\n",
      "img2= 69\n",
      "img1= 69\n",
      "img2= 70\n",
      "img1= 70\n",
      "img2= 71\n",
      "img1= 71\n",
      "img2= 72\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 67 to 72\n",
      "mean_flow_x=12.090729713439941, mean_flow_y=2.032161235809326\n",
      "---\n",
      "img1= 68\n",
      "img2= 69\n",
      "img1= 69\n",
      "img2= 70\n",
      "img1= 70\n",
      "img2= 71\n",
      "img1= 71\n",
      "img2= 72\n",
      "img1= 72\n",
      "img2= 73\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 68 to 73\n",
      "mean_flow_x=11.791520118713379, mean_flow_y=2.0635321140289307\n",
      "---\n",
      "img1= 69\n",
      "img2= 70\n",
      "img1= 70\n",
      "img2= 71\n",
      "img1= 71\n",
      "img2= 72\n",
      "img1= 72\n",
      "img2= 73\n",
      "img1= 73\n",
      "img2= 74\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 69 to 74\n",
      "mean_flow_x=11.543641090393066, mean_flow_y=2.7086551189422607\n",
      "---\n",
      "img1= 70\n",
      "img2= 71\n",
      "img1= 71\n",
      "img2= 72\n",
      "img1= 72\n",
      "img2= 73\n",
      "img1= 73\n",
      "img2= 74\n",
      "img1= 74\n",
      "img2= 75\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 70 to 75\n",
      "mean_flow_x=10.97716236114502, mean_flow_y=2.753540277481079\n",
      "---\n",
      "img1= 71\n",
      "img2= 72\n",
      "img1= 72\n",
      "img2= 73\n",
      "img1= 73\n",
      "img2= 74\n",
      "img1= 74\n",
      "img2= 75\n",
      "img1= 75\n",
      "img2= 76\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 71 to 76\n",
      "mean_flow_x=10.16408920288086, mean_flow_y=3.2371299266815186\n",
      "---\n",
      "img1= 72\n",
      "img2= 73\n",
      "img1= 73\n",
      "img2= 74\n",
      "img1= 74\n",
      "img2= 75\n",
      "img1= 75\n",
      "img2= 76\n",
      "img1= 76\n",
      "img2= 77\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 72 to 77\n",
      "mean_flow_x=9.9931001663208, mean_flow_y=2.213480234146118\n",
      "---\n",
      "img1= 73\n",
      "img2= 74\n",
      "img1= 74\n",
      "img2= 75\n",
      "img1= 75\n",
      "img2= 76\n",
      "img1= 76\n",
      "img2= 77\n",
      "img1= 77\n",
      "img2= 78\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 73 to 78\n",
      "mean_flow_x=9.734807968139648, mean_flow_y=2.392000913619995\n",
      "---\n",
      "img1= 74\n",
      "img2= 75\n",
      "img1= 75\n",
      "img2= 76\n",
      "img1= 76\n",
      "img2= 77\n",
      "img1= 77\n",
      "img2= 78\n",
      "img1= 78\n",
      "img2= 79\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 74 to 79\n",
      "mean_flow_x=10.2249755859375, mean_flow_y=1.159958004951477\n",
      "---\n",
      "img1= 75\n",
      "img2= 76\n",
      "img1= 76\n",
      "img2= 77\n",
      "img1= 77\n",
      "img2= 78\n",
      "img1= 78\n",
      "img2= 79\n",
      "img1= 79\n",
      "img2= 80\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 75 to 80\n",
      "mean_flow_x=8.90190601348877, mean_flow_y=1.082218050956726\n",
      "---\n",
      "img1= 76\n",
      "img2= 77\n",
      "img1= 77\n",
      "img2= 78\n",
      "img1= 78\n",
      "img2= 79\n",
      "img1= 79\n",
      "img2= 80\n",
      "img1= 80\n",
      "img2= 81\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 76 to 81\n",
      "mean_flow_x=8.987356185913086, mean_flow_y=0.6730476021766663\n",
      "---\n",
      "img1= 77\n",
      "img2= 78\n",
      "img1= 78\n",
      "img2= 79\n",
      "img1= 79\n",
      "img2= 80\n",
      "img1= 80\n",
      "img2= 81\n",
      "img1= 81\n",
      "img2= 82\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 77 to 82\n",
      "mean_flow_x=9.782465934753418, mean_flow_y=-0.4137685000896454\n",
      "---\n",
      "img1= 78\n",
      "img2= 79\n",
      "img1= 79\n",
      "img2= 80\n",
      "img1= 80\n",
      "img2= 81\n",
      "img1= 81\n",
      "img2= 82\n",
      "img1= 82\n",
      "img2= 83\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 78 to 83\n",
      "mean_flow_x=9.613778114318848, mean_flow_y=0.24774746596813202\n",
      "---\n",
      "img1= 79\n",
      "img2= 80\n",
      "img1= 80\n",
      "img2= 81\n",
      "img1= 81\n",
      "img2= 82\n",
      "img1= 82\n",
      "img2= 83\n",
      "img1= 83\n",
      "img2= 84\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 79 to 84\n",
      "mean_flow_x=9.040396690368652, mean_flow_y=-0.5865692496299744\n",
      "---\n",
      "img1= 80\n",
      "img2= 81\n",
      "img1= 81\n",
      "img2= 82\n",
      "img1= 82\n",
      "img2= 83\n",
      "img1= 83\n",
      "img2= 84\n",
      "img1= 84\n",
      "img2= 85\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 80 to 85\n",
      "mean_flow_x=8.4382963180542, mean_flow_y=0.021834276616573334\n",
      "---\n",
      "img1= 81\n",
      "img2= 82\n",
      "img1= 82\n",
      "img2= 83\n",
      "img1= 83\n",
      "img2= 84\n",
      "img1= 84\n",
      "img2= 85\n",
      "img1= 85\n",
      "img2= 86\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 81 to 86\n",
      "mean_flow_x=15.902531623840332, mean_flow_y=0.38229355216026306\n",
      "---\n",
      "img1= 82\n",
      "img2= 83\n",
      "img1= 83\n",
      "img2= 84\n",
      "img1= 84\n",
      "img2= 85\n",
      "img1= 85\n",
      "img2= 86\n",
      "img1= 86\n",
      "img2= 87\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 82 to 87\n",
      "mean_flow_x=14.36507511138916, mean_flow_y=1.442007303237915\n",
      "---\n",
      "img1= 83\n",
      "img2= 84\n",
      "img1= 84\n",
      "img2= 85\n",
      "img1= 85\n",
      "img2= 86\n",
      "img1= 86\n",
      "img2= 87\n",
      "img1= 87\n",
      "img2= 88\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 83 to 88\n",
      "mean_flow_x=12.739434242248535, mean_flow_y=1.4425305128097534\n",
      "---\n",
      "img1= 84\n",
      "img2= 85\n",
      "img1= 85\n",
      "img2= 86\n",
      "img1= 86\n",
      "img2= 87\n",
      "img1= 87\n",
      "img2= 88\n",
      "img1= 88\n",
      "img2= 89\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 84 to 89\n",
      "mean_flow_x=11.538870811462402, mean_flow_y=1.2293628454208374\n",
      "---\n",
      "img1= 85\n",
      "img2= 86\n",
      "img1= 86\n",
      "img2= 87\n",
      "img1= 87\n",
      "img2= 88\n",
      "img1= 88\n",
      "img2= 89\n",
      "img1= 89\n",
      "img2= 90\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 85 to 90\n",
      "mean_flow_x=9.884760856628418, mean_flow_y=1.4562537670135498\n",
      "---\n",
      "img1= 86\n",
      "img2= 87\n",
      "img1= 87\n",
      "img2= 88\n",
      "img1= 88\n",
      "img2= 89\n",
      "img1= 89\n",
      "img2= 90\n",
      "img1= 90\n",
      "img2= 91\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 86 to 91\n",
      "mean_flow_x=8.41053295135498, mean_flow_y=1.2885738611221313\n",
      "---\n",
      "img1= 87\n",
      "img2= 88\n",
      "img1= 88\n",
      "img2= 89\n",
      "img1= 89\n",
      "img2= 90\n",
      "img1= 90\n",
      "img2= 91\n",
      "img1= 91\n",
      "img2= 92\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 87 to 92\n",
      "mean_flow_x=8.429771423339844, mean_flow_y=2.182424306869507\n",
      "---\n",
      "img1= 88\n",
      "img2= 89\n",
      "img1= 89\n",
      "img2= 90\n",
      "img1= 90\n",
      "img2= 91\n",
      "img1= 91\n",
      "img2= 92\n",
      "img1= 92\n",
      "img2= 93\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 88 to 93\n",
      "mean_flow_x=9.575970649719238, mean_flow_y=3.8136789798736572\n",
      "---\n",
      "img1= 89\n",
      "img2= 90\n",
      "img1= 90\n",
      "img2= 91\n",
      "img1= 91\n",
      "img2= 92\n",
      "img1= 92\n",
      "img2= 93\n",
      "img1= 93\n",
      "img2= 94\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 89 to 94\n",
      "mean_flow_x=9.124604225158691, mean_flow_y=2.211256742477417\n",
      "---\n",
      "img1= 90\n",
      "img2= 91\n",
      "img1= 91\n",
      "img2= 92\n",
      "img1= 92\n",
      "img2= 93\n",
      "img1= 93\n",
      "img2= 94\n",
      "img1= 94\n",
      "img2= 95\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 90 to 95\n",
      "mean_flow_x=9.606305122375488, mean_flow_y=4.074783802032471\n",
      "---\n",
      "img1= 91\n",
      "img2= 92\n",
      "img1= 92\n",
      "img2= 93\n",
      "img1= 93\n",
      "img2= 94\n",
      "img1= 94\n",
      "img2= 95\n",
      "img1= 95\n",
      "img2= 96\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 91 to 96\n",
      "mean_flow_x=24.52039909362793, mean_flow_y=1.1196717023849487\n",
      "---\n",
      "img1= 92\n",
      "img2= 93\n",
      "img1= 93\n",
      "img2= 94\n",
      "img1= 94\n",
      "img2= 95\n",
      "img1= 95\n",
      "img2= 96\n",
      "img1= 96\n",
      "img2= 97\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 92 to 97\n",
      "mean_flow_x=21.932708740234375, mean_flow_y=-0.039580076932907104\n",
      "---\n",
      "img1= 93\n",
      "img2= 94\n",
      "img1= 94\n",
      "img2= 95\n",
      "img1= 95\n",
      "img2= 96\n",
      "img1= 96\n",
      "img2= 97\n",
      "img1= 97\n",
      "img2= 98\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 93 to 98\n",
      "mean_flow_x=17.691062927246094, mean_flow_y=-0.503899335861206\n",
      "---\n",
      "img1= 94\n",
      "img2= 95\n",
      "img1= 95\n",
      "img2= 96\n",
      "img1= 96\n",
      "img2= 97\n",
      "img1= 97\n",
      "img2= 98\n",
      "img1= 98\n",
      "img2= 99\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 94 to 99\n",
      "mean_flow_x=12.50847053527832, mean_flow_y=-0.8331171870231628\n",
      "---\n",
      "img1= 95\n",
      "img2= 96\n",
      "img1= 96\n",
      "img2= 97\n",
      "img1= 97\n",
      "img2= 98\n",
      "img1= 98\n",
      "img2= 99\n",
      "img1= 99\n",
      "img2= 100\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 95 to 100\n",
      "mean_flow_x=8.651860237121582, mean_flow_y=-0.8649188280105591\n",
      "---\n",
      "img1= 96\n",
      "img2= 97\n",
      "img1= 97\n",
      "img2= 98\n",
      "img1= 98\n",
      "img2= 99\n",
      "img1= 99\n",
      "img2= 100\n",
      "img1= 100\n",
      "img2= 101\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 96 to 101\n",
      "mean_flow_x=14.36070442199707, mean_flow_y=14.089266777038574\n",
      "---\n",
      "img1= 97\n",
      "img2= 98\n",
      "img1= 98\n",
      "img2= 99\n",
      "img1= 99\n",
      "img2= 100\n",
      "img1= 100\n",
      "img2= 101\n",
      "img1= 101\n",
      "img2= 102\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 97 to 102\n",
      "mean_flow_x=10.385385513305664, mean_flow_y=15.029000282287598\n",
      "---\n",
      "img1= 98\n",
      "img2= 99\n",
      "img1= 99\n",
      "img2= 100\n",
      "img1= 100\n",
      "img2= 101\n",
      "img1= 101\n",
      "img2= 102\n",
      "img1= 102\n",
      "img2= 103\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 98 to 103\n",
      "mean_flow_x=7.622707843780518, mean_flow_y=11.637114524841309\n",
      "---\n",
      "img1= 99\n",
      "img2= 100\n",
      "img1= 100\n",
      "img2= 101\n",
      "img1= 101\n",
      "img2= 102\n",
      "img1= 102\n",
      "img2= 103\n",
      "img1= 103\n",
      "img2= 104\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 99 to 104\n",
      "mean_flow_x=4.583826541900635, mean_flow_y=9.707521438598633\n",
      "---\n",
      "img1= 100\n",
      "img2= 101\n",
      "img1= 101\n",
      "img2= 102\n",
      "img1= 102\n",
      "img2= 103\n",
      "img1= 103\n",
      "img2= 104\n",
      "img1= 104\n",
      "img2= 105\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 100 to 105\n",
      "mean_flow_x=6.675320148468018, mean_flow_y=5.729884624481201\n",
      "---\n",
      "img1= 101\n",
      "img2= 102\n",
      "img1= 102\n",
      "img2= 103\n",
      "img1= 103\n",
      "img2= 104\n",
      "img1= 104\n",
      "img2= 105\n",
      "img1= 105\n",
      "img2= 106\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 101 to 106\n",
      "mean_flow_x=4.068971633911133, mean_flow_y=1.968207836151123\n",
      "---\n",
      "img1= 102\n",
      "img2= 103\n",
      "img1= 103\n",
      "img2= 104\n",
      "img1= 104\n",
      "img2= 105\n",
      "img1= 105\n",
      "img2= 106\n",
      "img1= 106\n",
      "img2= 107\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 102 to 107\n",
      "mean_flow_x=7.465031147003174, mean_flow_y=1.8093408346176147\n",
      "---\n",
      "img1= 103\n",
      "img2= 104\n",
      "img1= 104\n",
      "img2= 105\n",
      "img1= 105\n",
      "img2= 106\n",
      "img1= 106\n",
      "img2= 107\n",
      "img1= 107\n",
      "img2= 108\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 103 to 108\n",
      "mean_flow_x=7.136101722717285, mean_flow_y=0.9794573187828064\n",
      "---\n",
      "img1= 104\n",
      "img2= 105\n",
      "img1= 105\n",
      "img2= 106\n",
      "img1= 106\n",
      "img2= 107\n",
      "img1= 107\n",
      "img2= 108\n",
      "img1= 108\n",
      "img2= 109\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 104 to 109\n",
      "mean_flow_x=5.843418121337891, mean_flow_y=0.1906929463148117\n",
      "---\n",
      "img1= 105\n",
      "img2= 106\n",
      "img1= 106\n",
      "img2= 107\n",
      "img1= 107\n",
      "img2= 108\n",
      "img1= 108\n",
      "img2= 109\n",
      "img1= 109\n",
      "img2= 110\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 105 to 110\n",
      "mean_flow_x=5.856469631195068, mean_flow_y=-0.1890771985054016\n",
      "---\n",
      "img1= 106\n",
      "img2= 107\n",
      "img1= 107\n",
      "img2= 108\n",
      "img1= 108\n",
      "img2= 109\n",
      "img1= 109\n",
      "img2= 110\n",
      "img1= 110\n",
      "img2= 111\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 106 to 111\n",
      "mean_flow_x=7.411531448364258, mean_flow_y=-0.7122784852981567\n",
      "---\n",
      "img1= 107\n",
      "img2= 108\n",
      "img1= 108\n",
      "img2= 109\n",
      "img1= 109\n",
      "img2= 110\n",
      "img1= 110\n",
      "img2= 111\n",
      "img1= 111\n",
      "img2= 112\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 107 to 112\n",
      "mean_flow_x=6.279476165771484, mean_flow_y=-0.5401530861854553\n",
      "---\n",
      "img1= 108\n",
      "img2= 109\n",
      "img1= 109\n",
      "img2= 110\n",
      "img1= 110\n",
      "img2= 111\n",
      "img1= 111\n",
      "img2= 112\n",
      "img1= 112\n",
      "img2= 113\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 108 to 113\n",
      "mean_flow_x=7.197576522827148, mean_flow_y=-1.4846910238265991\n",
      "---\n",
      "img1= 109\n",
      "img2= 110\n",
      "img1= 110\n",
      "img2= 111\n",
      "img1= 111\n",
      "img2= 112\n",
      "img1= 112\n",
      "img2= 113\n",
      "img1= 113\n",
      "img2= 114\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 109 to 114\n",
      "mean_flow_x=6.870662689208984, mean_flow_y=-1.2706868648529053\n",
      "---\n",
      "img1= 110\n",
      "img2= 111\n",
      "img1= 111\n",
      "img2= 112\n",
      "img1= 112\n",
      "img2= 113\n",
      "img1= 113\n",
      "img2= 114\n",
      "img1= 114\n",
      "img2= 115\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 110 to 115\n",
      "mean_flow_x=6.4160475730896, mean_flow_y=-0.982492208480835\n",
      "---\n",
      "img1= 111\n",
      "img2= 112\n",
      "img1= 112\n",
      "img2= 113\n",
      "img1= 113\n",
      "img2= 114\n",
      "img1= 114\n",
      "img2= 115\n",
      "img1= 115\n",
      "img2= 116\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 111 to 116\n",
      "mean_flow_x=5.642266750335693, mean_flow_y=-1.08504056930542\n",
      "---\n",
      "img1= 112\n",
      "img2= 113\n",
      "img1= 113\n",
      "img2= 114\n",
      "img1= 114\n",
      "img2= 115\n",
      "img1= 115\n",
      "img2= 116\n",
      "img1= 116\n",
      "img2= 117\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 112 to 117\n",
      "mean_flow_x=6.643350601196289, mean_flow_y=-1.2142101526260376\n",
      "---\n",
      "img1= 113\n",
      "img2= 114\n",
      "img1= 114\n",
      "img2= 115\n",
      "img1= 115\n",
      "img2= 116\n",
      "img1= 116\n",
      "img2= 117\n",
      "img1= 117\n",
      "img2= 118\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 113 to 118\n",
      "mean_flow_x=6.141574382781982, mean_flow_y=-0.9813275337219238\n",
      "---\n",
      "img1= 114\n",
      "img2= 115\n",
      "img1= 115\n",
      "img2= 116\n",
      "img1= 116\n",
      "img2= 117\n",
      "img1= 117\n",
      "img2= 118\n",
      "img1= 118\n",
      "img2= 119\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 114 to 119\n",
      "mean_flow_x=6.704731464385986, mean_flow_y=-1.2802358865737915\n",
      "---\n",
      "img1= 115\n",
      "img2= 116\n",
      "img1= 116\n",
      "img2= 117\n",
      "img1= 117\n",
      "img2= 118\n",
      "img1= 118\n",
      "img2= 119\n",
      "img1= 119\n",
      "img2= 120\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 115 to 120\n",
      "mean_flow_x=6.523475646972656, mean_flow_y=-1.2796401977539062\n",
      "---\n",
      "img1= 116\n",
      "img2= 117\n",
      "img1= 117\n",
      "img2= 118\n",
      "img1= 118\n",
      "img2= 119\n",
      "img1= 119\n",
      "img2= 120\n",
      "img1= 120\n",
      "img2= 121\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 116 to 121\n",
      "mean_flow_x=6.020914554595947, mean_flow_y=-2.0646815299987793\n",
      "---\n",
      "img1= 117\n",
      "img2= 118\n",
      "img1= 118\n",
      "img2= 119\n",
      "img1= 119\n",
      "img2= 120\n",
      "img1= 120\n",
      "img2= 121\n",
      "img1= 121\n",
      "img2= 122\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 117 to 122\n",
      "mean_flow_x=5.568106174468994, mean_flow_y=-2.103208303451538\n",
      "---\n",
      "img1= 118\n",
      "img2= 119\n",
      "img1= 119\n",
      "img2= 120\n",
      "img1= 120\n",
      "img2= 121\n",
      "img1= 121\n",
      "img2= 122\n",
      "img1= 122\n",
      "img2= 123\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 118 to 123\n",
      "mean_flow_x=5.253599643707275, mean_flow_y=-1.7799402475357056\n",
      "---\n",
      "img1= 119\n",
      "img2= 120\n",
      "img1= 120\n",
      "img2= 121\n",
      "img1= 121\n",
      "img2= 122\n",
      "img1= 122\n",
      "img2= 123\n",
      "img1= 123\n",
      "img2= 124\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 119 to 124\n",
      "mean_flow_x=5.084257125854492, mean_flow_y=-1.3892648220062256\n",
      "---\n",
      "img1= 120\n",
      "img2= 121\n",
      "img1= 121\n",
      "img2= 122\n",
      "img1= 122\n",
      "img2= 123\n",
      "img1= 123\n",
      "img2= 124\n",
      "img1= 124\n",
      "img2= 125\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 120 to 125\n",
      "mean_flow_x=4.4065141677856445, mean_flow_y=1.3595433235168457\n",
      "---\n",
      "img1= 121\n",
      "img2= 122\n",
      "img1= 122\n",
      "img2= 123\n",
      "img1= 123\n",
      "img2= 124\n",
      "img1= 124\n",
      "img2= 125\n",
      "img1= 125\n",
      "img2= 126\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 121 to 126\n",
      "mean_flow_x=4.166952133178711, mean_flow_y=1.0221507549285889\n",
      "---\n",
      "img1= 122\n",
      "img2= 123\n",
      "img1= 123\n",
      "img2= 124\n",
      "img1= 124\n",
      "img2= 125\n",
      "img1= 125\n",
      "img2= 126\n",
      "img1= 126\n",
      "img2= 127\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 122 to 127\n",
      "mean_flow_x=4.165276527404785, mean_flow_y=0.3157317340373993\n",
      "---\n",
      "img1= 123\n",
      "img2= 124\n",
      "img1= 124\n",
      "img2= 125\n",
      "img1= 125\n",
      "img2= 126\n",
      "img1= 126\n",
      "img2= 127\n",
      "img1= 127\n",
      "img2= 128\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 123 to 128\n",
      "mean_flow_x=4.3081254959106445, mean_flow_y=-0.1260191649198532\n",
      "---\n",
      "img1= 124\n",
      "img2= 125\n",
      "img1= 125\n",
      "img2= 126\n",
      "img1= 126\n",
      "img2= 127\n",
      "img1= 127\n",
      "img2= 128\n",
      "img1= 128\n",
      "img2= 129\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 124 to 129\n",
      "mean_flow_x=4.560486793518066, mean_flow_y=2.682863235473633\n",
      "---\n",
      "img1= 125\n",
      "img2= 126\n",
      "img1= 126\n",
      "img2= 127\n",
      "img1= 127\n",
      "img2= 128\n",
      "img1= 128\n",
      "img2= 129\n",
      "img1= 129\n",
      "img2= 130\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 125 to 130\n",
      "mean_flow_x=4.705196857452393, mean_flow_y=1.755159616470337\n",
      "---\n",
      "img1= 126\n",
      "img2= 127\n",
      "img1= 127\n",
      "img2= 128\n",
      "img1= 128\n",
      "img2= 129\n",
      "img1= 129\n",
      "img2= 130\n",
      "img1= 130\n",
      "img2= 131\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 126 to 131\n",
      "mean_flow_x=3.9706554412841797, mean_flow_y=1.7591580152511597\n",
      "---\n",
      "img1= 127\n",
      "img2= 128\n",
      "img1= 128\n",
      "img2= 129\n",
      "img1= 129\n",
      "img2= 130\n",
      "img1= 130\n",
      "img2= 131\n",
      "img1= 131\n",
      "img2= 132\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 127 to 132\n",
      "mean_flow_x=3.9506609439849854, mean_flow_y=0.47616004943847656\n",
      "---\n",
      "img1= 128\n",
      "img2= 129\n",
      "img1= 129\n",
      "img2= 130\n",
      "img1= 130\n",
      "img2= 131\n",
      "img1= 131\n",
      "img2= 132\n",
      "img1= 132\n",
      "img2= 133\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 128 to 133\n",
      "mean_flow_x=4.173192024230957, mean_flow_y=0.039882127195596695\n",
      "---\n",
      "img1= 129\n",
      "img2= 130\n",
      "img1= 130\n",
      "img2= 131\n",
      "img1= 131\n",
      "img2= 132\n",
      "img1= 132\n",
      "img2= 133\n",
      "img1= 133\n",
      "img2= 134\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 129 to 134\n",
      "mean_flow_x=5.454845905303955, mean_flow_y=1.0852185487747192\n",
      "---\n",
      "img1= 130\n",
      "img2= 131\n",
      "img1= 131\n",
      "img2= 132\n",
      "img1= 132\n",
      "img2= 133\n",
      "img1= 133\n",
      "img2= 134\n",
      "img1= 134\n",
      "img2= 135\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 130 to 135\n",
      "mean_flow_x=4.82960844039917, mean_flow_y=2.152749538421631\n",
      "---\n",
      "img1= 131\n",
      "img2= 132\n",
      "img1= 132\n",
      "img2= 133\n",
      "img1= 133\n",
      "img2= 134\n",
      "img1= 134\n",
      "img2= 135\n",
      "img1= 135\n",
      "img2= 136\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 131 to 136\n",
      "mean_flow_x=4.789610385894775, mean_flow_y=1.4402472972869873\n",
      "---\n",
      "img1= 132\n",
      "img2= 133\n",
      "img1= 133\n",
      "img2= 134\n",
      "img1= 134\n",
      "img2= 135\n",
      "img1= 135\n",
      "img2= 136\n",
      "img1= 136\n",
      "img2= 137\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 132 to 137\n",
      "mean_flow_x=4.374383449554443, mean_flow_y=1.242634892463684\n",
      "---\n",
      "img1= 133\n",
      "img2= 134\n",
      "img1= 134\n",
      "img2= 135\n",
      "img1= 135\n",
      "img2= 136\n",
      "img1= 136\n",
      "img2= 137\n",
      "img1= 137\n",
      "img2= 138\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 133 to 138\n",
      "mean_flow_x=4.525891304016113, mean_flow_y=-0.3193291127681732\n",
      "---\n",
      "img1= 134\n",
      "img2= 135\n",
      "img1= 135\n",
      "img2= 136\n",
      "img1= 136\n",
      "img2= 137\n",
      "img1= 137\n",
      "img2= 138\n",
      "img1= 138\n",
      "img2= 139\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 134 to 139\n",
      "mean_flow_x=4.321969032287598, mean_flow_y=-0.6329665184020996\n",
      "---\n",
      "img1= 135\n",
      "img2= 136\n",
      "img1= 136\n",
      "img2= 137\n",
      "img1= 137\n",
      "img2= 138\n",
      "img1= 138\n",
      "img2= 139\n",
      "img1= 139\n",
      "img2= 140\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 135 to 140\n",
      "mean_flow_x=4.830026626586914, mean_flow_y=-1.1134389638900757\n",
      "---\n",
      "img1= 136\n",
      "img2= 137\n",
      "img1= 137\n",
      "img2= 138\n",
      "img1= 138\n",
      "img2= 139\n",
      "img1= 139\n",
      "img2= 140\n",
      "img1= 140\n",
      "img2= 141\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 136 to 141\n",
      "mean_flow_x=5.8458147048950195, mean_flow_y=-1.5823148488998413\n",
      "---\n",
      "img1= 137\n",
      "img2= 138\n",
      "img1= 138\n",
      "img2= 139\n",
      "img1= 139\n",
      "img2= 140\n",
      "img1= 140\n",
      "img2= 141\n",
      "img1= 141\n",
      "img2= 142\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 137 to 142\n",
      "mean_flow_x=8.279664039611816, mean_flow_y=-0.2775627374649048\n",
      "---\n",
      "img1= 138\n",
      "img2= 139\n",
      "img1= 139\n",
      "img2= 140\n",
      "img1= 140\n",
      "img2= 141\n",
      "img1= 141\n",
      "img2= 142\n",
      "img1= 142\n",
      "img2= 143\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 138 to 143\n",
      "mean_flow_x=16.884315490722656, mean_flow_y=-1.1241803169250488\n",
      "---\n",
      "img1= 139\n",
      "img2= 140\n",
      "img1= 140\n",
      "img2= 141\n",
      "img1= 141\n",
      "img2= 142\n",
      "img1= 142\n",
      "img2= 143\n",
      "img1= 143\n",
      "img2= 144\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 139 to 144\n",
      "mean_flow_x=14.940006256103516, mean_flow_y=-1.2656941413879395\n",
      "---\n",
      "img1= 140\n",
      "img2= 141\n",
      "img1= 141\n",
      "img2= 142\n",
      "img1= 142\n",
      "img2= 143\n",
      "img1= 143\n",
      "img2= 144\n",
      "img1= 144\n",
      "img2= 145\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 140 to 145\n",
      "mean_flow_x=12.430039405822754, mean_flow_y=-1.0176827907562256\n",
      "---\n",
      "img1= 141\n",
      "img2= 142\n",
      "img1= 142\n",
      "img2= 143\n",
      "img1= 143\n",
      "img2= 144\n",
      "img1= 144\n",
      "img2= 145\n",
      "img1= 145\n",
      "img2= 146\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 141 to 146\n",
      "mean_flow_x=9.832287788391113, mean_flow_y=-1.5501939058303833\n",
      "---\n",
      "img1= 142\n",
      "img2= 143\n",
      "img1= 143\n",
      "img2= 144\n",
      "img1= 144\n",
      "img2= 145\n",
      "img1= 145\n",
      "img2= 146\n",
      "img1= 146\n",
      "img2= 147\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 142 to 147\n",
      "mean_flow_x=7.548401355743408, mean_flow_y=-1.6027042865753174\n",
      "---\n",
      "img1= 143\n",
      "img2= 144\n",
      "img1= 144\n",
      "img2= 145\n",
      "img1= 145\n",
      "img2= 146\n",
      "img1= 146\n",
      "img2= 147\n",
      "img1= 147\n",
      "img2= 148\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 143 to 148\n",
      "mean_flow_x=5.168017387390137, mean_flow_y=-0.6428797245025635\n",
      "---\n",
      "img1= 144\n",
      "img2= 145\n",
      "img1= 145\n",
      "img2= 146\n",
      "img1= 146\n",
      "img2= 147\n",
      "img1= 147\n",
      "img2= 148\n",
      "img1= 148\n",
      "img2= 149\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 144 to 149\n",
      "mean_flow_x=5.188202381134033, mean_flow_y=-1.022096037864685\n",
      "---\n",
      "img1= 145\n",
      "img2= 146\n",
      "img1= 146\n",
      "img2= 147\n",
      "img1= 147\n",
      "img2= 148\n",
      "img1= 148\n",
      "img2= 149\n",
      "img1= 149\n",
      "img2= 150\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 145 to 150\n",
      "mean_flow_x=5.203534126281738, mean_flow_y=-1.6684120893478394\n",
      "---\n",
      "img1= 146\n",
      "img2= 147\n",
      "img1= 147\n",
      "img2= 148\n",
      "img1= 148\n",
      "img2= 149\n",
      "img1= 149\n",
      "img2= 150\n",
      "img1= 150\n",
      "img2= 151\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 146 to 151\n",
      "mean_flow_x=4.969593048095703, mean_flow_y=-1.453050136566162\n",
      "---\n",
      "img1= 147\n",
      "img2= 148\n",
      "img1= 148\n",
      "img2= 149\n",
      "img1= 149\n",
      "img2= 150\n",
      "img1= 150\n",
      "img2= 151\n",
      "img1= 151\n",
      "img2= 152\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 147 to 152\n",
      "mean_flow_x=4.022017955780029, mean_flow_y=-1.2081462144851685\n",
      "---\n",
      "img1= 148\n",
      "img2= 149\n",
      "img1= 149\n",
      "img2= 150\n",
      "img1= 150\n",
      "img2= 151\n",
      "img1= 151\n",
      "img2= 152\n",
      "img1= 152\n",
      "img2= 153\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 148 to 153\n",
      "mean_flow_x=6.486619472503662, mean_flow_y=-4.31486701965332\n",
      "---\n",
      "img1= 149\n",
      "img2= 150\n",
      "img1= 150\n",
      "img2= 151\n",
      "img1= 151\n",
      "img2= 152\n",
      "img1= 152\n",
      "img2= 153\n",
      "img1= 153\n",
      "img2= 154\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 149 to 154\n",
      "mean_flow_x=5.920197486877441, mean_flow_y=-2.3664419651031494\n",
      "---\n",
      "img1= 150\n",
      "img2= 151\n",
      "img1= 151\n",
      "img2= 152\n",
      "img1= 152\n",
      "img2= 153\n",
      "img1= 153\n",
      "img2= 154\n",
      "img1= 154\n",
      "img2= 155\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 150 to 155\n",
      "mean_flow_x=5.176307201385498, mean_flow_y=-1.8377554416656494\n",
      "---\n",
      "img1= 151\n",
      "img2= 152\n",
      "img1= 152\n",
      "img2= 153\n",
      "img1= 153\n",
      "img2= 154\n",
      "img1= 154\n",
      "img2= 155\n",
      "img1= 155\n",
      "img2= 156\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 151 to 156\n",
      "mean_flow_x=7.435665607452393, mean_flow_y=-2.355875015258789\n",
      "---\n",
      "img1= 152\n",
      "img2= 153\n",
      "img1= 153\n",
      "img2= 154\n",
      "img1= 154\n",
      "img2= 155\n",
      "img1= 155\n",
      "img2= 156\n",
      "img1= 156\n",
      "img2= 157\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 152 to 157\n",
      "mean_flow_x=6.00487756729126, mean_flow_y=-1.0493308305740356\n",
      "---\n",
      "img1= 153\n",
      "img2= 154\n",
      "img1= 154\n",
      "img2= 155\n",
      "img1= 155\n",
      "img2= 156\n",
      "img1= 156\n",
      "img2= 157\n",
      "img1= 157\n",
      "img2= 158\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 153 to 158\n",
      "mean_flow_x=4.940211296081543, mean_flow_y=1.44432532787323\n",
      "---\n",
      "img1= 154\n",
      "img2= 155\n",
      "img1= 155\n",
      "img2= 156\n",
      "img1= 156\n",
      "img2= 157\n",
      "img1= 157\n",
      "img2= 158\n",
      "img1= 158\n",
      "img2= 159\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 154 to 159\n",
      "mean_flow_x=8.219058990478516, mean_flow_y=9.565251350402832\n",
      "---\n",
      "img1= 155\n",
      "img2= 156\n",
      "img1= 156\n",
      "img2= 157\n",
      "img1= 157\n",
      "img2= 158\n",
      "img1= 158\n",
      "img2= 159\n",
      "img1= 159\n",
      "img2= 160\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 155 to 160\n",
      "mean_flow_x=6.281201362609863, mean_flow_y=7.467599391937256\n",
      "---\n",
      "img1= 156\n",
      "img2= 157\n",
      "img1= 157\n",
      "img2= 158\n",
      "img1= 158\n",
      "img2= 159\n",
      "img1= 159\n",
      "img2= 160\n",
      "img1= 160\n",
      "img2= 161\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 156 to 161\n",
      "mean_flow_x=6.328549861907959, mean_flow_y=7.216592311859131\n",
      "---\n",
      "img1= 157\n",
      "img2= 158\n",
      "img1= 158\n",
      "img2= 159\n",
      "img1= 159\n",
      "img2= 160\n",
      "img1= 160\n",
      "img2= 161\n",
      "img1= 161\n",
      "img2= 162\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 157 to 162\n",
      "mean_flow_x=6.1534552574157715, mean_flow_y=6.368503093719482\n",
      "---\n",
      "img1= 158\n",
      "img2= 159\n",
      "img1= 159\n",
      "img2= 160\n",
      "img1= 160\n",
      "img2= 161\n",
      "img1= 161\n",
      "img2= 162\n",
      "img1= 162\n",
      "img2= 163\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 158 to 163\n",
      "mean_flow_x=6.795740604400635, mean_flow_y=3.379767894744873\n",
      "---\n",
      "img1= 159\n",
      "img2= 160\n",
      "img1= 160\n",
      "img2= 161\n",
      "img1= 161\n",
      "img2= 162\n",
      "img1= 162\n",
      "img2= 163\n",
      "img1= 163\n",
      "img2= 164\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 159 to 164\n",
      "mean_flow_x=8.225974082946777, mean_flow_y=-0.2487635761499405\n",
      "---\n",
      "img1= 160\n",
      "img2= 161\n",
      "img1= 161\n",
      "img2= 162\n",
      "img1= 162\n",
      "img2= 163\n",
      "img1= 163\n",
      "img2= 164\n",
      "img1= 164\n",
      "img2= 165\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 160 to 165\n",
      "mean_flow_x=-31.371152877807617, mean_flow_y=3.1229469776153564\n",
      "---\n",
      "img1= 161\n",
      "img2= 162\n",
      "img1= 162\n",
      "img2= 163\n",
      "img1= 163\n",
      "img2= 164\n",
      "img1= 164\n",
      "img2= 165\n",
      "img1= 165\n",
      "img2= 166\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 161 to 166\n",
      "mean_flow_x=-23.937084197998047, mean_flow_y=-0.21462158858776093\n",
      "---\n",
      "img1= 162\n",
      "img2= 163\n",
      "img1= 163\n",
      "img2= 164\n",
      "img1= 164\n",
      "img2= 165\n",
      "img1= 165\n",
      "img2= 166\n",
      "img1= 166\n",
      "img2= 167\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 162 to 167\n",
      "mean_flow_x=-16.32086944580078, mean_flow_y=-1.536217212677002\n",
      "---\n",
      "img1= 163\n",
      "img2= 164\n",
      "img1= 164\n",
      "img2= 165\n",
      "img1= 165\n",
      "img2= 166\n",
      "img1= 166\n",
      "img2= 167\n",
      "img1= 167\n",
      "img2= 168\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 163 to 168\n",
      "mean_flow_x=-11.188716888427734, mean_flow_y=-0.9052639603614807\n",
      "---\n",
      "img1= 164\n",
      "img2= 165\n",
      "img1= 165\n",
      "img2= 166\n",
      "img1= 166\n",
      "img2= 167\n",
      "img1= 167\n",
      "img2= 168\n",
      "img1= 168\n",
      "img2= 169\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 164 to 169\n",
      "mean_flow_x=-4.459843158721924, mean_flow_y=-1.1191825866699219\n",
      "---\n",
      "img1= 165\n",
      "img2= 166\n",
      "img1= 166\n",
      "img2= 167\n",
      "img1= 167\n",
      "img2= 168\n",
      "img1= 168\n",
      "img2= 169\n",
      "img1= 169\n",
      "img2= 170\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 165 to 170\n",
      "mean_flow_x=3.0094852447509766, mean_flow_y=-2.138572931289673\n",
      "---\n",
      "img1= 166\n",
      "img2= 167\n",
      "img1= 167\n",
      "img2= 168\n",
      "img1= 168\n",
      "img2= 169\n",
      "img1= 169\n",
      "img2= 170\n",
      "img1= 170\n",
      "img2= 171\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 166 to 171\n",
      "mean_flow_x=3.10715651512146, mean_flow_y=0.7815046906471252\n",
      "---\n",
      "img1= 167\n",
      "img2= 168\n",
      "img1= 168\n",
      "img2= 169\n",
      "img1= 169\n",
      "img2= 170\n",
      "img1= 170\n",
      "img2= 171\n",
      "img1= 171\n",
      "img2= 172\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 167 to 172\n",
      "mean_flow_x=3.099263906478882, mean_flow_y=0.1430019587278366\n",
      "---\n",
      "img1= 168\n",
      "img2= 169\n",
      "img1= 169\n",
      "img2= 170\n",
      "img1= 170\n",
      "img2= 171\n",
      "img1= 171\n",
      "img2= 172\n",
      "img1= 172\n",
      "img2= 173\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 168 to 173\n",
      "mean_flow_x=3.204265594482422, mean_flow_y=-0.15691660344600677\n",
      "---\n",
      "img1= 169\n",
      "img2= 170\n",
      "img1= 170\n",
      "img2= 171\n",
      "img1= 171\n",
      "img2= 172\n",
      "img1= 172\n",
      "img2= 173\n",
      "img1= 173\n",
      "img2= 174\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 169 to 174\n",
      "mean_flow_x=3.0398809909820557, mean_flow_y=-0.2000948190689087\n",
      "---\n",
      "img1= 170\n",
      "img2= 171\n",
      "img1= 171\n",
      "img2= 172\n",
      "img1= 172\n",
      "img2= 173\n",
      "img1= 173\n",
      "img2= 174\n",
      "img1= 174\n",
      "img2= 175\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 170 to 175\n",
      "mean_flow_x=2.4286949634552, mean_flow_y=-0.262880802154541\n",
      "---\n",
      "img1= 171\n",
      "img2= 172\n",
      "img1= 172\n",
      "img2= 173\n",
      "img1= 173\n",
      "img2= 174\n",
      "img1= 174\n",
      "img2= 175\n",
      "img1= 175\n",
      "img2= 176\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 171 to 176\n",
      "mean_flow_x=1.9482009410858154, mean_flow_y=-0.6184199452400208\n",
      "---\n",
      "img1= 172\n",
      "img2= 173\n",
      "img1= 173\n",
      "img2= 174\n",
      "img1= 174\n",
      "img2= 175\n",
      "img1= 175\n",
      "img2= 176\n",
      "img1= 176\n",
      "img2= 177\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 172 to 177\n",
      "mean_flow_x=2.2855184078216553, mean_flow_y=-1.1341441869735718\n",
      "---\n",
      "img1= 173\n",
      "img2= 174\n",
      "img1= 174\n",
      "img2= 175\n",
      "img1= 175\n",
      "img2= 176\n",
      "img1= 176\n",
      "img2= 177\n",
      "img1= 177\n",
      "img2= 178\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 173 to 178\n",
      "mean_flow_x=2.274812936782837, mean_flow_y=-0.9194566607475281\n",
      "---\n",
      "img1= 174\n",
      "img2= 175\n",
      "img1= 175\n",
      "img2= 176\n",
      "img1= 176\n",
      "img2= 177\n",
      "img1= 177\n",
      "img2= 178\n",
      "img1= 178\n",
      "img2= 179\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 174 to 179\n",
      "mean_flow_x=2.950984477996826, mean_flow_y=-0.404674768447876\n",
      "---\n",
      "img1= 175\n",
      "img2= 176\n",
      "img1= 176\n",
      "img2= 177\n",
      "img1= 177\n",
      "img2= 178\n",
      "img1= 178\n",
      "img2= 179\n",
      "img1= 179\n",
      "img2= 180\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 175 to 180\n",
      "mean_flow_x=4.238081455230713, mean_flow_y=5.3983635902404785\n",
      "---\n",
      "img1= 176\n",
      "img2= 177\n",
      "img1= 177\n",
      "img2= 178\n",
      "img1= 178\n",
      "img2= 179\n",
      "img1= 179\n",
      "img2= 180\n",
      "img1= 180\n",
      "img2= 181\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 176 to 181\n",
      "mean_flow_x=10.666109085083008, mean_flow_y=13.499686241149902\n",
      "---\n",
      "img1= 177\n",
      "img2= 178\n",
      "img1= 178\n",
      "img2= 179\n",
      "img1= 179\n",
      "img2= 180\n",
      "img1= 180\n",
      "img2= 181\n",
      "img1= 181\n",
      "img2= 182\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 177 to 182\n",
      "mean_flow_x=9.282272338867188, mean_flow_y=10.86111831665039\n",
      "---\n",
      "img1= 178\n",
      "img2= 179\n",
      "img1= 179\n",
      "img2= 180\n",
      "img1= 180\n",
      "img2= 181\n",
      "img1= 181\n",
      "img2= 182\n",
      "img1= 182\n",
      "img2= 183\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 178 to 183\n",
      "mean_flow_x=8.083096504211426, mean_flow_y=8.359675407409668\n",
      "---\n",
      "img1= 179\n",
      "img2= 180\n",
      "img1= 180\n",
      "img2= 181\n",
      "img1= 181\n",
      "img2= 182\n",
      "img1= 182\n",
      "img2= 183\n",
      "img1= 183\n",
      "img2= 184\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 179 to 184\n",
      "mean_flow_x=6.1176438331604, mean_flow_y=5.627038478851318\n",
      "---\n",
      "img1= 180\n",
      "img2= 181\n",
      "img1= 181\n",
      "img2= 182\n",
      "img1= 182\n",
      "img2= 183\n",
      "img1= 183\n",
      "img2= 184\n",
      "img1= 184\n",
      "img2= 185\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 180 to 185\n",
      "mean_flow_x=4.371720314025879, mean_flow_y=8.808344841003418\n",
      "---\n",
      "img1= 181\n",
      "img2= 182\n",
      "img1= 182\n",
      "img2= 183\n",
      "img1= 183\n",
      "img2= 184\n",
      "img1= 184\n",
      "img2= 185\n",
      "img1= 185\n",
      "img2= 186\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 181 to 186\n",
      "mean_flow_x=4.683608055114746, mean_flow_y=10.677903175354004\n",
      "---\n",
      "img1= 182\n",
      "img2= 183\n",
      "img1= 183\n",
      "img2= 184\n",
      "img1= 184\n",
      "img2= 185\n",
      "img1= 185\n",
      "img2= 186\n",
      "img1= 186\n",
      "img2= 187\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 182 to 187\n",
      "mean_flow_x=18.293731689453125, mean_flow_y=31.61815071105957\n",
      "---\n",
      "img1= 183\n",
      "img2= 184\n",
      "img1= 184\n",
      "img2= 185\n",
      "img1= 185\n",
      "img2= 186\n",
      "img1= 186\n",
      "img2= 187\n",
      "img1= 187\n",
      "img2= 188\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 183 to 188\n",
      "mean_flow_x=15.558733940124512, mean_flow_y=24.709259033203125\n",
      "---\n",
      "img1= 184\n",
      "img2= 185\n",
      "img1= 185\n",
      "img2= 186\n",
      "img1= 186\n",
      "img2= 187\n",
      "img1= 187\n",
      "img2= 188\n",
      "img1= 188\n",
      "img2= 189\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 184 to 189\n",
      "mean_flow_x=12.540234565734863, mean_flow_y=18.444902420043945\n",
      "---\n",
      "img1= 185\n",
      "img2= 186\n",
      "img1= 186\n",
      "img2= 187\n",
      "img1= 187\n",
      "img2= 188\n",
      "img1= 188\n",
      "img2= 189\n",
      "img1= 189\n",
      "img2= 190\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 185 to 190\n",
      "mean_flow_x=8.86042308807373, mean_flow_y=10.792828559875488\n",
      "---\n",
      "img1= 186\n",
      "img2= 187\n",
      "img1= 187\n",
      "img2= 188\n",
      "img1= 188\n",
      "img2= 189\n",
      "img1= 189\n",
      "img2= 190\n",
      "img1= 190\n",
      "img2= 191\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 186 to 191\n",
      "mean_flow_x=5.654730319976807, mean_flow_y=4.5746049880981445\n",
      "---\n",
      "img1= 187\n",
      "img2= 188\n",
      "img1= 188\n",
      "img2= 189\n",
      "img1= 189\n",
      "img2= 190\n",
      "img1= 190\n",
      "img2= 191\n",
      "img1= 191\n",
      "img2= 192\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 187 to 192\n",
      "mean_flow_x=3.1145668029785156, mean_flow_y=-0.48216763138771057\n",
      "---\n",
      "img1= 188\n",
      "img2= 189\n",
      "img1= 189\n",
      "img2= 190\n",
      "img1= 190\n",
      "img2= 191\n",
      "img1= 191\n",
      "img2= 192\n",
      "img1= 192\n",
      "img2= 193\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 188 to 193\n",
      "mean_flow_x=3.2792375087738037, mean_flow_y=0.42707642912864685\n",
      "---\n",
      "img1= 189\n",
      "img2= 190\n",
      "img1= 190\n",
      "img2= 191\n",
      "img1= 191\n",
      "img2= 192\n",
      "img1= 192\n",
      "img2= 193\n",
      "img1= 193\n",
      "img2= 194\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 189 to 194\n",
      "mean_flow_x=3.7732503414154053, mean_flow_y=1.0318700075149536\n",
      "---\n",
      "img1= 190\n",
      "img2= 191\n",
      "img1= 191\n",
      "img2= 192\n",
      "img1= 192\n",
      "img2= 193\n",
      "img1= 193\n",
      "img2= 194\n",
      "img1= 194\n",
      "img2= 195\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 190 to 195\n",
      "mean_flow_x=4.006688594818115, mean_flow_y=2.154468297958374\n",
      "---\n",
      "img1= 191\n",
      "img2= 192\n",
      "img1= 192\n",
      "img2= 193\n",
      "img1= 193\n",
      "img2= 194\n",
      "img1= 194\n",
      "img2= 195\n",
      "img1= 195\n",
      "img2= 196\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 191 to 196\n",
      "mean_flow_x=4.478511810302734, mean_flow_y=2.6835412979125977\n",
      "---\n",
      "img1= 192\n",
      "img2= 193\n",
      "img1= 193\n",
      "img2= 194\n",
      "img1= 194\n",
      "img2= 195\n",
      "img1= 195\n",
      "img2= 196\n",
      "img1= 196\n",
      "img2= 197\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 192 to 197\n",
      "mean_flow_x=12.454941749572754, mean_flow_y=11.65099048614502\n",
      "---\n",
      "img1= 193\n",
      "img2= 194\n",
      "img1= 194\n",
      "img2= 195\n",
      "img1= 195\n",
      "img2= 196\n",
      "img1= 196\n",
      "img2= 197\n",
      "img1= 197\n",
      "img2= 198\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 193 to 198\n",
      "mean_flow_x=9.709552764892578, mean_flow_y=9.87303638458252\n",
      "---\n",
      "img1= 194\n",
      "img2= 195\n",
      "img1= 195\n",
      "img2= 196\n",
      "img1= 196\n",
      "img2= 197\n",
      "img1= 197\n",
      "img2= 198\n",
      "img1= 198\n",
      "img2= 199\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 194 to 199\n",
      "mean_flow_x=7.845941543579102, mean_flow_y=7.560146808624268\n",
      "---\n",
      "img1= 195\n",
      "img2= 196\n",
      "img1= 196\n",
      "img2= 197\n",
      "img1= 197\n",
      "img2= 198\n",
      "img1= 198\n",
      "img2= 199\n",
      "img1= 199\n",
      "img2= 200\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 195 to 200\n",
      "mean_flow_x=5.02242374420166, mean_flow_y=7.359978199005127\n",
      "---\n",
      "img1= 196\n",
      "img2= 197\n",
      "img1= 197\n",
      "img2= 198\n",
      "img1= 198\n",
      "img2= 199\n",
      "img1= 199\n",
      "img2= 200\n",
      "img1= 200\n",
      "img2= 201\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 196 to 201\n",
      "mean_flow_x=1.8962210416793823, mean_flow_y=4.266996383666992\n",
      "---\n",
      "img1= 197\n",
      "img2= 198\n",
      "img1= 198\n",
      "img2= 199\n",
      "img1= 199\n",
      "img2= 200\n",
      "img1= 200\n",
      "img2= 201\n",
      "img1= 201\n",
      "img2= 202\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 197 to 202\n",
      "mean_flow_x=-0.7407675981521606, mean_flow_y=4.936417102813721\n",
      "---\n",
      "img1= 198\n",
      "img2= 199\n",
      "img1= 199\n",
      "img2= 200\n",
      "img1= 200\n",
      "img2= 201\n",
      "img1= 201\n",
      "img2= 202\n",
      "img1= 202\n",
      "img2= 203\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 198 to 203\n",
      "mean_flow_x=1.723741054534912, mean_flow_y=6.733722686767578\n",
      "---\n",
      "img1= 199\n",
      "img2= 200\n",
      "img1= 200\n",
      "img2= 201\n",
      "img1= 201\n",
      "img2= 202\n",
      "img1= 202\n",
      "img2= 203\n",
      "img1= 203\n",
      "img2= 204\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 199 to 204\n",
      "mean_flow_x=2.822294235229492, mean_flow_y=5.573642253875732\n",
      "---\n",
      "img1= 200\n",
      "img2= 201\n",
      "img1= 201\n",
      "img2= 202\n",
      "img1= 202\n",
      "img2= 203\n",
      "img1= 203\n",
      "img2= 204\n",
      "img1= 204\n",
      "img2= 205\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 200 to 205\n",
      "mean_flow_x=5.756302356719971, mean_flow_y=7.744051456451416\n",
      "---\n",
      "img1= 201\n",
      "img2= 202\n",
      "img1= 202\n",
      "img2= 203\n",
      "img1= 203\n",
      "img2= 204\n",
      "img1= 204\n",
      "img2= 205\n",
      "img1= 205\n",
      "img2= 206\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 201 to 206\n",
      "mean_flow_x=6.820601463317871, mean_flow_y=8.801840782165527\n",
      "---\n",
      "img1= 202\n",
      "img2= 203\n",
      "img1= 203\n",
      "img2= 204\n",
      "img1= 204\n",
      "img2= 205\n",
      "img1= 205\n",
      "img2= 206\n",
      "img1= 206\n",
      "img2= 207\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 202 to 207\n",
      "mean_flow_x=7.902182579040527, mean_flow_y=9.58345890045166\n",
      "---\n",
      "img1= 203\n",
      "img2= 204\n",
      "img1= 204\n",
      "img2= 205\n",
      "img1= 205\n",
      "img2= 206\n",
      "img1= 206\n",
      "img2= 207\n",
      "img1= 207\n",
      "img2= 208\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 203 to 208\n",
      "mean_flow_x=7.1315693855285645, mean_flow_y=6.123981475830078\n",
      "---\n",
      "img1= 204\n",
      "img2= 205\n",
      "img1= 205\n",
      "img2= 206\n",
      "img1= 206\n",
      "img2= 207\n",
      "img1= 207\n",
      "img2= 208\n",
      "img1= 208\n",
      "img2= 209\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 204 to 209\n",
      "mean_flow_x=6.752406120300293, mean_flow_y=2.9466090202331543\n",
      "---\n",
      "img1= 205\n",
      "img2= 206\n",
      "img1= 206\n",
      "img2= 207\n",
      "img1= 207\n",
      "img2= 208\n",
      "img1= 208\n",
      "img2= 209\n",
      "img1= 209\n",
      "img2= 210\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 205 to 210\n",
      "mean_flow_x=6.555754661560059, mean_flow_y=0.604602038860321\n",
      "---\n",
      "img1= 206\n",
      "img2= 207\n",
      "img1= 207\n",
      "img2= 208\n",
      "img1= 208\n",
      "img2= 209\n",
      "img1= 209\n",
      "img2= 210\n",
      "img1= 210\n",
      "img2= 211\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 206 to 211\n",
      "mean_flow_x=4.996848106384277, mean_flow_y=-1.20579195022583\n",
      "---\n",
      "img1= 207\n",
      "img2= 208\n",
      "img1= 208\n",
      "img2= 209\n",
      "img1= 209\n",
      "img2= 210\n",
      "img1= 210\n",
      "img2= 211\n",
      "img1= 211\n",
      "img2= 212\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 207 to 212\n",
      "mean_flow_x=7.821340560913086, mean_flow_y=0.5073642730712891\n",
      "---\n",
      "img1= 208\n",
      "img2= 209\n",
      "img1= 209\n",
      "img2= 210\n",
      "img1= 210\n",
      "img2= 211\n",
      "img1= 211\n",
      "img2= 212\n",
      "img1= 212\n",
      "img2= 213\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 208 to 213\n",
      "mean_flow_x=8.054853439331055, mean_flow_y=1.5961971282958984\n",
      "---\n",
      "img1= 209\n",
      "img2= 210\n",
      "img1= 210\n",
      "img2= 211\n",
      "img1= 211\n",
      "img2= 212\n",
      "img1= 212\n",
      "img2= 213\n",
      "img1= 213\n",
      "img2= 214\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 209 to 214\n",
      "mean_flow_x=7.821079730987549, mean_flow_y=4.257550239562988\n",
      "---\n",
      "img1= 210\n",
      "img2= 211\n",
      "img1= 211\n",
      "img2= 212\n",
      "img1= 212\n",
      "img2= 213\n",
      "img1= 213\n",
      "img2= 214\n",
      "img1= 214\n",
      "img2= 215\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 210 to 215\n",
      "mean_flow_x=7.605893611907959, mean_flow_y=5.172432899475098\n",
      "---\n",
      "img1= 211\n",
      "img2= 212\n",
      "img1= 212\n",
      "img2= 213\n",
      "img1= 213\n",
      "img2= 214\n",
      "img1= 214\n",
      "img2= 215\n",
      "img1= 215\n",
      "img2= 216\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 211 to 216\n",
      "mean_flow_x=6.086006164550781, mean_flow_y=4.208019733428955\n",
      "---\n",
      "img1= 212\n",
      "img2= 213\n",
      "img1= 213\n",
      "img2= 214\n",
      "img1= 214\n",
      "img2= 215\n",
      "img1= 215\n",
      "img2= 216\n",
      "img1= 216\n",
      "img2= 217\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 212 to 217\n",
      "mean_flow_x=5.453557968139648, mean_flow_y=3.6533894538879395\n",
      "---\n",
      "img1= 213\n",
      "img2= 214\n",
      "img1= 214\n",
      "img2= 215\n",
      "img1= 215\n",
      "img2= 216\n",
      "img1= 216\n",
      "img2= 217\n",
      "img1= 217\n",
      "img2= 218\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 213 to 218\n",
      "mean_flow_x=4.824333667755127, mean_flow_y=2.9790680408477783\n",
      "---\n",
      "img1= 214\n",
      "img2= 215\n",
      "img1= 215\n",
      "img2= 216\n",
      "img1= 216\n",
      "img2= 217\n",
      "img1= 217\n",
      "img2= 218\n",
      "img1= 218\n",
      "img2= 219\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 214 to 219\n",
      "mean_flow_x=4.750707626342773, mean_flow_y=6.936873435974121\n",
      "---\n",
      "img1= 215\n",
      "img2= 216\n",
      "img1= 216\n",
      "img2= 217\n",
      "img1= 217\n",
      "img2= 218\n",
      "img1= 218\n",
      "img2= 219\n",
      "img1= 219\n",
      "img2= 220\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 215 to 220\n",
      "mean_flow_x=4.510542392730713, mean_flow_y=5.824482440948486\n",
      "---\n",
      "img1= 216\n",
      "img2= 217\n",
      "img1= 217\n",
      "img2= 218\n",
      "img1= 218\n",
      "img2= 219\n",
      "img1= 219\n",
      "img2= 220\n",
      "img1= 220\n",
      "img2= 221\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 216 to 221\n",
      "mean_flow_x=5.344813346862793, mean_flow_y=4.977488994598389\n",
      "---\n",
      "img1= 217\n",
      "img2= 218\n",
      "img1= 218\n",
      "img2= 219\n",
      "img1= 219\n",
      "img2= 220\n",
      "img1= 220\n",
      "img2= 221\n",
      "img1= 221\n",
      "img2= 222\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 217 to 222\n",
      "mean_flow_x=6.338135719299316, mean_flow_y=5.409507751464844\n",
      "---\n",
      "img1= 218\n",
      "img2= 219\n",
      "img1= 219\n",
      "img2= 220\n",
      "img1= 220\n",
      "img2= 221\n",
      "img1= 221\n",
      "img2= 222\n",
      "img1= 222\n",
      "img2= 223\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 218 to 223\n",
      "mean_flow_x=6.114012718200684, mean_flow_y=5.13165283203125\n",
      "---\n",
      "img1= 219\n",
      "img2= 220\n",
      "img1= 220\n",
      "img2= 221\n",
      "img1= 221\n",
      "img2= 222\n",
      "img1= 222\n",
      "img2= 223\n",
      "img1= 223\n",
      "img2= 224\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 219 to 224\n",
      "mean_flow_x=6.071475982666016, mean_flow_y=4.465387344360352\n",
      "---\n",
      "img1= 220\n",
      "img2= 221\n",
      "img1= 221\n",
      "img2= 222\n",
      "img1= 222\n",
      "img2= 223\n",
      "img1= 223\n",
      "img2= 224\n",
      "img1= 224\n",
      "img2= 225\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 220 to 225\n",
      "mean_flow_x=7.825977325439453, mean_flow_y=6.41815710067749\n",
      "---\n",
      "img1= 221\n",
      "img2= 222\n",
      "img1= 222\n",
      "img2= 223\n",
      "img1= 223\n",
      "img2= 224\n",
      "img1= 224\n",
      "img2= 225\n",
      "img1= 225\n",
      "img2= 226\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 221 to 226\n",
      "mean_flow_x=7.753747463226318, mean_flow_y=6.360386371612549\n",
      "---\n",
      "img1= 222\n",
      "img2= 223\n",
      "img1= 223\n",
      "img2= 224\n",
      "img1= 224\n",
      "img2= 225\n",
      "img1= 225\n",
      "img2= 226\n",
      "img1= 226\n",
      "img2= 227\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 222 to 227\n",
      "mean_flow_x=8.567185401916504, mean_flow_y=6.9376654624938965\n",
      "---\n",
      "img1= 223\n",
      "img2= 224\n",
      "img1= 224\n",
      "img2= 225\n",
      "img1= 225\n",
      "img2= 226\n",
      "img1= 226\n",
      "img2= 227\n",
      "img1= 227\n",
      "img2= 228\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 223 to 228\n",
      "mean_flow_x=8.742776870727539, mean_flow_y=7.533095359802246\n",
      "---\n",
      "img1= 224\n",
      "img2= 225\n",
      "img1= 225\n",
      "img2= 226\n",
      "img1= 226\n",
      "img2= 227\n",
      "img1= 227\n",
      "img2= 228\n",
      "img1= 228\n",
      "img2= 229\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 224 to 229\n",
      "mean_flow_x=6.852250576019287, mean_flow_y=5.669468879699707\n",
      "---\n",
      "img1= 225\n",
      "img2= 226\n",
      "img1= 226\n",
      "img2= 227\n",
      "img1= 227\n",
      "img2= 228\n",
      "img1= 228\n",
      "img2= 229\n",
      "img1= 229\n",
      "img2= 230\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 225 to 230\n",
      "mean_flow_x=5.881430625915527, mean_flow_y=3.533076286315918\n",
      "---\n",
      "img1= 226\n",
      "img2= 227\n",
      "img1= 227\n",
      "img2= 228\n",
      "img1= 228\n",
      "img2= 229\n",
      "img1= 229\n",
      "img2= 230\n",
      "img1= 230\n",
      "img2= 231\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 226 to 231\n",
      "mean_flow_x=7.135164260864258, mean_flow_y=4.035223007202148\n",
      "---\n",
      "img1= 227\n",
      "img2= 228\n",
      "img1= 228\n",
      "img2= 229\n",
      "img1= 229\n",
      "img2= 230\n",
      "img1= 230\n",
      "img2= 231\n",
      "img1= 231\n",
      "img2= 232\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 227 to 232\n",
      "mean_flow_x=5.866591453552246, mean_flow_y=2.38922119140625\n",
      "---\n",
      "img1= 228\n",
      "img2= 229\n",
      "img1= 229\n",
      "img2= 230\n",
      "img1= 230\n",
      "img2= 231\n",
      "img1= 231\n",
      "img2= 232\n",
      "img1= 232\n",
      "img2= 233\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 228 to 233\n",
      "mean_flow_x=5.287318706512451, mean_flow_y=0.24011436104774475\n",
      "---\n",
      "img1= 229\n",
      "img2= 230\n",
      "img1= 230\n",
      "img2= 231\n",
      "img1= 231\n",
      "img2= 232\n",
      "img1= 232\n",
      "img2= 233\n",
      "img1= 233\n",
      "img2= 234\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 229 to 234\n",
      "mean_flow_x=5.245626926422119, mean_flow_y=-0.21813447773456573\n",
      "---\n",
      "img1= 230\n",
      "img2= 231\n",
      "img1= 231\n",
      "img2= 232\n",
      "img1= 232\n",
      "img2= 233\n",
      "img1= 233\n",
      "img2= 234\n",
      "img1= 234\n",
      "img2= 235\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 230 to 235\n",
      "mean_flow_x=4.692755699157715, mean_flow_y=-0.9999741911888123\n",
      "---\n",
      "img1= 231\n",
      "img2= 232\n",
      "img1= 232\n",
      "img2= 233\n",
      "img1= 233\n",
      "img2= 234\n",
      "img1= 234\n",
      "img2= 235\n",
      "img1= 235\n",
      "img2= 236\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 231 to 236\n",
      "mean_flow_x=4.329248428344727, mean_flow_y=-1.1655505895614624\n",
      "---\n",
      "img1= 232\n",
      "img2= 233\n",
      "img1= 233\n",
      "img2= 234\n",
      "img1= 234\n",
      "img2= 235\n",
      "img1= 235\n",
      "img2= 236\n",
      "img1= 236\n",
      "img2= 237\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 232 to 237\n",
      "mean_flow_x=4.315561771392822, mean_flow_y=-1.1631807088851929\n",
      "---\n",
      "img1= 233\n",
      "img2= 234\n",
      "img1= 234\n",
      "img2= 235\n",
      "img1= 235\n",
      "img2= 236\n",
      "img1= 236\n",
      "img2= 237\n",
      "img1= 237\n",
      "img2= 238\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 233 to 238\n",
      "mean_flow_x=4.044626712799072, mean_flow_y=-0.6171863079071045\n",
      "---\n",
      "img1= 234\n",
      "img2= 235\n",
      "img1= 235\n",
      "img2= 236\n",
      "img1= 236\n",
      "img2= 237\n",
      "img1= 237\n",
      "img2= 238\n",
      "img1= 238\n",
      "img2= 239\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 234 to 239\n",
      "mean_flow_x=4.7253899574279785, mean_flow_y=-0.9679160118103027\n",
      "---\n",
      "img1= 235\n",
      "img2= 236\n",
      "img1= 236\n",
      "img2= 237\n",
      "img1= 237\n",
      "img2= 238\n",
      "img1= 238\n",
      "img2= 239\n",
      "img1= 239\n",
      "img2= 240\n",
      "shape= torch.Size([1, 2, 200, 200])\n",
      "Processed frame 235 to 240\n",
      "mean_flow_x=4.268718719482422, mean_flow_y=-1.0917328596115112\n",
      "---\n",
      "All frames processed.\n"
     ]
    }
   ],
   "execution_count": 192
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
